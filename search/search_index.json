{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"EQIPA \u2013 Evapotranspiration-based Quick Irrigation Performance Assessment Platform","text":""},{"location":"#overview","title":"\ud83c\udf10 Overview","text":"<p>The EQIPA (Evapotranspiration-based Quick Irrigation Performance Assessment) platform \u2013 eqipa.waterinag.org \u2013 is a powerful, web-based geospatial application built to evaluate the performance of irrigation schemes across India.</p> <p>EQIPA platform leverages open-source remote sensing datasets from multiple sources to generate Irrigation Performance Assessment (IPA) reports for any selected command area across India. The platform is highly interective where users can select the area of interest, season and data sources for Evapotranspitation and rainfall. There are more than 2000 irrigation commands ingested into the platform ready to analyse and can be filtered state-wise. The user can select the area of interest from these ingested schemes and the platform will provide with a detailed report on spatial assessments of land &amp; water resources for the selected scheme. The reports are generated in both pdf and web HTML formats (unique url) for a selected year and season (user-specified start and end month). The platform is entirely developed using open source libraries and database in a modular structure which makes it highly customizable and transferrable.</p>"},{"location":"#developed-by","title":"\ud83e\uddd1\u200d\ud83d\udcbb Developed By","text":"<p>Water Informatics Team \u2013 The World Bank</p>"},{"location":"#resource-persons","title":"\ud83d\udce9 Resource Persons","text":"<ul> <li>Dr. Poolad Karimi \u2013 pkarimi@worldbank.org</li> <li>Dr. Anju Gaur \u2013 agaur@worldbank.org</li> <li>Mr. Aman Chaudhary \u2013 achaudhary7@worldbank.org</li> </ul>"},{"location":"#copyright-usage","title":"\u00a9\ufe0f Copyright &amp; Usage","text":"<p>\u00a9 2025 The World Bank Group. All rights reserved.</p> <p>This platform and its associated documentation are proprietary assets of the World Bank and intended for internal use, training, and authorized collaborations only. Redistribution, reproduction, or reuse of this content or platform components without explicit permission is strictly prohibited.</p> <p>For inquiries regarding access, partnerships, or licensing, please contact the project team.</p>"},{"location":"datasets/","title":"\ud83d\udef0\ufe0f Download Datasets \u2013 Overview","text":"<p>This section provides access instructions and sources for downloading remote sensing datasets used in the EQIPA platform. Each dataset has its own dedicated page with download links, tools, and script examples.</p>"},{"location":"datasets/#available-datasets","title":"\ud83d\udce6 Available Datasets","text":"<ul> <li>IMD Gridded Precipitation (PCP)</li> <li>WaPOR v3 \u2013 Actual Evapotranspiration (ETa)</li> <li>WaPOR v3 \u2013 Biomass Production (TBP)</li> <li>NRSC LULC 250K Land Cover (LULC)</li> <li>AW3D30 Elevation Model</li> </ul>"},{"location":"datasets/elevation/","title":"Elevation (Digital surface model):","text":"<p>In this analysis, DEM data from the Japan Aerospace Exploration Agency (JAXA) were used to understand the topography of the region. The data is open access and free to use for any scientific studies. Data Source:  https://www.eorc.jaxa.jp/ALOS/en/aw3d30/index.htm</p>"},{"location":"datasets/elevation/#dataset-overview","title":"\ud83d\uddc2\ufe0f Dataset Overview","text":"<ul> <li>Source: JAXA</li> <li>Product: AW3D30</li> <li>Spatial Resolution: 30m</li> <li>Output Format Used in EQIPA: GeoTIFF</li> </ul>"},{"location":"datasets/eta/","title":"Actual Evapotranspiration","text":"<p>Evapotranspiration is the sum of the soil evaporation (E), canopy transpiration (T) and interception (I).  The sum of all three parameters i.e. the Actual Evapotranspiration and Interception (AETI) can be used to quantify the agricultural water consumption. For further information on the methodology read the WaPOR documentation available at: https://bitbucket.org/cioapps/wapor-et-look/wiki/Home</p>"},{"location":"datasets/eta/#dataset-overview","title":"\ud83d\uddc2\ufe0f Dataset Overview","text":"<ul> <li>Source: WaPOR L1 v3</li> <li>Period of Use: 2018\u20132023 crop years</li> <li>Spatial Resolution: 300m</li> <li>Temporal Resolution: Monthly</li> <li>Output Format Used in EQIPA: Monthly GeoTIFF</li> </ul>"},{"location":"datasets/eta/#data-processing-summary","title":"\ud83d\udccc Data Processing Summary","text":"<ol> <li>Monthly WaPOR L1 v3 AETI (300m) maps have been downloaded from WaPOR.</li> <li>Each monthly AETI raster have been multiplied by scale factor (0.1). See the scale factor for each WaPOR product here: https://data.apps.fao.org/wapor</li> <li>Annual AETI is computed for all crop years by aggregating monthly AETI values from June to May, covering crop years 2018-19 to 2022-23.</li> </ol>"},{"location":"datasets/eta/#python-script-download-monthly-aeti-wapor-v3","title":"\u2b07\ufe0f Python Script: Download Monthly AETI (WaPOR v3)","text":"<p>This script downloads monthly AETI GeoTIFFs from FAO's WaPOR v3 Google-hosted URLs.</p> <pre><code>import requests\nimport os\nfrom tqdm import tqdm\n\nfirstyear = 2018\nlastyear = 2024\n\n# Create a folder to store downloads (optional)\ndownload_folder = \"eta_wapor_v3_monthly\"\nos.makedirs(download_folder, exist_ok=True)\n\n\nfor year in range(firstyear, lastyear):\n    for month in range(1, 13):\n        # Format filename as WAPOR-3.L1-AETI-M.YYYY-MM.tif\n        filename = f\"WAPOR-3.L1-AETI-M.{year}-{month:02d}.tif\"\n        url = f\"https://gismgr.fao.org/DATA/WAPOR-3/MAPSET/L1-AETI-M/{filename}\"\n        print(f\"Downloading {filename} from {url} ...\")\n\n        try:\n            response = requests.get(url, stream=True)\n            response.raise_for_status()  # Raise an error for bad responses\n\n            # Get total file size from headers (if available)\n            total_size = int(response.headers.get('content-length', 0))\n\n            # Create a progress bar with tqdm\n            progress_bar = tqdm(total=total_size, unit='B', unit_scale=True, desc=filename)\n\n            output_path = os.path.join(download_folder, filename)\n            with open(output_path, \"wb\") as f:\n                for chunk in response.iter_content(chunk_size=8192):\n                    if chunk:\n                        f.write(chunk)\n                        progress_bar.update(len(chunk))\n            progress_bar.close()\n\n            # Optional: Check if the download completed correctly\n            if total_size != 0 and progress_bar.n != total_size:\n                print(f\"WARNING: Download size mismatch for {filename}\")\n            else:\n                print(f\"Downloaded {filename} successfully.\")\n        except requests.exceptions.RequestException as e:\n            print(f\"Failed to download {filename}: {e}\")\n\n</code></pre>"},{"location":"datasets/lulc/","title":"\ud83d\uddfa\ufe0f Land Use and Land Cover (LULC)","text":"<p>The Land Use and Land Cover (LULC) data used in the EQIPA tool is sourced from the National Remote Sensing Centre (NRSC), India. These maps provide a detailed spatial representation of how different land types are utilized across agricultural regions, enabling spatial analysis of irrigation performance.</p>"},{"location":"datasets/lulc/#dataset-overview","title":"\ud83d\uddc2\ufe0f Dataset Overview","text":"<ul> <li>Source: NRSC LULC Portal</li> <li>Provider: National Remote Sensing Centre (NRSC), ISRO</li> <li>Product: LULC at 1:250,000 scale (250K)</li> <li>Spatial Resolution: ~56 meters</li> <li>Temporal Resolution: Annual</li> <li>Period of Use: 2018\u20132023</li> <li>Output Format Used in EQIPA: Annual GeoTIFF</li> </ul>"},{"location":"datasets/lulc/#notes","title":"\ud83d\udccc Notes","text":"<ul> <li>The dataset is not directly downloadable online.</li> <li>Access to LULC maps from NRSC requires formal data request through their official portal or by contacting NRSC.</li> <li>For official data acquisition, visit: https://www.nrsc.gov.in/EO_LULC_Portals</li> </ul>"},{"location":"datasets/pcp_chirps/","title":"\ud83c\udf27\ufe0f Precipitation (IMD)","text":"<p>For estimating precipitation, the EQIPA tool uses high-resolution daily gridded rainfall data provided by the India Meteorological Department (IMD). The dataset spans a long period (1901\u20132022) and offers daily precipitation values across India at a 0.25\u00b0 x 0.25\u00b0 spatial resolution.</p>"},{"location":"datasets/pcp_chirps/#dataset-overview","title":"\ud83d\uddc2\ufe0f Dataset Overview","text":"<ul> <li>Source: IMD Daily Gridded Rainfall Data</li> <li>Format: NetCDF (<code>.nc</code>)</li> <li>Period of Use: 2018\u20132023 crop years</li> <li>Spatial Resolution: 0.25\u00b0 x 0.25\u00b0</li> <li>Temporal Resolution: Daily</li> <li>Output Format Used in EQIPA: Monthly GeoTIFF</li> </ul>"},{"location":"datasets/pcp_chirps/#data-processing-summary","title":"\ud83d\udccc Data Processing Summary","text":"<ol> <li>Daily NetCDF files are downloaded from IMD.</li> <li>Each file is converted to daily GeoTIFF rasters.</li> <li>These daily rasters are aggregated to produce monthly precipitation maps.</li> <li>Annual precipitation (per crop year) is computed by summing monthly rasters from June to May (e.g., June 2022 \u2013 May 2023).</li> </ol>"},{"location":"datasets/pcp_chirps/#convert-netcdf-to-daily-geotiffs","title":"\ud83d\udd04 Convert NetCDF to Daily GeoTIFFs","text":"<p>The following Python script converts daily precipitation values from IMD NetCDF files to GeoTIFF format using <code>xarray</code> and <code>rioxarray</code>.</p> <pre><code>import xarray as xr\nimport rioxarray\nimport os\n\nfirstyear = 2023\nlastyear = 2024\n\noutput_folder = \"pcp_imd_daily\"\nos.makedirs(output_folder, exist_ok=True)\n\ninput_folder = \"IMD_PCP_netcdf\"\n\nfor year in range(firstyear, lastyear + 1):\n    # Construct the full path to the netCDF file using f-string and os.path.join\n    input_nc = os.path.join(input_folder, f\"RF25_ind{year}_rfp25.nc\")\n\n    # Open the netCDF file\n    ds = xr.open_dataset(input_nc)\n    # print(ds.variables)\n\n    variable_name = \"RAINFALL\"\n    da = ds[variable_name]\n\n    # Loop over each day using the \"TIME\" coordinate\n    for day in da.coords[\"TIME\"]:\n        # Select the slice for the specific day\n        daily_data = da.sel(TIME=day)\n\n        # Write the CRS if not already present\n        daily_data.rio.write_crs(\"EPSG:4326\", inplace=True)\n\n        # Construct a filename based on the day (e.g., '2018-01-01')\n        day_str = str(day.values).split(\"T\")[0]\n        output_path = os.path.join(output_folder, f\"imd_pcp_{day_str}.tif\")\n\n        # Export the daily slice to a GeoTIFF file\n        daily_data.rio.to_raster(output_path)\n        print(f\"Saved {output_path}\")\n</code></pre>"},{"location":"datasets/pcp_chirps/#aggregate-daily-geotiffs-to-monthly","title":"\ud83d\udcc6 Aggregate Daily GeoTIFFs to Monthly","text":"<p>This script uses <code>rasterio</code> and <code>numpy</code> to aggregate daily rasters into monthly precipitation maps by summing values.</p> <pre><code>import os\nimport glob\nimport rasterio\nimport numpy as np\n\nfirstyear = 2000\nlastyear = 2024\n\noutput_folder = \"pcp_imd_monthly\"\nos.makedirs(output_folder, exist_ok=True)\n\ninput_folder = \"pcp_imd_daily\"\n\nfor year in range(firstyear, lastyear + 1):\n    for month in range(1, 13):\n        # Daily files are assumed to be named: imd_pcp_YYYY-MM-DD.tif\n        pattern = os.path.join(input_folder, f\"imd_pcp_{year}-{month:02d}-*.tif\")\n        daily_files = sorted(glob.glob(pattern))\n\n        if not daily_files:\n            print(f\"No daily files found for {year}-{month:02d}\")\n            continue\n\n        daily_arrays = []\n        meta = None\n        nodata_val = None\n\n        # Loop over daily files and read data as float32.\n        # Replace no-data values with np.nan for summing.\n        for daily_file in daily_files:\n            with rasterio.open(daily_file) as src:\n                data = src.read(1).astype(np.float32)\n                if meta is None:\n                    meta = src.meta.copy()\n                    nodata_val = src.nodata\n                    if nodata_val is None:\n                        # If nodata isn't defined, set a default value (e.g., -9999)\n                        nodata_val = -9999\n                        meta.update(nodata=nodata_val)\n                # Replace nodata with np.nan so it won't affect the sum\n                data[data == nodata_val] = np.nan\n                daily_arrays.append(data)\n\n        # Stack daily arrays along a new axis\n        stack = np.stack(daily_arrays, axis=0)\n        monthly_sum = np.nansum(stack, axis=0)\n        # Identify pixels that are no-data in all daily files\n        all_nan_mask = np.all(np.isnan(stack), axis=0)\n        monthly_sum[all_nan_mask] = nodata_val\n\n        # Update metadata: ensure data type and single band output\n        meta.update(dtype=rasterio.float32, count=1)\n        output_filename = os.path.join(output_folder, f\"imd_pcp_{year}_{month:02d}.tif\")\n\n        with rasterio.open(output_filename, 'w', **meta) as dst:\n            dst.write(monthly_sum, 1)\n\n        print(f\"Saved monthly raster: {output_filename}\")\n</code></pre> <p>\u2705 This process ensures consistent and analysis-ready raster datasets for use in EQIPA's irrigation performance reports.</p>"},{"location":"datasets/pcp_imd/","title":"\ud83c\udf27\ufe0f Precipitation (IMD)","text":"<p>For estimating precipitation, the EQIPA platform uses high-resolution daily gridded rainfall data provided by the India Meteorological Department (IMD). The dataset spans a long period (1901\u20132022) and offers daily precipitation values across India at a 0.25\u00b0 x 0.25\u00b0 spatial resolution.</p>"},{"location":"datasets/pcp_imd/#dataset-overview","title":"\ud83d\uddc2\ufe0f Dataset Overview","text":"<ul> <li>Source: IMD Daily Gridded Rainfall Data</li> <li>Format: NetCDF (<code>.nc</code>)</li> <li>Period of Use: 2018\u20132023 crop years</li> <li>Spatial Resolution: 0.25\u00b0 x 0.25\u00b0</li> <li>Temporal Resolution: Daily</li> <li>Output Format Used in EQIPA: Monthly GeoTIFF</li> </ul>"},{"location":"datasets/pcp_imd/#data-processing-summary","title":"\ud83d\udccc Data Processing Summary","text":"<ol> <li>Daily NetCDF files are downloaded from IMD.</li> <li>Each file is converted to daily GeoTIFF rasters.</li> <li>These daily rasters are aggregated to produce monthly precipitation maps.</li> <li>Annual precipitation (per crop year) is computed by summing monthly rasters from June to May (e.g., June 2022 \u2013 May 2023).</li> </ol>"},{"location":"datasets/pcp_imd/#convert-netcdf-to-daily-geotiffs","title":"\ud83d\udd04 Convert NetCDF to Daily GeoTIFFs","text":"<p>The following Python script converts daily precipitation values from IMD NetCDF files to GeoTIFF format using <code>xarray</code> and <code>rioxarray</code>.</p> <pre><code>import xarray as xr\nimport rioxarray\nimport os\n\nfirstyear = 2023\nlastyear = 2024\n\noutput_folder = \"pcp_imd_daily\"\nos.makedirs(output_folder, exist_ok=True)\n\ninput_folder = \"IMD_PCP_netcdf\"\n\nfor year in range(firstyear, lastyear + 1):\n    # Construct the full path to the netCDF file using f-string and os.path.join\n    input_nc = os.path.join(input_folder, f\"RF25_ind{year}_rfp25.nc\")\n\n    # Open the netCDF file\n    ds = xr.open_dataset(input_nc)\n    # print(ds.variables)\n\n    variable_name = \"RAINFALL\"\n    da = ds[variable_name]\n\n    # Loop over each day using the \"TIME\" coordinate\n    for day in da.coords[\"TIME\"]:\n        # Select the slice for the specific day\n        daily_data = da.sel(TIME=day)\n\n        # Write the CRS if not already present\n        daily_data.rio.write_crs(\"EPSG:4326\", inplace=True)\n\n        # Construct a filename based on the day (e.g., '2018-01-01')\n        day_str = str(day.values).split(\"T\")[0]\n        output_path = os.path.join(output_folder, f\"imd_pcp_{day_str}.tif\")\n\n        # Export the daily slice to a GeoTIFF file\n        daily_data.rio.to_raster(output_path)\n        print(f\"Saved {output_path}\")\n</code></pre>"},{"location":"datasets/pcp_imd/#aggregate-daily-geotiffs-to-monthly","title":"\ud83d\udcc6 Aggregate Daily GeoTIFFs to Monthly","text":"<p>This script uses <code>rasterio</code> and <code>numpy</code> to aggregate daily rasters into monthly precipitation maps by summing values.</p> <pre><code>import os\nimport glob\nimport rasterio\nimport numpy as np\n\nfirstyear = 2000\nlastyear = 2024\n\noutput_folder = \"pcp_imd_monthly\"\nos.makedirs(output_folder, exist_ok=True)\n\ninput_folder = \"pcp_imd_daily\"\n\nfor year in range(firstyear, lastyear + 1):\n    for month in range(1, 13):\n        # Daily files are assumed to be named: imd_pcp_YYYY-MM-DD.tif\n        pattern = os.path.join(input_folder, f\"imd_pcp_{year}-{month:02d}-*.tif\")\n        daily_files = sorted(glob.glob(pattern))\n\n        if not daily_files:\n            print(f\"No daily files found for {year}-{month:02d}\")\n            continue\n\n        daily_arrays = []\n        meta = None\n        nodata_val = None\n\n        # Loop over daily files and read data as float32.\n        # Replace no-data values with np.nan for summing.\n        for daily_file in daily_files:\n            with rasterio.open(daily_file) as src:\n                data = src.read(1).astype(np.float32)\n                if meta is None:\n                    meta = src.meta.copy()\n                    nodata_val = src.nodata\n                    if nodata_val is None:\n                        # If nodata isn't defined, set a default value (e.g., -9999)\n                        nodata_val = -9999\n                        meta.update(nodata=nodata_val)\n                # Replace nodata with np.nan so it won't affect the sum\n                data[data == nodata_val] = np.nan\n                daily_arrays.append(data)\n\n        # Stack daily arrays along a new axis\n        stack = np.stack(daily_arrays, axis=0)\n        monthly_sum = np.nansum(stack, axis=0)\n        # Identify pixels that are no-data in all daily files\n        all_nan_mask = np.all(np.isnan(stack), axis=0)\n        monthly_sum[all_nan_mask] = nodata_val\n\n        # Update metadata: ensure data type and single band output\n        meta.update(dtype=rasterio.float32, count=1)\n        output_filename = os.path.join(output_folder, f\"imd_pcp_{year}_{month:02d}.tif\")\n\n        with rasterio.open(output_filename, 'w', **meta) as dst:\n            dst.write(monthly_sum, 1)\n\n        print(f\"Saved monthly raster: {output_filename}\")\n</code></pre> <p>\u2705 This process ensures consistent and analysis-ready raster datasets for use in EQIPA's irrigation performance reports.</p>"},{"location":"datasets/tbp/","title":"Actual Evapotranspiration","text":"<p>Total Biomass Production (TBP) is defined as the sum of the above-ground dry matter produced for a given year. TBP is calculated from Net Primary Production (NPP). TBP is expressed in kgDM/ha/day, and has thus different biomass units compared to NPP, with 1 gC/m2/day (NPP) = 22.222 kgDM/ha/day (DMP).</p> <p>For further information on the methodology read the WaPOR documentation available at: https://bitbucket.org/cioapps/wapor-et-look/wiki/Home</p>"},{"location":"datasets/tbp/#dataset-overview","title":"\ud83d\uddc2\ufe0f Dataset Overview","text":"<ul> <li>Source: WaPOR L1 v3</li> <li>Period of Use: 2018\u20132023 crop years</li> <li>Spatial Resolution: 300m</li> <li>Temporal Resolution: Monthly</li> <li>Output Format Used in EQIPA: Monthly GeoTIFF</li> </ul>"},{"location":"datasets/tbp/#data-processing-summary","title":"\ud83d\udccc Data Processing Summary","text":"<ol> <li>Monthly WaPOR L1 v3 NPP (300m) maps have been downloaded from WaPOR.</li> <li>EMonthly TBP maps are calculated as = Monthly NPP \u00d7 Scale Factor (0.001) \u00d7 Unit Conversion Factor (22.222). See the scale factor for each WaPOR product here: https://data.apps.fao.org/wapor</li> <li>Annual TBP maps is computed for all crop years by aggregating monthly TBP maps from June to May, covering crop years 2018-19 to 2022-23.</li> </ol>"},{"location":"datasets/tbp/#python-script-download-monthly-npp-wapor-v3","title":"\u2b07\ufe0f Python Script: Download Monthly NPP (WaPOR v3)","text":"<p>This script downloads monthly NPP GeoTIFFs from FAO's WaPOR v3 Google-hosted URLs.</p> <pre><code>import requests\nimport os\nfrom tqdm import tqdm\n\nfirstyear = 2018\nlastyear = 2024\n\n# Create a folder to store downloads (optional)\ndownload_folder = \"npp_wapor_v3_monthly\"\nos.makedirs(download_folder, exist_ok=True)\n\n\nfor year in range(firstyear, lastyear):\n    for month in range(1, 13):\n\n        filename = f\"WAPOR-3.L1-NPP-M.{year}-{month:02d}.tif\"\n        url = f\"https://gismgr.fao.org/DATA/WAPOR-3/MAPSET/L1-NPP-M/{filename}\"\n        print(f\"Downloading {filename} from {url} ...\")\n\n        try:\n            response = requests.get(url, stream=True)\n            response.raise_for_status()  # Raise an error for bad responses\n\n            # Get total file size from headers (if available)\n            total_size = int(response.headers.get('content-length', 0))\n\n            # Create a progress bar with tqdm\n            progress_bar = tqdm(total=total_size, unit='B', unit_scale=True, desc=filename)\n\n            output_path = os.path.join(download_folder, filename)\n            with open(output_path, \"wb\") as f:\n                for chunk in response.iter_content(chunk_size=8192):\n                    if chunk:\n                        f.write(chunk)\n                        progress_bar.update(len(chunk))\n            progress_bar.close()\n\n            # Optional: Check if the download completed correctly\n            if total_size != 0 and progress_bar.n != total_size:\n                print(f\"WARNING: Download size mismatch for {filename}\")\n            else:\n                print(f\"Downloaded {filename} successfully.\")\n        except requests.exceptions.RequestException as e:\n            print(f\"Failed to download {filename}: {e}\")\n\n\n\n\n\n</code></pre>"},{"location":"tool-setup/apache/","title":"\ud83c\udf10 Apache Configuration","text":"<p>This section explains how to configure Apache to serve the EQIPA Django project using uWSGI and enable SSL using Let's Encrypt via Certbot.</p>"},{"location":"tool-setup/apache/#step-1-copy-apache-virtual-host-configuration","title":"\ud83d\udcdd Step 1: Copy Apache Virtual Host Configuration","text":"<p>Copy the example configuration to the Apache sites-available directory:</p> <pre><code>sudo cp ipa_india/template_apache.conf /etc/apache2/sites-available/ipa_india.conf\n</code></pre> <p>Make sure to update paths in the config to match your project directory.</p>"},{"location":"tool-setup/apache/#step-2-enable-required-apache-modules","title":"\ud83d\udd0c Step 2: Enable Required Apache Modules","text":"<pre><code>sudo a2enmod uwsgi\nsudo a2enmod ssl\n</code></pre>"},{"location":"tool-setup/apache/#step-3-enable-the-site","title":"\ud83d\udd27 Step 3: Enable the Site","text":"<pre><code>sudo a2ensite ipa_india.conf\n</code></pre> <p>Restart Apache to apply changes:</p> <pre><code>sudo systemctl reload apache2\nsudo systemctl restart apache2\n</code></pre>"},{"location":"tool-setup/apache/#verify-apache-configuration","title":"\u2705 Verify Apache Configuration","text":"<pre><code>sudo apachectl configtest\n</code></pre> <p>You should see: <code>Syntax OK</code></p>"},{"location":"tool-setup/apache/#step-4-enable-ssl-with-certbot","title":"\ud83d\udee1\ufe0f Step 4: Enable SSL with Certbot","text":"<p>Install Certbot:</p> <pre><code>sudo apt install certbot python3-certbot-apache\n</code></pre> <p>Enable HTTPS with your domain:</p> <pre><code>sudo certbot --apache -d ipa.waterinag.org\n</code></pre> <p>You can enable multiple domains if needed:</p> <pre><code>sudo certbot --apache -d ipa.waterinag.org -d eqipa.waterinag.org\n</code></pre>"},{"location":"tool-setup/apache/#apache-site-commands-summary","title":"\ud83d\udcc2 Apache Site Commands Summary","text":""},{"location":"tool-setup/apache/#enable-site","title":"Enable site","text":"<pre><code>sudo a2ensite ipa.waterinag.org.conf\n</code></pre>"},{"location":"tool-setup/apache/#disable-site","title":"Disable site","text":"<pre><code>sudo a2dissite ipa.waterinag.org.conf\n</code></pre>"},{"location":"tool-setup/apache/#list-enabled-sites","title":"List enabled sites","text":"<pre><code>ls -l /etc/apache2/sites-enabled\n</code></pre>"},{"location":"tool-setup/apache/#logs-and-troubleshooting","title":"\ud83d\udd0e Logs and Troubleshooting","text":""},{"location":"tool-setup/apache/#view-apache-error-log","title":"View Apache error log","text":"<pre><code>sudo tail -f /var/log/apache2/ipa_india_error.log\n</code></pre>"},{"location":"tool-setup/apache/#check-uwsgi-log","title":"Check uWSGI log","text":"<pre><code>tail -f /home/aman/ipa_india/webapp/ipa_india/log/ipa_india.log\n</code></pre> <p>Ensure Apache's config is pointing to the correct uWSGI socket and the socket file has proper read/write permissions.</p> <p>\u2705 Apache is now configured and serving your EQIPA application securely over HTTPS!</p>"},{"location":"tool-setup/deployment/","title":"\ud83d\ude80 Deployment in Production","text":"<p>This guide covers how to deploy the EQIPA Django app to a production server using Celery, uWSGI, and Apache2.</p>"},{"location":"tool-setup/deployment/#celery-worker-as-a-systemd-service","title":"\ud83e\uddf5 Celery Worker as a Systemd Service","text":"<p>Celery is used to handle background tasks such as report generation.</p>"},{"location":"tool-setup/deployment/#step-1-create-pid-directory","title":"\ud83d\udcc1 Step 1: Create PID Directory","text":"<pre><code>sudo mkdir /var/run/celery/\nsudo chown -R $USER:$USER /var/run/celery/\n</code></pre>"},{"location":"tool-setup/deployment/#step-2-add-celery-service-to-systemd","title":"\ud83d\udd17 Step 2: Add Celery Service to Systemd","text":"<pre><code>sudo ln -s /home/aman/ipa_india/webapp/ipa_india/celery_ipa_india.service /etc/systemd/system\n</code></pre> <p>Make sure to update paths if your project is located elsewhere.</p>"},{"location":"tool-setup/deployment/#step-3-reload-and-enable-service","title":"\u2699\ufe0f Step 3: Reload and Enable Service","text":"<pre><code>sudo systemctl daemon-reload\nsudo systemctl enable celery_ipa_india.service\nsudo systemctl start celery_ipa_india.service\n</code></pre>"},{"location":"tool-setup/deployment/#check-celery-logs","title":"\ud83d\udcca Check Celery Logs","text":"<pre><code>tail -f /home/aman/ipa_india/webapp/ipa_india/log/celery/worker1.log\n</code></pre>"},{"location":"tool-setup/deployment/#uwsgi-setup","title":"\ud83c\udf00 uWSGI Setup","text":""},{"location":"tool-setup/deployment/#run-django-app-via-uwsgi","title":"\u25b6\ufe0f Run Django App via uWSGI","text":"<p>Ensure your virtual environment is activated, then run:</p> <pre><code>uwsgi --ini ipa_india.ini\n</code></pre> <p>This will launch the Django application using your <code>.ini</code> configuration.</p>"},{"location":"tool-setup/deployment/#summary-of-configuration-files","title":"\ud83d\udcdd Summary of Configuration Files","text":"<ul> <li><code>celery_ipa_india.service</code>: systemd unit file for Celery</li> <li><code>ipa_india.ini</code>: uWSGI configuration file</li> <li><code>template_apache.conf</code>: Apache virtual host config</li> </ul> <p>\u2705 Once both Celery and uWSGI are running, you're ready to link them to Apache2 (covered next in Apache Configuration).</p>"},{"location":"tool-setup/errors/","title":"\u2757 Common Errors &amp; Fixes","text":"<p>This page lists common issues encountered while setting up or deploying the EQIPA application, along with tested solutions.</p>"},{"location":"tool-setup/errors/#file-permission-errors","title":"\ud83d\udd10 File Permission Errors","text":""},{"location":"tool-setup/errors/#error","title":"Error","text":"<p>Logs show permission denied when accessing socket or log files.</p>"},{"location":"tool-setup/errors/#solution","title":"Solution","text":"<pre><code>sudo chown -R www-data:www-data /home/aman/ipa_india/webapp/ipa_india\nsudo chown -R aman:aman /home/aman/ipa_india/webapp/ipa_india/log/\nsudo chmod -R 755 /home/aman/ipa_india/webapp/ipa_india/log/\n</code></pre>"},{"location":"tool-setup/errors/#uwsgi-modifier-error","title":"\ud83c\udf00 uWSGI Modifier Error","text":""},{"location":"tool-setup/errors/#error-in-uwsgi-logs","title":"Error (in uWSGI logs)","text":"<pre><code>-- unavailable modifier requested: 0 --\n</code></pre>"},{"location":"tool-setup/errors/#solution_1","title":"Solution","text":"<pre><code>sudo killall -9 uwsgi\n\nsudo chown -R aman:aman /home/aman/ipa_india/webapp/ipa_india/\nsudo chmod 755 /home/aman/ipa_india/webapp/ipa_india/\n\nuwsgi --ini ipa_india.ini\n</code></pre>"},{"location":"tool-setup/errors/#postgresql-delete-constraint-error","title":"\ud83d\udce6 PostgreSQL Delete Constraint Error","text":""},{"location":"tool-setup/errors/#error_1","title":"Error","text":"<pre><code>ERROR:  update or delete on table \"area\" violates foreign key constraint ...\nDETAIL:  Key (id)=(X) is still referenced from table \"taskhistory\"\n</code></pre>"},{"location":"tool-setup/errors/#solution_2","title":"Solution","text":"<ol> <li>Delete dependent entries from <code>taskhistory</code>:</li> </ol> <pre><code>DELETE FROM taskhistory WHERE area_id = &lt;id&gt;;\n</code></pre> <ol> <li>Then delete from <code>area</code>:</li> </ol> <pre><code>DELETE FROM area WHERE name = 'target_area_name';\n</code></pre>"},{"location":"tool-setup/errors/#screen-issues-managing-background-sessions","title":"\ud83e\uddf5 Screen Issues (Managing Background Sessions)","text":""},{"location":"tool-setup/errors/#attach-to-a-running-screen","title":"Attach to a running screen","text":"<pre><code>screen -r 392898.django_server\n</code></pre>"},{"location":"tool-setup/errors/#detach-from-a-screen","title":"Detach from a screen","text":"<pre><code>Ctrl + A, then D\n</code></pre>"},{"location":"tool-setup/errors/#kill-a-screen-session","title":"Kill a screen session","text":"<pre><code>screen -S celery_worker -X quit\n</code></pre>"},{"location":"tool-setup/errors/#start-a-new-screen","title":"Start a new screen","text":"<pre><code>screen -S ipa_server\nscreen -S ipa_celery\n</code></pre>"},{"location":"tool-setup/errors/#monitoring-celery-logs","title":"\ud83d\udcc4 Monitoring Celery Logs","text":"<pre><code>tail -f /home/aman/ipa_india/webapp/ipa_india/log/celery/worker1.log\n\n# or all at once:\nfor file in /home/aman/ipa_india/webapp/ipa_india/log/celery/*.log; do\n    echo \"Checking $file\"\n    tail -n 20 $file\ndone\n</code></pre>"},{"location":"tool-setup/errors/#restarting-celery-and-uwsgi-after-code-changes","title":"\ud83e\uddfc Restarting Celery and uWSGI After Code Changes","text":"<pre><code># Reload systemd\nsudo systemctl daemon-reload\n\n# Stop &amp; start Celery\nsudo systemctl stop celery_ipa_india.service\nsudo systemctl start celery_ipa_india.service\nsudo systemctl status celery_ipa_india.service\n\n# Kill stray celery workers\nsudo pkill -9 -f 'celery worker'\nps aux | grep celery\n\n# Restart uWSGI\nsudo killall -9 uwsgi\nuwsgi --ini ipa_india.ini\n</code></pre> <p>\u2705 These solutions cover most of the deployment and runtime errors you may encounter.</p>"},{"location":"tool-setup/run-locally/","title":"\ud83d\udcbb Running App in Development Mode","text":"<p>This guide explains how to set up and run the EQIPA Django app in a development environment.</p>"},{"location":"tool-setup/run-locally/#step-1-copy-the-code-to-the-system","title":"\ud83d\udd27 Step 1: Copy the code to the system","text":""},{"location":"tool-setup/run-locally/#step-2-create-and-activate-a-virtual-environment","title":"\ud83d\udc0d Step 2: Create and Activate a Virtual Environment","text":"<p>Create a Python 3 virtual environment inside the <code>webapp</code> folder:</p> <pre><code>python3 -m venv venv\nsource venv/bin/activate\n</code></pre>"},{"location":"tool-setup/run-locally/#step-3-install-python-dependencies","title":"\ud83d\udce6 Step 3: Install Python Dependencies","text":"<p>Install all required packages using the <code>requirements.txt</code> file:</p> <pre><code>pip install -r requirements.txt\n</code></pre>"},{"location":"tool-setup/run-locally/#step-4-configure-django-settings","title":"\u2699\ufe0f Step 4: Configure Django Settings","text":"<p>Open <code>ipa_india/settings.py</code> and update the following:</p> <ul> <li><code>DATABASES</code> section \u2192 add username, password, and DB name</li> <li><code>GRASS_DB</code> path \u2192 e.g., <code>/mnt/mapdata/grassdata/ipa_india</code></li> </ul>"},{"location":"tool-setup/run-locally/#step-5-apply-migrations-collect-static-files","title":"\ud83d\udd04 Step 5: Apply Migrations &amp; Collect Static Files","text":"<p>Run the following commands to prepare your database and static files:</p> <pre><code>python manage.py makemigrations webapp\npython manage.py migrate\npython manage.py collectstatic\n</code></pre>"},{"location":"tool-setup/run-locally/#step-6-create-a-superuser","title":"\ud83d\udc64 Step 6: Create a Superuser","text":"<pre><code>python manage.py createsuperuser --username admin\n</code></pre> <p>Sample credentials:</p> <ul> <li>Username: <code>admin</code></li> <li>Email: <code>your-email@gmail.com</code></li> <li>Password: <code>your-pass</code></li> </ul>"},{"location":"tool-setup/run-locally/#step-7-test-local-server","title":"\ud83e\uddea Step 7: Test Local Server","text":"<p>Run the Django development server:</p> <pre><code>python manage.py runserver\n</code></pre> <p>To access from another device on the same network:</p> <pre><code>python manage.py runserver 0.0.0.0:8001\n</code></pre> <p>Now open your browser at:</p> <ul> <li>http://127.0.0.1:8000</li> <li>or your local IP, e.g.: <code>http://10.37.129.2:8001/</code></li> </ul>"},{"location":"tool-setup/run-locally/#admin-site-setup","title":"\ud83d\udda5\ufe0f Admin Site Setup","text":"<p>When running the server for the first time, visit:</p> <pre><code>http://127.0.0.1:8000/admin\n</code></pre> <p>Go to the \"Sites\" tab and update the domain to match your current host:</p> <ul> <li>For local testing: <code>127.0.0.1:8000</code></li> <li>For production: your domain name</li> </ul> <p>This ensures correct rendering of templates during report generation.</p> <p>\u2705 Your development server is now ready!</p>"},{"location":"tool-setup/system-setup/","title":"\ud83d\udee0\ufe0f System Setup","text":"<p>This section covers the complete setup of system dependencies and software required to run the EQIPA (Evapotranspiration-based Quick Irrigation Performance Assessment) application on a fresh Ubuntu server (tested on Ubuntu 20.04+).</p>"},{"location":"tool-setup/system-setup/#server-configuration","title":"Server Configuration","text":"<ul> <li>The EQIPA Tool requires a Linux-based Ubuntu server with AMD or intel processor minimum 8 cores, 5TB storage (considering future expansion of the database) and minimum 126 GB RAM for efficient performance.</li> <li>Full admin access to the server</li> </ul>"},{"location":"tool-setup/system-setup/#prerequisite-software","title":"Prerequisite Software","text":"<p>Ensure the following software is installed:</p> <ul> <li>Python 3.10</li> <li>PostgreSQL</li> <li>PostGIS</li> <li>GRASS GIS</li> <li>GDAL</li> <li>Redis</li> <li>Apache2</li> <li>Virtualenv</li> <li>Git</li> <li>Build tools &amp; Python development headers</li> </ul>"},{"location":"tool-setup/system-setup/#install-required-system-packages","title":"Install Required System Packages","text":"<pre><code>sudo apt-get update\n</code></pre> <pre><code>sudo apt-get install -y \\\n    git \\\n    gdal-bin \\\n    apache2 \\\n    postgis \\\n    redis-server \\\n    virtualenv \\\n    build-essential \\\n    python3-dev \\\n    libpq-dev \\\n    pango1.0-tools\n</code></pre>"},{"location":"tool-setup/system-setup/#install-postgresql-postgis","title":"Install PostgreSQL &amp; PostGIS","text":"<pre><code>sudo apt-get install -y postgresql postgresql-postgis\n</code></pre>"},{"location":"tool-setup/system-setup/#install-grass-gis","title":"Install GRASS GIS","text":"<pre><code>sudo add-apt-repository ppa:ubuntugis/ubuntugis-unstable\nsudo apt-get update\nsudo apt-get install -y grass grass-dev\n</code></pre>"},{"location":"tool-setup/system-setup/#create-a-grass-gis-location","title":"Create a GRASS GIS Location","text":"<pre><code>grass -c EPSG:4326 -e /mnt/mapdata/grassdata/ipa_india\n</code></pre> <p>Verify the mapset:</p> <pre><code>ls /mnt/mapdata/grassdata/ipa_india\n</code></pre> <p>Note: In <code>settings.py</code>, the value of <code>GRASS_DB</code> should be set as <code>/mnt/mapdata/grassdata</code></p>"},{"location":"tool-setup/system-setup/#configure-postgresql-user-and-database","title":"Configure PostgreSQL User and Database","text":"<p>Create a new PostgreSQL user:</p> <pre><code>sudo -u postgres createuser ipa_india\n</code></pre> <p>Login to PostgreSQL:</p> <pre><code>sudo -u postgres psql\n</code></pre> <p>Inside psql:</p> <pre><code>ALTER USER postgres PASSWORD 'ipa_india';\nALTER USER ipa_india PASSWORD 'ipa_india123';\nALTER USER ipa_india WITH SUPERUSER;\n\\q\n</code></pre> <p>Create the database and enable PostGIS:</p> <pre><code>createdb -U ipa_india -h localhost ipa_india\npsql -U ipa_india -h localhost ipa_india -c \"CREATE EXTENSION postgis\"\n</code></pre>"},{"location":"tool-setup/system-setup/#summary","title":"\u2705 Summary","text":"Component Version / Details OS Ubuntu 20.04 or later Python 3.10 PostgreSQL With PostGIS extension GRASS GIS Installed via ubuntugis-unstable PPA Redis Required for Celery queue Apache2 + uWSGI For production deployment <p>You're now ready to proceed with setting up the Django app. \u2192 Continue to Running App Locally</p>"}]}