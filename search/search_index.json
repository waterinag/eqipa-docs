{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"EQIPA \u2013 Evapotranspiration-based Quick Irrigation Performance Assessment Platform","text":""},{"location":"#overview","title":"\ud83c\udf10 Overview","text":"<p>The EQIPA (Evapotranspiration-based Quick Irrigation Performance Assessment) platform \u2013 eqipa.waterinag.org \u2013 is a powerful, web-based geospatial application built to evaluate the performance of irrigation schemes across India.</p> <p>EQIPA platform leverages open-source remote sensing datasets from multiple sources to generate Irrigation Performance Assessment (IPA) reports for any selected command area across India. The platform is highly interective where users can select the area of interest, season and data sources for Evapotranspitation and rainfall. There are more than 2000 irrigation commands ingested into the platform ready to analyse and can be filtered state-wise. The user can select the area of interest from these ingested schemes and the platform will provide with a detailed report on spatial assessments of land &amp; water resources for the selected scheme. The reports are generated in both pdf and web HTML formats (unique url) for a selected year and season (user-specified start and end month). The platform is entirely developed using open source libraries and database in a modular structure which makes it highly customizable and transferrable.</p>"},{"location":"#developed-by","title":"Developed By","text":"<p>Water Informatics Team \u2013 The World Bank</p>"},{"location":"#resource-persons","title":"Resource Persons","text":"<ul> <li>Dr. Poolad Karimi \u2013 pkarimi@worldbank.org</li> <li>Dr. Anju Gaur \u2013 agaur@worldbank.org</li> <li>Mr. Aman Chaudhary \u2013 achaudhary7@worldbank.org</li> </ul>"},{"location":"#copyright-usage","title":"\u00a9\ufe0f Copyright &amp; Usage","text":"<p>\u00a9 2025 The World Bank Group. All rights reserved.</p> <p>This platform and its associated documentation are proprietary assets of the World Bank and intended for internal use, training, and authorized collaborations only. Redistribution, reproduction, or reuse of this content or platform components without explicit permission is strictly prohibited.</p> <p>For inquiries regarding access, partnerships, or licensing, please contact the project team.</p>"},{"location":"datasets/elevation/","title":"Elevation (Digital surface model):","text":"<p>In this analysis, DEM data from the Japan Aerospace Exploration Agency (JAXA) were used to understand the topography of the region. The data is open access and free to use for any scientific studies.</p>"},{"location":"datasets/elevation/#dataset-overview","title":"Dataset Overview","text":"<ul> <li>Source: JAXA</li> <li>Product: AW3D30</li> <li>Spatial Resolution: 30m</li> <li>Output Format Used in EQIPA: GeoTIFF</li> </ul>"},{"location":"datasets/eta_ssebop/","title":"Evapotranspiration (SSEBop)","text":"<p>Actual ET (ETa) is produced using the operational Simplified Surface Energy Balance (SSEBop) model (Senay et al., 2012) for the period 2000 to present. The SSEBop setup is based on the Simplified Surface Energy Balance (SSEB) approach (Senay et al., 2011, 2013) with unique parameterization for operational applications. It combines ET fractions generated from remotely sensed MODIS thermal imagery, acquired every 8 days, with reference ET using a thermal index approach. The unique feature of the SSEBop parameterization is that it uses pre-defined, seasonally dynamic, boundary conditions that are unique to each pixel for the \u201chot/dry\u201d and \u201ccold/wet\u201d reference points. The original formulation of SSEB is based on the hot and cold pixel principles of SEBAL (Bastiaanssen et al., 1998) and METRIC (Allen et al., 2007) models.</p>"},{"location":"datasets/eta_ssebop/#dataset-overview","title":"Dataset Overview","text":"<ul> <li>Source: USGS</li> <li>Spatial Resolution: 1000m</li> <li>Temporal Resolution: Monthly and Annual</li> </ul>"},{"location":"datasets/eta_ssebop/#python-script-download-monthly-eta-ssebop","title":"\u2b07\ufe0f Python Script: Download Monthly ETa (SSEBop)","text":"<p>This script downloads monthly SSEBop ETa v6.1 GeoTIFFs.</p> <pre><code>import requests\nimport os\n\n\nfirstyear = 2000\nlastyear = 2012\n\n# Create a folder to store downloads (optional)\ndownload_folder = \"eta_ssebop_monthly\"\nos.makedirs(download_folder, exist_ok=True)\n\n\nfor year in range(firstyear,lastyear):\n    for month in range(1,13):\n        # Format filename as mYYYYmm.zip (e.g., m201202.zip)\n        filename = f\"m{year}{month:02d}.zip\"\n        url = f\"https://edcintl.cr.usgs.gov/downloads/sciweb1/shared/fews/web/global/monthly/etav61/downloads/monthly/{filename}\"\n        print(f\"Downloading {filename} from {url} ...\")\n\n        try:\n            response = requests.get(url, stream=True)\n            response.raise_for_status()  # raise an error for bad responses\n            output_path = os.path.join(download_folder, filename)\n            with open(output_path, \"wb\") as f:\n                for chunk in response.iter_content(chunk_size=8192):\n                    if chunk:\n                        f.write(chunk)\n            print(f\"Downloaded {filename} successfully.\")\n        except requests.exceptions.RequestException as e:\n            print(f\"Failed to download {filename}: {e}\")\n</code></pre>"},{"location":"datasets/eta_wapor/","title":"Actual Evapotranspiration","text":"<p>Evapotranspiration is the sum of the soil evaporation (E), canopy transpiration (T) and interception (I).  The sum of all three parameters i.e. the Actual Evapotranspiration and Interception (AETI) can be used to quantify the agricultural water consumption. For further information on the methodology read the WaPOR documentation available at: https://bitbucket.org/cioapps/wapor-et-look/wiki/Home</p>"},{"location":"datasets/eta_wapor/#dataset-overview","title":"Dataset Overview","text":"<ul> <li>Source: WaPOR L1 v3</li> <li>Period of Use: 2018\u20132023 crop years</li> <li>Spatial Resolution: 300m</li> <li>Temporal Resolution: Monthly</li> <li>Output Format Used in EQIPA: Monthly GeoTIFF</li> </ul>"},{"location":"datasets/eta_wapor/#data-processing-summary","title":"\ud83d\udccc Data Processing Summary","text":"<ol> <li>Monthly WaPOR L1 v3 AETI (300m) maps have been downloaded from WaPOR.</li> <li>Each monthly AETI raster have been multiplied by scale factor (0.1). See the scale factor for each WaPOR product here: https://data.apps.fao.org/wapor</li> <li>Annual AETI is computed for all crop years by aggregating monthly AETI values from June to May, covering crop years 2018-19 to 2022-23.</li> </ol>"},{"location":"datasets/eta_wapor/#python-script-download-monthly-aeti-wapor-v3","title":"\u2b07\ufe0f Python Script: Download Monthly AETI (WaPOR v3)","text":"<p>This script downloads monthly AETI GeoTIFFs from FAO's WaPOR v3 Google-hosted URLs.</p> <pre><code>import requests\nimport os\nfrom tqdm import tqdm\n\nfirstyear = 2023\nlastyear = 2024\n\n# Create a folder to store downloads (optional)\ndownload_folder = \"eta_wapor_v3_monthly\"\nos.makedirs(download_folder, exist_ok=True)\n\n\nfor year in range(firstyear, lastyear+1):\n    for month in range(1, 13):\n        # Format filename as WAPOR-3.L1-AETI-M.YYYY-MM.tif\n        filename = f\"WAPOR-3.L1-AETI-M.{year}-{month:02d}.tif\"\n        url = f\"https://gismgr.fao.org/DATA/WAPOR-3/MAPSET/L1-AETI-M/{filename}\"\n        print(f\"Downloading {filename} from {url} ...\")\n\n        try:\n            response = requests.get(url, stream=True)\n            response.raise_for_status()  # Raise an error for bad responses\n\n            # Get total file size from headers (if available)\n            total_size = int(response.headers.get('content-length', 0))\n\n            # Create a progress bar with tqdm\n            progress_bar = tqdm(total=total_size, unit='B', unit_scale=True, desc=filename)\n\n            output_path = os.path.join(download_folder, filename)\n            with open(output_path, \"wb\") as f:\n                for chunk in response.iter_content(chunk_size=8192):\n                    if chunk:\n                        f.write(chunk)\n                        progress_bar.update(len(chunk))\n            progress_bar.close()\n\n            # Optional: Check if the download completed correctly\n            if total_size != 0 and progress_bar.n != total_size:\n                print(f\"WARNING: Download size mismatch for {filename}\")\n            else:\n                print(f\"Downloaded {filename} successfully.\")\n        except requests.exceptions.RequestException as e:\n            print(f\"Failed to download {filename}: {e}\")\n</code></pre>"},{"location":"datasets/eta_wapor/#clip-global-rasters-to-india-boundary","title":"Clip Global Rasters to India Boundary","text":"<p>Once downloaded, use this script to clip the global raster to the India boundary using a boundary file.</p> <p>\ud83d\udcc1 Boundary file required: <code>assets/IndiaBoundary.geojson</code></p> <pre><code>import os\nimport numpy as np\nimport rasterio\nfrom osgeo import gdal\n\n# Set your paths\ninput_folder = \"eta_wapor_v3_monthly\"      \noutput_folder = \"eta_wapor_v3_monthly_ind\"   \ngeojson_boundary = \"IndiaBoundary.geojson\" \n\nfirstyear = 2023\nlastyear = 2024\nscale_factor=0.1\n\n# Create the output folder if it doesn't exist\nif not os.path.exists(output_folder):\n    os.makedirs(output_folder)\n\n# Loop through all files in the input folder\nfor year in range(firstyear, lastyear+1):\n    for month in range(1, 13):\n        # Build input filename: WAPOR-3.L1-AETI-M.YYYY-MM.tif\n        filename = f\"WAPOR-3.L1-AETI-M.{year}-{month:02d}.tif\"\n        input_path = os.path.join(input_folder, filename)\n        output_filename = f\"wapor_eta_m_{year}_{month:02d}.tif\"\n\n        # Temporary file for the clipped raster\n        temp_clip = os.path.join(output_folder, f\"temp_{output_filename}\")\n\n        # Clip the raster using GDAL.Warp with the GeoJSON boundary\n        warp_options = gdal.WarpOptions(cutlineDSName=geojson_boundary, cropToCutline=True,dstNodata=-9999)\n        gdal.Warp(destNameOrDestDS=temp_clip, srcDSOrSrcDSTab=input_path, options=warp_options)\n\n        # Define the output path for the scaled raster\n        output_path = os.path.join(output_folder, output_filename)\n\n        # Open the clipped raster with Rasterio\n        with rasterio.open(temp_clip) as src:\n            profile = src.profile \n            data = src.read(1)\n            nodata = src.nodata\n\n            data = np.where(data == src.nodata, -9999, data)  \n            scaled_data = np.where(data != -9999, data * scale_factor, -9999)  \n\n\n\n            # Update the profile for the output file\n            profile.update(\n                dtype=rasterio.float32, \n                nodata=nodata, \n                compress=\"LZW\"  # Apply LZW compression\n            )\n            if nodata is not None:\n                profile.update(nodata=nodata)\n\n            # Write the scaled data to a new file\n            with rasterio.open(output_path, \"w\", **profile) as dst:\n                dst.write(scaled_data.astype(rasterio.float32), 1)\n\n        # Optionally, remove the temporary clipped file\n        os.remove(temp_clip)\n\n        print(f\"Processed {filename}: clipped and scaled saved to {output_path}\")\n</code></pre>"},{"location":"datasets/lulc/","title":"Land Use and Land Cover (LULC)","text":"<p>The Land Use and Land Cover (LULC) data used in the EQIPA tool is sourced from the National Remote Sensing Centre (NRSC), India. These maps provide a detailed spatial representation of how different land types are utilized across agricultural regions, enabling spatial analysis of irrigation performance.</p>"},{"location":"datasets/lulc/#dataset-overview","title":"Dataset Overview","text":"<ul> <li>Source: NRSC LULC Portal</li> <li>Provider: National Remote Sensing Centre (NRSC), ISRO</li> <li>Product: LULC at 1:250,000 scale (250K)</li> <li>Spatial Resolution: ~56 meters</li> <li>Temporal Resolution: Annual</li> <li>Period of Use: 2018\u20132023</li> <li>Output Format Used in EQIPA: Annual GeoTIFF</li> </ul>"},{"location":"datasets/lulc/#notes","title":"\ud83d\udccc Notes","text":"<ul> <li>The dataset is not directly downloadable online.</li> <li>Access to LULC maps from NRSC requires formal data request through their official portal or by contacting NRSC.</li> <li>For official data acquisition, visit: https://www.nrsc.gov.in/EO_LULC_Portals</li> </ul>"},{"location":"datasets/overview/","title":"\ud83d\udef0\ufe0f Download Datasets \u2013 Overview","text":"<p>This section provides access instructions and sources for downloading remote sensing datasets used in the EQIPA platform. Each dataset has its own dedicated page with download links, tools, and script examples.</p>"},{"location":"datasets/overview/#datasets-used","title":"\ud83d\udce6 Datasets Used:","text":"<ul> <li>IMD Gridded Precipitation (PCP)</li> <li>WaPOR v3 \u2013 Actual Evapotranspiration (ETa)</li> <li>WaPOR v3 \u2013 Biomass Production (TBP)</li> <li>NRSC LULC 250K Land Cover (LULC)</li> <li>AW3D30 Elevation Model</li> </ul>"},{"location":"datasets/pcp_chirps/","title":"Precipitation (CHIRPS)","text":"<p>Since 1999, USGS and CHC scientists\u2014supported by funding from USAID, NASA, and NOAA\u2014have developed techniques for producing rainfall maps, especially in areas where surface data is sparse.</p>"},{"location":"datasets/pcp_chirps/#chirps-v30-overview","title":"CHIRPS v3.0 Overview","text":"<p>CHIRPS v3.0 is available for three domains: Global, Africa, and Latin America. Similar to CHIRPS v2.0, two products of CHIRPS v3.0 are available. A preliminary version and a final version. The preliminary version is produced at the end of every pentad with rapidly available Global Telecommunication System (GTS) data, while the final version \u2013 produced about two weeks after the end of the month \u2013 incorporates data from the Global Historical Climatology Network (GHCN), and the Global Summary of the Day (GSOD).</p> <p>CHIRPS v3.0 benefits from nearly four times more sources of gauge data compared to CHIRPS v2.0. This increased volume of observations significantly improves the spatial and temporal accuracy of rainfall estimates.</p> <ul> <li>Source: CHIRPS v3</li> </ul>"},{"location":"datasets/pcp_chirps/#download-monthly-chirps-pcp","title":"Download Monthly CHIRPS PCP","text":"<p>The following script downloads monthly CHIRPS v3.0 GeoTIFFs for a given year range:</p> <pre><code>import requests\nimport os\n\n\nfirstyear = 2022\nlastyear = 2023\n\n# Create a folder to store downloads\ndownload_folder = \"pcp_chirps_v3_monthly\"\nos.makedirs(download_folder, exist_ok=True)\n\n\nfor year in range(firstyear, lastyear + 1):\n    for month in range(1,13):\n        filename = f\"chirps-v3.0.{year}.{month:02d}.tif\"\n        url = f\"https://data.chc.ucsb.edu/products/CHIRPS/v3.0/monthly/global/tifs/{filename}\"\n        print(f\"Downloading {filename} from {url} ...\")\n\n        try:\n            response = requests.get(url, stream=True)\n            response.raise_for_status()  \n            output_path = os.path.join(download_folder, filename)\n            with open(output_path, \"wb\") as f:\n                for chunk in response.iter_content(chunk_size=8192):\n                    if chunk:\n                        f.write(chunk)\n            print(f\"Downloaded {filename} successfully.\")\n        except requests.exceptions.RequestException as e:\n            print(f\"Failed to download {filename}: {e}\")\n</code></pre>"},{"location":"datasets/pcp_chirps/#clip-chirps-data-to-india-boundary","title":"Clip CHIRPS Data to India Boundary","text":"<p>Once downloaded, use this script to clip the global raster to the India boundary using a GeoJSON file.</p> <p>\ud83d\udcc1 Boundary file required: <code>IndiaBoundary.geojson</code></p> <pre><code>import os\nfrom osgeo import gdal\n\n# Set your paths\ninput_folder = \"pcp_chirps_v3_monthly\"      \noutput_folder = \"pcp_chirps_ind_monthly\"   \ngeojson_boundary = \"IndiaBoundary.geojson\" \n\nfirstyear = 2022\nlastyear = 2023\n\n# Create the output folder if it doesn't exist\nif not os.path.exists(output_folder):\n    os.makedirs(output_folder)\n\n# Loop through all files in the input folder\nfor year in range(firstyear, lastyear+1):\n    for month in range(1, 13):\n        # Build input filename: WAPOR-3.L1-AETI-M.YYYY-MM.tif\n        filename = f\"chirps-v3.0.{year}.{month:02d}.tif\"\n        input_path = os.path.join(input_folder, filename)\n        output_filename = f\"chirps_pcp_m_{year}_{month:02d}.tif\"\n\n        output_path = os.path.join(output_folder, output_filename)\n\n        # Clip the raster using GDAL.Warp with the GeoJSON boundary\n        warp_options = gdal.WarpOptions(cutlineDSName=geojson_boundary, cropToCutline=True,dstNodata=-9999)\n        gdal.Warp(destNameOrDestDS=output_path, srcDSOrSrcDSTab=input_path, options=warp_options)\n\n        print(f\"Processed {filename}: clipped and scaled saved to {output_path}\")\n</code></pre>"},{"location":"datasets/pcp_imd/","title":"Precipitation (IMD)","text":"<p>For estimating precipitation, the EQIPA platform uses high-resolution daily gridded rainfall data provided by the India Meteorological Department (IMD). The dataset spans a long period (1901\u20132022) and offers daily precipitation values across India at a 0.25\u00b0 x 0.25\u00b0 spatial resolution.</p>"},{"location":"datasets/pcp_imd/#dataset-overview","title":"Dataset Overview","text":"<ul> <li>Source: IMD Daily Gridded Rainfall Data</li> <li>Format: NetCDF (<code>.nc</code>)</li> <li>Period of Use: 2018\u20132023 crop years</li> <li>Spatial Resolution: 0.25\u00b0 x 0.25\u00b0</li> <li>Temporal Resolution: Daily</li> <li>Output Format Used in EQIPA: Monthly GeoTIFF</li> </ul>"},{"location":"datasets/pcp_imd/#data-processing-summary","title":"\ud83d\udccc Data Processing Summary","text":"<ol> <li>Daily NetCDF files are downloaded from IMD.</li> <li>Each file is converted to daily GeoTIFF rasters.</li> <li>These daily rasters are aggregated to produce monthly precipitation maps.</li> <li>Annual precipitation (per crop year) is computed by summing monthly rasters from June to May (e.g., June 2022 \u2013 May 2023).</li> </ol>"},{"location":"datasets/pcp_imd/#download-annual-netcdf-from-imd","title":"Download Annual NetCDF from IMD","text":"<pre><code>import requests\nimport os\nimport re\nfrom tqdm import tqdm\n\n# Create a folder to store downloaded files\ndownload_folder = \"imd_netcdf_files\"\nos.makedirs(download_folder, exist_ok=True)\n\nfirstyear = 2023\nlastyear = 2024\n\n\n\n# Define the URL\nurl = \"https://www.imdpune.gov.in/cmpg/Griddata/RF25.php\"\n\n# Loop over the years for which you wish to download the netCDF files\nfor year in range(firstyear, lastyear + 1):  # Adjust the range as needed\n    payload = {\"RF25\": str(year)}\n    print(f\"Downloading netCDF file for year {year} ...\")\n\n    try:\n        # Post the request with the payload\n        response = requests.post(url, data=payload, stream=True)\n        response.raise_for_status()  # Raise an error for bad responses\n\n        # Determine filename (using a default if not provided in headers)\n        filename = f\"RF25_{year}.nc\"\n\n        # Get total file size from headers (if available) for the progress bar\n        total_size = int(response.headers.get('content-length', 0))\n        progress_bar = tqdm(total=total_size, unit='B', unit_scale=True, desc=filename)\n\n        output_path = os.path.join(download_folder, filename)\n        with open(output_path, \"wb\") as f:\n            for chunk in response.iter_content(chunk_size=8192):\n                if chunk:\n                    f.write(chunk)\n                    progress_bar.update(len(chunk))\n        progress_bar.close()\n\n        # Check if the download completed correctly\n        if total_size != 0 and progress_bar.n != total_size:\n            print(f\"WARNING: Download size mismatch for {filename}\")\n        else:\n            print(f\"Downloaded {filename} successfully.\")\n\n    except requests.RequestException as e:\n        print(f\"Failed to download netCDF file for year {year}: {e}\")\n</code></pre>"},{"location":"datasets/pcp_imd/#convert-netcdf-to-daily-geotiffs","title":"Convert NetCDF to Daily GeoTIFFs","text":"<p>The following Python script converts daily precipitation values from IMD NetCDF files to GeoTIFF format using <code>xarray</code> and <code>rioxarray</code>.</p> <pre><code>import xarray as xr\nimport rioxarray\nimport os\n\nfirstyear = 2023\nlastyear = 2024\n\ninput_folder = \"imd_netcdf_files\"\n\noutput_folder = \"pcp_imd_daily\"\nos.makedirs(output_folder, exist_ok=True)\n\n\nfor year in range(firstyear, lastyear + 1):\n    # Construct the full path to the netCDF file using f-string and os.path.join\n    input_nc = os.path.join(input_folder, f\"RF25_{year}.nc\")\n\n    # Open the netCDF file\n    ds = xr.open_dataset(input_nc)\n    # print(ds.variables)\n\n    variable_name = \"RAINFALL\"\n    da = ds[variable_name]\n\n    # Loop over each day using the \"TIME\" coordinate\n    for day in da.coords[\"TIME\"]:\n        # Select the slice for the specific day\n        daily_data = da.sel(TIME=day)\n\n        # Write the CRS if not already present\n        daily_data.rio.write_crs(\"EPSG:4326\", inplace=True)\n\n        # Construct a filename based on the day (e.g., '2018-01-01')\n        day_str = str(day.values).split(\"T\")[0]\n        output_path = os.path.join(output_folder, f\"imd_pcp_{day_str}.tif\")\n\n        # Export the daily slice to a GeoTIFF file\n        daily_data.rio.to_raster(output_path)\n        print(f\"Saved {output_path}\")\n</code></pre>"},{"location":"datasets/pcp_imd/#aggregate-daily-geotiffs-to-monthly","title":"Aggregate Daily GeoTIFFs to Monthly","text":"<p>This script uses <code>rasterio</code> and <code>numpy</code> to aggregate daily rasters into monthly precipitation maps by summing values.</p> <pre><code>import os\nimport glob\nimport rasterio\nimport numpy as np\n\nfirstyear = 2023\nlastyear = 2024\n\noutput_folder = \"pcp_imd_monthly\"\nos.makedirs(output_folder, exist_ok=True)\n\ninput_folder = \"pcp_imd_daily\"\n\nfor year in range(firstyear, lastyear + 1):\n    for month in range(1, 13):\n        # Daily files are assumed to be named: imd_pcp_YYYY-MM-DD.tif\n        pattern = os.path.join(input_folder, f\"imd_pcp_{year}-{month:02d}-*.tif\")\n        daily_files = sorted(glob.glob(pattern))\n\n        if not daily_files:\n            print(f\"No daily files found for {year}-{month:02d}\")\n            continue\n\n        daily_arrays = []\n        meta = None\n        nodata_val = None\n\n        # Loop over daily files and read data as float32.\n        # Replace no-data values with np.nan for summing.\n        for daily_file in daily_files:\n            with rasterio.open(daily_file) as src:\n                data = src.read(1).astype(np.float32)\n                if meta is None:\n                    meta = src.meta.copy()\n                    nodata_val = src.nodata\n                    if nodata_val is None:\n                        # If nodata isn't defined, set a default value (e.g., -9999)\n                        nodata_val = -9999\n                        meta.update(nodata=nodata_val)\n                # Replace nodata with np.nan so it won't affect the sum\n                data[data == nodata_val] = np.nan\n                daily_arrays.append(data)\n\n        # Stack daily arrays along a new axis\n        stack = np.stack(daily_arrays, axis=0)\n        monthly_sum = np.nansum(stack, axis=0)\n        # Identify pixels that are no-data in all daily files\n        all_nan_mask = np.all(np.isnan(stack), axis=0)\n        monthly_sum[all_nan_mask] = nodata_val\n\n        # Update metadata: ensure data type and single band output\n        meta.update(dtype=rasterio.float32, count=1)\n        output_filename = os.path.join(output_folder, f\"imd_pcp_{year}_{month:02d}.tif\")\n\n        with rasterio.open(output_filename, 'w', **meta) as dst:\n            dst.write(monthly_sum, 1)\n\n        print(f\"Saved monthly raster: {output_filename}\")\n</code></pre>"},{"location":"datasets/pcp_imd/#aggregate-monthly-geotiffs-to-annual","title":"Aggregate Monthly GeoTIFFs to Annual","text":"<pre><code>import os\nimport numpy as np\nimport rasterio\n\nfirstyear = 2023\nlastyear=2024\n\noutput_folder = \"pcp_imd_annual\"\nos.makedirs(output_folder, exist_ok=True)\n\ninput_folder = \"pcp_imd_monthly\"\n\nfor year in range(firstyear, lastyear):\n    # Annual period: June of current year to May of next year.\n    monthly_files = []\n\n    # June to December for the current year\n    for month in range(6, 13):\n        file_path = os.path.join(input_folder, f\"imd_pcp_{year}_{month:02d}.tif\")\n        monthly_files.append(file_path)\n\n    # January to May for the next year\n    for month in range(1, 6):\n        file_path = os.path.join(input_folder, f\"imd_pcp_{year+1}_{month:02d}.tif\")\n        monthly_files.append(file_path)\n\n\n    monthly_arrays = []\n    meta = None\n    nodata_val = None\n\n    for monthly_file in monthly_files:\n        with rasterio.open(monthly_file) as src:\n            data = src.read(1).astype(np.float32)\n            if meta is None:\n                meta = src.meta.copy()\n                nodata_val = src.nodata\n                if nodata_val is None:\n                    # If nodata is not defined, set a default value (e.g., -9999)\n                    nodata_val = -9999\n                    meta.update(nodata=nodata_val)\n            # Replace nodata values with np.nan so they don't affect the sum\n            data[data == nodata_val] = np.nan\n            monthly_arrays.append(data)\n\n    # Stack monthly arrays and compute the sum, ignoring NaNs\n    stack = np.stack(monthly_arrays, axis=0)\n    annual_sum = np.nansum(stack, axis=0)\n\n    # For pixels that are nan in every month, set back to nodata\n    all_nan_mask = np.all(np.isnan(stack), axis=0)\n    annual_sum[all_nan_mask] = nodata_val\n\n    meta.update(dtype=rasterio.float32, count=1)\n    output_filename = os.path.join(output_folder, f\"imd_pcp_{year}_{year+1}.tif\")\n    with rasterio.open(output_filename, 'w', **meta) as dst:\n        dst.write(annual_sum, 1)\n\n    print(f\"Saved annual raster: {output_filename}\")\n</code></pre>"},{"location":"datasets/setup/","title":"\u2699\ufe0f Environment Setup for Dataset Download","text":"<p>To download or process these dataset, you need to set up a Python environment with all required libraries.</p>"},{"location":"datasets/setup/#1-on-local-pc","title":"1: On Local PC","text":""},{"location":"datasets/setup/#1-install-conda-recommended","title":"1: Install Conda (Recommended)","text":"<p>Conda is a cross-platform environment manager that makes it easy to install geospatial libraries like GDAL.</p>"},{"location":"datasets/setup/#windows","title":"Windows","text":"<ol> <li>Download the Miniconda installer:    \ud83d\udc49 Miniconda Windows 64-bit</li> <li>Run the installer and choose \u201cAdd Miniconda to PATH\u201d during setup.</li> <li>After installation, open Anaconda Prompt or Command Prompt and test:</li> </ol> <pre><code>conda --version\n</code></pre>"},{"location":"datasets/setup/#macos-os","title":"MacOS OS","text":"<ol> <li> <p>Download the installer for macOS from:    \ud83d\udc49 Miniconda macOS</p> </li> <li> <p>Run the installer</p> </li> <li> <p>Restart terminal and verify:</p> </li> </ol> <pre><code>conda --version\n</code></pre>"},{"location":"datasets/setup/#2-create-a-conda-environment","title":"2: Create a Conda Environment","text":"<p>Conda makes it easy to isolate packages:</p> <pre><code>conda create --name eqipa_env python=3.10\nconda activate eqipa_env\n</code></pre>"},{"location":"datasets/setup/#3-install-gdal-and-geospatial-libraries","title":"3: Install GDAL and Geospatial Libraries","text":"<p>Use the <code>conda-forge</code> channel:</p> <pre><code>conda install -c conda-forge gdal libgdal-jp2openjpeg \n</code></pre> <p>Verify installation:</p> <pre><code>gdalinfo --version\n</code></pre> <p>Then install required Python libraries:</p> <pre><code>pip install pandas tqdm geopandas numpy xarray rioxarray rasterio netCDF4 requests\n</code></pre>"},{"location":"datasets/setup/#optional-save-environment-for-future-use","title":"Optional: Save Environment for Future Use","text":"<pre><code>conda env export &gt; eqipa_env.yml\n</code></pre> <p>Others can recreate the environment with:</p> <pre><code>conda env create -f eqipa_env.yml\n</code></pre>"},{"location":"datasets/setup/#on-ubuntu-without-conda","title":"On Ubuntu (Without Conda)","text":""},{"location":"datasets/setup/#1-install-gdal-system-packages","title":"1. Install GDAL system packages:","text":""},{"location":"datasets/setup/#sudo-apt-get-install-gdal-bin-libgdal-dev-libspatialindex-dev","title":"<pre><code>sudo apt-get install gdal-bin libgdal-dev libspatialindex-dev\n</code></pre>","text":""},{"location":"datasets/setup/#2-create-and-activate-a-python-virtual-environment","title":"2. Create and Activate a Python Virtual Environment","text":"<pre><code>python3 -m venv venv\nsource venv/bin/activate\n</code></pre>"},{"location":"datasets/setup/#3-install-required-python-libraries","title":"3. Install Required Python Libraries","text":"<pre><code>pip install pandas tqdm geopandas numpy xarray rioxarray rasterio netCDF4\n</code></pre>"},{"location":"datasets/setup/#4-recommended-requirementstxt","title":"4. Recommended <code>requirements.txt</code>","text":"<p>You can create a <code>requirements.txt</code> for reuse:</p> <pre><code>pandas\ntqdm\ngeopandas\nnumpy\nxarray\nrioxarray\nrasterio\nnetCDF4\n</code></pre> <p>Install with:</p> <pre><code>pip install -r requirements.txt\n</code></pre>"},{"location":"datasets/setup/#next-step","title":"\u2705 Next Step","text":"<p>Once the environment is set up, proceed to the dataset you want to download.</p>"},{"location":"datasets/tbp_wapor/","title":"Actual Evapotranspiration","text":"<p>Total Biomass Production (TBP) is defined as the sum of the above-ground dry matter produced for a given year. TBP is calculated from Net Primary Production (NPP). TBP is expressed in kgDM/ha/day, and has thus different biomass units compared to NPP, with 1 gC/m2/day (NPP) = 22.222 kgDM/ha/day (DMP).</p> <p>For further information on the methodology read the WaPOR documentation available at: https://bitbucket.org/cioapps/wapor-et-look/wiki/Home</p>"},{"location":"datasets/tbp_wapor/#dataset-overview","title":"Dataset Overview","text":"<ul> <li>Source: WaPOR L1 v3</li> <li>Period of Use: 2018\u20132023 crop years</li> <li>Spatial Resolution: 300m</li> <li>Temporal Resolution: Monthly</li> <li>Output Format Used in EQIPA: Monthly GeoTIFF</li> </ul>"},{"location":"datasets/tbp_wapor/#data-processing-summary","title":"\ud83d\udccc Data Processing Summary","text":"<ol> <li>Monthly WaPOR L1 v3 NPP (300m) maps have been downloaded from WaPOR.</li> <li>EMonthly TBP maps are calculated as = Monthly NPP \u00d7 Scale Factor (0.001) \u00d7 Unit Conversion Factor (22.222). See the scale factor for each WaPOR product here: https://data.apps.fao.org/wapor</li> <li>Annual TBP maps is computed for all crop years by aggregating monthly TBP maps from June to May, covering crop years 2018-19 to 2022-23.</li> </ol>"},{"location":"datasets/tbp_wapor/#python-script-download-monthly-npp-wapor-v3","title":"\u2b07\ufe0f Python Script: Download Monthly NPP (WaPOR v3)","text":"<p>This script downloads monthly NPP GeoTIFFs from FAO's WaPOR v3 Google-hosted URLs.</p> <pre><code>import requests\nimport os\nfrom tqdm import tqdm\n\nfirstyear = 2023\nlastyear = 2024\n\n# Create a folder to store downloads (optional)\ndownload_folder = \"npp_wapor_v3_monthly\"\nos.makedirs(download_folder, exist_ok=True)\n\n\nfor year in range(firstyear, lastyear+1):\n    for month in range(1, 13):\n\n        filename = f\"WAPOR-3.L1-NPP-M.{year}-{month:02d}.tif\"\n        url = f\"https://gismgr.fao.org/DATA/WAPOR-3/MAPSET/L1-NPP-M/{filename}\"\n        print(f\"Downloading {filename} from {url} ...\")\n\n        try:\n            response = requests.get(url, stream=True)\n            response.raise_for_status()  # Raise an error for bad responses\n\n            # Get total file size from headers (if available)\n            total_size = int(response.headers.get('content-length', 0))\n\n            # Create a progress bar with tqdm\n            progress_bar = tqdm(total=total_size, unit='B', unit_scale=True, desc=filename)\n\n            output_path = os.path.join(download_folder, filename)\n            with open(output_path, \"wb\") as f:\n                for chunk in response.iter_content(chunk_size=8192):\n                    if chunk:\n                        f.write(chunk)\n                        progress_bar.update(len(chunk))\n            progress_bar.close()\n\n            # Optional: Check if the download completed correctly\n            if total_size != 0 and progress_bar.n != total_size:\n                print(f\"WARNING: Download size mismatch for {filename}\")\n            else:\n                print(f\"Downloaded {filename} successfully.\")\n        except requests.exceptions.RequestException as e:\n            print(f\"Failed to download {filename}: {e}\")\n</code></pre>"},{"location":"datasets/tbp_wapor/#clip-global-rasters-to-india-boundary","title":"Clip Global Rasters to India Boundary","text":"<p>Once downloaded, use this script to clip the global raster to the India boundary using a boundary file.</p> <p>\ud83d\udcc1 Boundary file required: <code>assets/IndiaBoundary.geojson</code></p> <pre><code>import os\nimport numpy as np\nimport rasterio\nfrom osgeo import gdal\n\n# Set your paths\ninput_folder = \"npp_wapor_v3_monthly\"      \noutput_folder = \"tbp_wapor_v3_monthly_ind\"   \ngeojson_boundary = \"IndiaBoundary.geojson\" \nscale_factor=0.001*22.222\nfirstyear = 2023\nlastyear = 2024\n\n# Create the output folder if it doesn't exist\nif not os.path.exists(output_folder):\n    os.makedirs(output_folder)\n\n# Loop through all files in the input folder\nfor year in range(firstyear, lastyear+1):\n    for month in range(1, 13):\n        output_filename = f\"wapor_tbp_m_{year}_{month:02d}.tif\"\n        temp_clip = os.path.join(output_folder, f\"temp_{output_filename}\")\n\n        # Clip and Download raster from Cloud\n        fileURL=f\"https://storage.googleapis.com/fao-gismgr-wapor-3-data/DATA/WAPOR-3/MAPSET/L2-NPP-M/WAPOR-3.L2-NPP-M.{year}-{month:02d}.tif\" \n        vrt_file=f\"WAPOR-3.L2-NPP-M.{year}-{month:02d}.vrt\"\n        gdal.BuildVRT(vrt_file, [f\"/vsicurl/{fileURL}\"])\n        gdal.Warp(temp_clip, vrt_file, cutlineDSName=geojson_boundary, cropToCutline=True, dstNodata=-9999)\n\n\n        # Clip raster from local\n        # filename = f\"WAPOR-3.L1-NPP-M.{year}-{month:02d}.tif\"\n        # input_path = os.path.join(input_folder, filename)\n        # warp_options = gdal.WarpOptions(cutlineDSName=geojson_boundary, cropToCutline=True,dstNodata=-9999)\n        # gdal.Warp(destNameOrDestDS=temp_clip, srcDSOrSrcDSTab=input_path, options=warp_options)\n\n\n\n        # Define the output path for the scaled raster\n        output_path = os.path.join(output_folder, output_filename)\n\n        # Open the clipped raster with Rasterio\n        with rasterio.open(temp_clip) as src:\n            profile = src.profile \n            data = src.read(1)\n            nodata = src.nodata\n\n            data = np.where(data == src.nodata, -9999, data)  \n            scaled_data = np.where(data != -9999, data * scale_factor, -9999)\n\n\n            # Update the profile for the output file\n            profile.update(\n                dtype=rasterio.float32, \n                nodata=nodata, \n                compress=\"LZW\"  # Apply LZW compression\n            )\n            if nodata is not None:\n                profile.update(nodata=nodata)\n\n            # Write the scaled data to a new file\n            with rasterio.open(output_path, \"w\", **profile) as dst:\n                dst.write(scaled_data.astype(rasterio.float32), 1)\n\n        # Optionally, remove the temporary clipped file\n        os.remove(temp_clip)\n\n        print(f\"Processed: clipped and scaled saved to {output_path}\")\n</code></pre>"},{"location":"geo-tools/gdal/","title":"\ud83c\udf0d GDAL (Geospatial Data Abstraction Library)","text":"<p>GDAL is an open-source library used in GIS (Geographic Information Systems) for reading, writing, and processing raster and vector geospatial data. It acts as a translator between different geospatial data formats and is widely used in software like QGIS, GRASS GIS, and many Python-based GIS workflows.</p>"},{"location":"geo-tools/gdal/#key-features","title":"Key Features","text":"<ul> <li>Supports 100+ raster formats (GeoTIFF, NetCDF, HDF, etc.) and vector formats (Shapefile, GeoJSON, KML, etc.)</li> <li>Powerful command-line tools (like gdalwarp, gdal_translate, ogr2ogr) for data conversion, reprojection, clipping, mosaicking, and more.</li> <li>Allows raster and vector data transformation, such as projection changes, resampling, and format conversion.</li> <li>Well-supported Python bindings for automation and integration with geospatial workflows.</li> <li>Extensively used in remote sensing, cartography, and spatial analysis.</li> </ul>"},{"location":"geo-tools/gdal/#learn-more","title":"\ud83d\udcda Learn More","text":"<ul> <li>GDAL Official Site</li> <li>Mastering GDAL Tools (Full Course)</li> </ul>"},{"location":"geo-tools/grass/","title":"\ud83c\udf3f GRASS GIS","text":"<p>The Geographic Resource Analysis Support System (GRASS) is a free and open source geographic information system (GIS). It is a powerful tool for managing, analyzing, and visualizing geospatial data, supporting raster, vector, and 3D modeling functionalities.</p>"},{"location":"geo-tools/grass/#key-features","title":"Key Features","text":"<ul> <li>This cross platform GIS runs on Windows, Mac, and Linux. </li> <li>Support for large datasets and high-resolution analysis</li> <li>Extensive scripting and automation capabilities</li> <li>Integration with other GIS tools and libraries like QGIS, GDAL, and R</li> </ul>"},{"location":"geo-tools/grass/#install-grass-gis","title":"Install GRASS GIS","text":"<p>Download the latest stable release from the official site:</p> <p>https://grass.osgeo.org/download/</p> <p>Choose the installer based on your operating system: - Standalone installer for Windows - <code>.dmg</code> or Homebrew package for MacOS - <code>apt</code>, <code>dnf</code>, or <code>snap</code> installation for Linux</p>"},{"location":"geo-tools/grass/#starting-grass-gis","title":"Starting GRASS GIS","text":"<p>When GRASS GIS launches, you must select a:</p> <ol> <li>GISDBASE (root project directory)</li> <li>Location (defines projection and extent)</li> <li>Mapset (stores individual data and settings)</li> </ol> <p>\ud83d\udcd8 Read the GRASS Quickstart Guide to understand this setup better.</p>"},{"location":"geo-tools/grass/#grass-gis-startup-screen","title":"GRASS GIS Startup Screen","text":""},{"location":"geo-tools/grass/#grass-gis-database-structure","title":"GRASS GIS Database Structure","text":"Component Description <code>GISDBASE</code> Root folder where all GRASS GIS data is stored. <code>LOCATION</code> Folder inside <code>GISDBASE</code> that defines a projection/CRS. All data in a LOCATION shares the same CRS. <code>MAPSET</code> Subdirectory of a LOCATION for storing actual data and managing workflows. <code>PERMANENT</code> Special mapset holding region settings and the default CRS. <code>WIND</code> File in each MAPSET that holds region resolution/extent."},{"location":"geo-tools/grass/#common-grass-gis-commands","title":"Common GRASS GIS Commands","text":"<p>Here are some frequently used GRASS GIS commands useful for working with rasters, vectors, regions, and exporting data.</p>"},{"location":"geo-tools/grass/#starting-and-managing-sessions","title":"Starting and Managing Sessions","text":"<pre><code># Create a new location from scratch\ngrass -c /mnt/mapdata/grassdata/new_location\n\n# Start GRASS in an existing location/mapset\ngrass /path/to/mapset/location\n\n# Create a new mapset inside an existing location\ng.mapset -c mapset=test location=ipa_india\n\n# Switch to a different mapset\ng.mapset mapset=pcp_mean_monthly\n\n# Add multiple mapsets to current search path\ng.mapsets mapset=nrsc_lulc,ind_annual_data operation=add\n</code></pre>"},{"location":"geo-tools/grass/#map-and-region-management","title":"Map and Region Management","text":"<pre><code># Check raster resolution and extent\nr.info -g pcpm_imd_2023_10\n\n# List all rasters and vectors\ng.list type=raster,vector\n\n# List all rasters and export to file\ng.list rast map=etg_etb_ind_monthly &gt;&gt; names.txt\n\n# Set region to match a raster or vector map\ng.region raster=your_raster_map\ng.region vector=your_vector_map\n\n# View current region settings\ng.region -p\n</code></pre>"},{"location":"geo-tools/grass/#import-data","title":"Import Data","text":"<pre><code># Import a raster file (GeoTIFF, NetCDF, etc.)\nr.import input=chirps_pcp.tif output=chirps_pcp\n\n# Import a vector file (GeoJSON, Shapefile, etc.)\nv.import input=IndiaBoundary.geojson output=india_boundary\n</code></pre>"},{"location":"geo-tools/grass/#raster-vector-info","title":"Raster &amp; Vector Info","text":"<pre><code># View metadata of a raster or vector\nr.info map=chirps_pcp\nv.info map=india_boundary\n</code></pre>"},{"location":"geo-tools/grass/#raster-operations","title":"Raster Operations","text":"<pre><code># Map algebra\nr.mapcalc expression=\"output_map = raster1 + raster2\"\n\n# Zonal statistics\nr.univar map=raster_map zones=vector_zones_map\n\n# Raster statistics summary\nr.stats -a input=raster_map_name\n\n# Merge rasters\nr.patch input=map1,map2 output=merged_map\n\n# Clip raster with current region\nr.clip input=your_raster output=clipped_raster\n\n# Resample raster\nr.resample input=your_raster output=resampled_raster\n\n# Apply raster mask\nr.mask raster=mask_map\n\n# Export raster to GeoTIFF\nr.out.gdal input=raster_map output=/path/output.tif format=GTiff\n</code></pre>"},{"location":"geo-tools/grass/#vector-operations","title":"Vector Operations","text":"<pre><code># Buffer vector geometry\nv.buffer input=your_vector output=buffered_vector distance=500\n\n# Convert vector to raster\nv.to.rast input=your_vector output=rasterized_vector use=cat\n\n# Convert raster to vector\nr.to.vect input=your_raster output=vector_map feature=area\n\n# Merge vectors\nv.patch input=vector1,vector2 output=merged_vector\n\n# Export vector to Shapefile\nv.out.ogr input=vector_map output=/path/output.shp format=ESRI_Shapefile\n</code></pre> <p>Tip: Always verify the region and CRS settings (<code>g.region -p</code>) before running any spatial operation.</p>"},{"location":"geo-tools/grass/#learn-more","title":"\ud83d\udcda Learn More","text":"<ul> <li>GRASS GIS Official Site</li> <li>GRASS GIS Documentation</li> <li>Python API for GRASS</li> <li>GRASS GIS Manuals</li> <li>GRASS GIS Tutorials</li> <li>Intro to GRASS GIS Workshop</li> </ul>"},{"location":"geo-tools/overview/","title":"\ud83e\uddf0 Geospatial Tools Used in EQIPA","text":"<p>EQIPA leverages several powerful open-source geospatial tools and libraries to enable efficient geospatial analysis, raster processing, and report generation.</p> <p>This section documents the core tools integrated into the backend of the platform:</p> <ul> <li>GRASS GIS</li> <li>GDAL (Geospatial Data Abstraction Library)</li> <li>Rasterio</li> <li>GeoPandas</li> <li>rioxarray</li> </ul>"},{"location":"tool-setup/apache/","title":"\ud83c\udf10 Apache Configuration","text":"<p>This section explains how to configure Apache to serve the EQIPA Django project using uWSGI and enable SSL using Let's Encrypt via Certbot.</p>"},{"location":"tool-setup/apache/#1-copy-apache-virtual-host-configuration","title":"1: Copy Apache Virtual Host Configuration","text":"<p>Copy the example configuration to the Apache sites-available directory:</p> <pre><code>sudo cp ipa_india/template_apache.conf /etc/apache2/sites-available/ipa_india.conf\n</code></pre> ipa_india.conf <pre><code>&lt;VirtualHost *:80&gt;\n    ServerName eqipa.waterinag.org\n\nAlias /static/ /home/aman/ipa_india/webapp/ipa_india/static/\n\n    &lt;Directory /home/aman/ipa_india/webapp/ipa_india/ipa_india&gt;\n        &lt;Files wsgi.py&gt;\n            Require all granted\n        &lt;/Files&gt;\n    &lt;/Directory&gt;\n\n&lt;Location /static&gt;\n                SetHandler none\n                Options -Indexes\n        &lt;/Location&gt;\n\n        &lt;Location /media&gt;\n                SetHandler none\n                Options -Indexes\n        &lt;/Location&gt;\n\n        Alias /media/ /home/aman/ipa_india/webapp/ipa_india/media/\n\n        Alias /static/ /home/aman/ipa_india/webapp/ipa_india/static/\n\n        &lt;Directory /home/aman/ipa_india/webapp/ipa_india/&gt;\n                Require all granted\n        &lt;/Directory&gt;\n\n        &lt;Directory /home/aman/ipa_india/webapp/ipa_india/static&gt;\n                Options FollowSymLinks\n                Order allow,deny\n                Allow from all\n        &lt;/Directory&gt;\n\n        &lt;Directory /home/aman/ipa_india/webapp/ipa_india/media&gt;\n                Options FollowSymLinks\n                Order allow,deny\n                Allow from all\n        &lt;/Directory&gt;\n\n    ProxyPass / unix:/home/aman/ipa_india/webapp/ipa_india/ipa_india.sock|uwsgi://localhost/\n    # Proxying the connection to uWSGI\n\n    # ProxyPass / unix:/home/aman/ipa_india/webapp/ipa_india/ipa_india.sock|uwsgi://localhost/\n    ErrorLog ${APACHE_LOG_DIR}/ipa_india_error.log\n    CustomLog ${APACHE_LOG_DIR}/ipa_india_access.log combined\n\n\n&lt;/VirtualHost&gt;\n</code></pre> <p>Make sure to update paths in the config to match your project directory.</p>"},{"location":"tool-setup/apache/#2-enable-required-apache-modules","title":"2: Enable Required Apache Modules","text":"<pre><code>sudo a2enmod uwsgi\nsudo a2enmod ssl\n</code></pre>"},{"location":"tool-setup/apache/#3-enable-the-site","title":"3: Enable the Site","text":"<pre><code>sudo a2ensite ipa_india.conf\n</code></pre> <p>Restart Apache to apply changes:</p> <pre><code>sudo systemctl reload apache2\nsudo systemctl restart apache2\n</code></pre>"},{"location":"tool-setup/apache/#verify-apache-configuration","title":"\u2705 Verify Apache Configuration","text":"<pre><code>sudo apachectl configtest\n</code></pre> <p>You should see: <code>Syntax OK</code></p>"},{"location":"tool-setup/apache/#4-enable-ssl-with-certbot","title":"4: Enable SSL with Certbot","text":"<p>Install Certbot:</p> <pre><code>sudo apt install certbot python3-certbot-apache\n</code></pre> <p>Enable HTTPS with your domain:</p> <pre><code>sudo certbot --apache -d eqipa.waterinag.org\n</code></pre> <p>Restart Apache to apply changes:</p> <pre><code>sudo systemctl restart apache2\n</code></pre>"},{"location":"tool-setup/apache/#apache-site-commands-summary","title":"\ud83d\udcc2 Apache Site Commands Summary","text":""},{"location":"tool-setup/apache/#enable-site","title":"Enable site","text":"<pre><code>sudo a2ensite eqipa.waterinag.org.conf\n</code></pre>"},{"location":"tool-setup/apache/#disable-site","title":"Disable site","text":"<pre><code>sudo a2dissite eqipa.waterinag.org.conf\n</code></pre>"},{"location":"tool-setup/apache/#list-enabled-sites","title":"List enabled sites","text":"<pre><code>ls -l /etc/apache2/sites-enabled\n</code></pre>"},{"location":"tool-setup/apache/#logs-and-troubleshooting","title":"\ud83d\udd0e Logs and Troubleshooting","text":""},{"location":"tool-setup/apache/#view-apache-error-log","title":"View Apache error log","text":"<pre><code>sudo tail -f /var/log/apache2/ipa_india_error.log\n</code></pre>"},{"location":"tool-setup/apache/#check-uwsgi-log","title":"Check uWSGI log","text":"<pre><code>tail -f /home/aman/ipa_india/webapp/ipa_india/log/ipa_india.log\n</code></pre> <p>Ensure Apache's config is pointing to the correct uWSGI socket and the socket file has proper read/write permissions.</p> <p>\u2705 Apache is now configured and serving your EQIPA application securely over HTTPS!</p>"},{"location":"tool-setup/deployment/","title":"\ud83d\ude80 Deployment in Production","text":"<p>This guide covers how to deploy the EQIPA Django app to a production server using Celery, uWSGI, and Apache2.</p>"},{"location":"tool-setup/deployment/#celery-worker-as-a-systemd-service","title":"Celery Worker as a Systemd Service","text":"<p>Celery is used to handle background tasks such as report generation.</p>"},{"location":"tool-setup/deployment/#1-create-pid-directory","title":"1: Create PID Directory","text":"<pre><code>sudo mkdir /var/run/celery/\nsudo chown -R $USER:$USER /var/run/celery/\n\nsudo chown -R aman:aman /var/run/celery/\n</code></pre>"},{"location":"tool-setup/deployment/#2-add-celery-service-to-systemd","title":"2: Add Celery Service to Systemd","text":"<pre><code>sudo ln -s /home/aman/ipa_india/webapp/ipa_india/celery_ipa_india.service /etc/systemd/system\n</code></pre> <p>Make sure to update paths if your project is located elsewhere. .. EnvironmentFile=-/home/aman/ipa_india/webapp/ipa_india/celery.conf .. WorkingDirectory=/home/aman/ipa_india/webapp/ipa_india/</p>"},{"location":"tool-setup/deployment/#3-reload-and-enable-service","title":"3: Reload and Enable Service","text":"<pre><code>sudo systemctl daemon-reload\nsudo systemctl enable celery_ipa_india.service\nsudo systemctl start celery_ipa_india.service\n</code></pre> celery_ipa_india.service <pre><code>[Unit]\nDescription=Celery Service for ipa_india app\nAfter=network.target\n\n[Service]\nType=forking\nUser=aman\nGroup=aman\nEnvironmentFile=/home/aman/ipa_india/webapp/ipa_india/celery.conf\nWorkingDirectory=/home/aman/ipa_india/webapp/ipa_india/\nExecStart=/bin/sh -c '${CELERY_BIN} -A ${CELERY_APP} multi start ${CELERYD_NODES} \\\n    --pidfile=${CELERYD_PID_FILE} --logfile=${CELERYD_LOG_FILE} \\\n    --loglevel=${CELERYD_LOG_LEVEL} ${CELERYD_OPTS}'\nExecStop=/bin/sh -c '${CELERY_BIN} multi stopwait ${CELERYD_NODES} \\\n    --pidfile=${CELERYD_PID_FILE} --loglevel=${CELERYD_LOG_LEVEL}'\nExecReload=/bin/sh -c '${CELERY_BIN} -A ${CELERY_APP} multi restart ${CELERYD_NODES} \\\n    --pidfile=${CELERYD_PID_FILE} --logfile=${CELERYD_LOG_FILE} \\\n    --loglevel=${CELERYD_LOG_LEVEL} ${CELERYD_OPTS}'\nRestart=always\n\n[Install]\nWantedBy=multi-user.target\n</code></pre>"},{"location":"tool-setup/deployment/#check-celery-logs","title":"Check Celery Logs","text":"<pre><code>tail -f /home/aman/ipa_india/webapp/ipa_india/log/celery/worker1.log\n</code></pre>"},{"location":"tool-setup/deployment/#uwsgi-setup","title":"uWSGI Setup","text":""},{"location":"tool-setup/deployment/#run-django-app-via-uwsgi","title":"Run Django App via uWSGI","text":"<p>Ensure your virtual environment is activated, then run:</p> <pre><code>uwsgi --ini ipa_india.ini\n</code></pre> ipa_india.ini <pre><code>[uwsgi]\nchdir           = /home/aman/ipa_india/webapp/ipa_india\nmodule          = ipa_india.wsgi\nhome            = /home/aman/ipa_india/webapp/venv\nenv = DJANGO_SETTINGS_MODULE=ipa_india.settings\nmaster          = true\nprocesses       = 5\nthreads = 2\nsocket          = /home/aman/ipa_india/webapp/ipa_india/ipa_india.sock\nchmod-socket    = 666\nvacuum          = true\ndaemonize = /home/aman/ipa_india/webapp/ipa_india/log/ipa_india.log\npost-buffering = True\nroute-run = harakiri:180\n</code></pre> <p>This will launch the Django application using your <code>.ini</code> configuration.</p>"},{"location":"tool-setup/deployment/#summary-of-configuration-files","title":"Summary of Configuration Files","text":"<ul> <li><code>celery_ipa_india.service</code>: systemd unit file for Celery</li> <li><code>ipa_india.ini</code>: uWSGI configuration file</li> <li><code>template_apache.conf</code>: Apache virtual host config</li> </ul> <p>\u2705 Once both Celery and uWSGI are running, you're ready to link them to Apache2 (covered next in Apache Configuration).</p>"},{"location":"tool-setup/errors/","title":"\u2757 Common Errors &amp; Fixes","text":"<p>This page lists common issues encountered while setting up or deploying the EQIPA application, along with tested solutions.</p>"},{"location":"tool-setup/errors/#file-permission-errors","title":"File Permission Errors","text":""},{"location":"tool-setup/errors/#error","title":"Error","text":"<p>Logs show permission denied when accessing socket or log files.</p>"},{"location":"tool-setup/errors/#solution","title":"Solution","text":"<pre><code>sudo chown -R www-data:www-data /home/aman/ipa_india/webapp/ipa_india\nsudo chown -R aman:aman /home/aman/ipa_india/webapp/ipa_india/log/\nsudo chmod -R 755 /home/aman/ipa_india/webapp/ipa_india/log/\n</code></pre>"},{"location":"tool-setup/errors/#uwsgi-modifier-error","title":"uWSGI Modifier Error","text":""},{"location":"tool-setup/errors/#error-in-uwsgi-logs","title":"Error (in uWSGI logs)","text":"<pre><code>-- unavailable modifier requested: 0 --\n</code></pre>"},{"location":"tool-setup/errors/#solution_1","title":"Solution","text":"<pre><code>sudo killall -9 uwsgi\n\nsudo chown -R aman:aman /home/aman/ipa_india/webapp/ipa_india/\nsudo chmod 755 /home/aman/ipa_india/webapp/ipa_india/\n\nuwsgi --ini ipa_india.ini\n</code></pre>"},{"location":"tool-setup/errors/#postgresql-delete-constraint-error","title":"PostgreSQL Delete Constraint Error","text":""},{"location":"tool-setup/errors/#error_1","title":"Error","text":"<pre><code>ERROR:  update or delete on table \"area\" violates foreign key constraint ...\nDETAIL:  Key (id)=(X) is still referenced from table \"taskhistory\"\n</code></pre>"},{"location":"tool-setup/errors/#solution_2","title":"Solution","text":"<ol> <li>Delete dependent entries from <code>taskhistory</code>:</li> </ol> <pre><code>DELETE FROM taskhistory WHERE area_id = &lt;id&gt;;\n</code></pre> <ol> <li>Then delete from <code>area</code>:</li> </ol> <pre><code>DELETE FROM area WHERE name = 'target_area_name';\n</code></pre>"},{"location":"tool-setup/errors/#screen-issues-managing-background-sessions","title":"Screen Issues (Managing Background Sessions)","text":""},{"location":"tool-setup/errors/#attach-to-a-running-screen","title":"Attach to a running screen","text":"<pre><code>screen -r 392898.django_server\n</code></pre>"},{"location":"tool-setup/errors/#detach-from-a-screen","title":"Detach from a screen","text":"<pre><code>Ctrl + A, then D\n</code></pre>"},{"location":"tool-setup/errors/#kill-a-screen-session","title":"Kill a screen session","text":"<pre><code>screen -S celery_worker -X quit\n</code></pre>"},{"location":"tool-setup/errors/#start-a-new-screen","title":"Start a new screen","text":"<pre><code>screen -S ipa_server\nscreen -S ipa_celery\n</code></pre>"},{"location":"tool-setup/errors/#monitoring-celery-logs","title":"Monitoring Celery Logs","text":"<pre><code>tail -f /home/aman/ipa_india/webapp/ipa_india/log/celery/worker1.log\n\n# or all at once:\nfor file in /home/aman/ipa_india/webapp/ipa_india/log/celery/*.log; do\n    echo \"Checking $file\"\n    tail -n 20 $file\ndone\n</code></pre>"},{"location":"tool-setup/errors/#restarting-celery-and-uwsgi-after-code-changes","title":"Restarting Celery and uWSGI After Code Changes","text":"<pre><code># Reload systemd\nsudo systemctl daemon-reload\n\n# Stop &amp; start Celery\nsudo systemctl stop celery_ipa_india.service\nsudo systemctl start celery_ipa_india.service\nsudo systemctl status celery_ipa_india.service\n\n# Kill stray celery workers\nsudo pkill -9 -f 'celery worker'\nps aux | grep celery\n\n# Restart uWSGI\nsudo killall -9 uwsgi\nuwsgi --ini ipa_india.ini\n</code></pre>"},{"location":"tool-setup/run-locally/","title":"\ud83d\udcbb Running App in Development Mode","text":"<p>This guide explains how to set up and run the EQIPA Django app in a development environment.</p>"},{"location":"tool-setup/run-locally/#1-copy-the-code-to-the-system","title":"1: Copy the code to the system","text":""},{"location":"tool-setup/run-locally/#2-create-and-activate-a-virtual-environment","title":"2: Create and Activate a Virtual Environment","text":"<p>Create a Python 3 virtual environment inside the <code>webapp</code> folder:</p> <pre><code>python3 -m venv venv\nsource venv/bin/activate\n</code></pre>"},{"location":"tool-setup/run-locally/#3-install-python-dependencies","title":"3: Install Python Dependencies","text":"<p>Install all required packages using the <code>requirements.txt</code> file:</p> <pre><code>pip install -r requirements.txt\n</code></pre>"},{"location":"tool-setup/run-locally/#4-configure-django-settings","title":"4: Configure Django Settings","text":"<p>Open <code>ipa_india/settings.py</code> and update the following:</p> <ul> <li><code>DATABASES</code> section \u2192 add username, password, and DB name</li> <li><code>GRASS_DB</code> path \u2192 e.g., <code>/mnt/mapdata/grassdata/ipa_india</code></li> </ul>"},{"location":"tool-setup/run-locally/#5-apply-migrations-collect-static-files","title":"5: Apply Migrations &amp; Collect Static Files","text":"<p>Run the following commands to prepare your database and static files:</p> <pre><code>python manage.py makemigrations webapp\npython manage.py migrate\npython manage.py collectstatic\n</code></pre>"},{"location":"tool-setup/run-locally/#6-create-a-superuser","title":"6: Create a Superuser","text":"<pre><code>python manage.py createsuperuser --username admin\n</code></pre> <p>Sample credentials:</p> <ul> <li>Username: <code>admin</code></li> <li>Email: <code>your-email@gmail.com</code></li> <li>Password: <code>your-pass</code></li> </ul>"},{"location":"tool-setup/run-locally/#7-test-local-server","title":"7: Test Local Server","text":"<p>Run the Django development server:</p> <pre><code>python manage.py runserver\n</code></pre> <p>To access from another device on the same network:</p> <pre><code>python manage.py runserver 0.0.0.0:8001\n</code></pre> <p>Now open your browser at:</p> <ul> <li>http://127.0.0.1:8000</li> <li>or your local IP, e.g.: <code>http://10.37.129.2:8001/</code></li> </ul> <p>Note</p> <p>Celery is used for handling long-running background tasks (like report generation). Start the worker using:</p> <pre><code>celery -A ipa_india worker -l INFO\n</code></pre> <p>To run Celery inside a <code>screen</code> session (optional):</p> <pre><code>screen -S ipa_celery\ncelery -A ipa_india worker -l INFO\n</code></pre> <p>To detach from the screen session:</p> <pre><code>Ctrl + A, then D\n</code></pre> <p>To reattach:</p> <pre><code>screen -r ipa_celery\n</code></pre> \ud83d\udce6 Screen <p>Learn more: How to Use Linux Screen</p> <p>Use <code>screen</code> to manage background processes like Celery or the Django dev server:</p> <p>\ud83d\udd0d Check running screens: <pre><code>screen -r\n</code></pre></p> <p>\ud83d\udd04 Attach to a screen: <pre><code>screen -r &lt;screen_name&gt;\n</code></pre></p> <p>\ud83d\udd19 Detach a screen: <pre><code>screen -d &lt;screen_name&gt;\n</code></pre></p> <p>\u274c Delete (terminate) a screen: <pre><code>screen -S &lt;screen_name&gt; -X quit\n</code></pre></p> <p>\ud83c\udd95 Start a new screen session: <pre><code>screen -S &lt;screen_name&gt;\n</code></pre></p>"},{"location":"tool-setup/run-locally/#admin-site-setup","title":"Admin Site Setup","text":"<p>When running the server for the first time, visit:</p> <pre><code>http://127.0.0.1:8000/admin\n</code></pre> <p>Go to the \"Sites\" tab and update the domain to match your current host:</p> <ul> <li>For local testing: <code>127.0.0.1:8000</code></li> <li>For production: your domain name</li> </ul> <p>This ensures correct rendering of templates during report generation.</p> <p>\u2705 Your development server is now ready!</p>"},{"location":"tool-setup/system-setup/","title":"\ud83d\udee0\ufe0f System Setup","text":"<p>This section covers the complete setup of system dependencies and software required to run the EQIPA (Evapotranspiration-based Quick Irrigation Performance Assessment) application on a fresh Ubuntu server.</p>"},{"location":"tool-setup/system-setup/#server-configuration","title":"Server Configuration","text":"<ul> <li>The EQIPA Tool requires a Linux-based Ubuntu server with AMD or intel processor minimum 8 cores, 5TB storage (considering future expansion of the database) and minimum 126 GB RAM for efficient performance.</li> <li>Full admin access to the server</li> </ul>"},{"location":"tool-setup/system-setup/#prerequisite-software","title":"Prerequisite Software","text":"<p>Ensure the following software is installed:</p> <ul> <li>Python 3.10</li> <li>PostgreSQL</li> <li>PostGIS</li> <li>GRASS GIS</li> <li>GDAL</li> <li>Redis</li> <li>Apache2</li> <li>Virtualenv</li> <li>Git</li> <li>Build tools &amp; Python development headers</li> </ul>"},{"location":"tool-setup/system-setup/#install-required-system-packages","title":"Install Required System Packages","text":"<pre><code>sudo apt-get update\n</code></pre> <pre><code>sudo apt-get install -y \\\n    git \\\n    gdal-bin \\\n    apache2 \\\n    postgis \\\n    redis-server \\\n    virtualenv \\\n    build-essential \\\n    python3-dev \\\n    libpq-dev \\\n    pango1.0-tools\n</code></pre>"},{"location":"tool-setup/system-setup/#install-postgresql-postgis","title":"Install PostgreSQL &amp; PostGIS","text":"<pre><code>sudo apt-get install -y postgresql postgresql-postgis\n</code></pre>"},{"location":"tool-setup/system-setup/#install-grass-gis","title":"Install GRASS GIS","text":"<pre><code>sudo add-apt-repository ppa:ubuntugis/ubuntugis-unstable\nsudo apt-get install -y grass grass-dev\n</code></pre>"},{"location":"tool-setup/system-setup/#create-a-grass-gis-location","title":"Create a GRASS GIS Location","text":"<pre><code>grass -c EPSG:4326 -e /mnt/mapdata/grassdata/ipa_india\n</code></pre> <p>Verify the mapset:</p> <pre><code>ls /mnt/mapdata/grassdata/ipa_india\n</code></pre> <p>Note: In <code>settings.py</code>, the value of <code>GRASS_DB</code> should be set as <code>/mnt/mapdata/grassdata</code></p>"},{"location":"tool-setup/system-setup/#configure-postgresql-user-and-database","title":"Configure PostgreSQL User and Database","text":"<p>Create a new PostgreSQL user:</p> <pre><code>sudo -u postgres createuser ipa_india\n</code></pre> <p>Login to PostgreSQL:</p> <pre><code>sudo -u postgres psql\n</code></pre> <p>Inside psql:</p> <pre><code>ALTER USER postgres PASSWORD 'ipa_india';\nALTER USER ipa_india PASSWORD 'ipa_india123';\nALTER USER ipa_india WITH SUPERUSER;\n\\q\n</code></pre> <p>Create the database and enable PostGIS:</p> <pre><code>createdb -U ipa_india -h localhost ipa_india\npsql -U ipa_india -h localhost ipa_india -c \"CREATE EXTENSION postgis\"\n</code></pre>"},{"location":"tool-setup/system-setup/#summary","title":"\u2705 Summary","text":"Component Version / Details OS Ubuntu 20.04 or later Python 3.10 PostgreSQL With PostGIS extension GRASS GIS Installed via ubuntugis-unstable PPA Redis Required for Celery queue Apache2 + uWSGI For production deployment <p>You're now ready to proceed with setting up the Django app. \u2192 Continue to Running App Locally</p>"}]}