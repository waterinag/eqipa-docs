{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"EQIPA \u2013 Evapotranspiration-based Quick Irrigation Performance Assessment Platform","text":""},{"location":"#overview","title":"\ud83c\udf10 Overview","text":"<p>The EQIPA (Evapotranspiration-based Quick Irrigation Performance Assessment) platform \u2013 eqipa.waterinag.org \u2013 is a powerful, web-based geospatial application built to evaluate the performance of irrigation schemes across India.</p> <p>EQIPA platform leverages open-source remote sensing datasets from multiple sources to generate Irrigation Performance Assessment (IPA) reports for any selected command area across India. The platform is highly interective where users can select the area of interest, season and data sources for Evapotranspitation and rainfall. There are more than 2000 irrigation commands ingested into the platform ready to analyse and can be filtered state-wise. The user can select the area of interest from these ingested schemes and the platform will provide with a detailed report on spatial assessments of land &amp; water resources for the selected scheme. The reports are generated in both pdf and web HTML formats (unique url) for a selected year and season (user-specified start and end month). The platform is entirely developed using open source libraries and database in a modular structure which makes it highly customizable and transferrable.</p>"},{"location":"#developed-by","title":"Developed By","text":"<p>Water Informatics Team \u2013 The World Bank</p>"},{"location":"#resource-persons","title":"Resource Persons","text":"<ul> <li>Dr. Poolad Karimi \u2013 pkarimi@worldbank.org</li> <li>Dr. Anju Gaur \u2013 agaur@worldbank.org</li> <li>Mr. Aman Chaudhary \u2013 achaudhary7@worldbank.org</li> </ul>"},{"location":"#copyright-usage","title":"\u00a9\ufe0f Copyright &amp; Usage","text":"<p>\u00a9 2025 The World Bank Group. All rights reserved.</p> <p>This platform and its associated documentation are proprietary assets of the World Bank and intended for internal use, training, and authorized collaborations only. Redistribution, reproduction, or reuse of this content or platform components without explicit permission is strictly prohibited.</p> <p>For inquiries regarding access, partnerships, or licensing, please contact the project team.</p>"},{"location":"datasets/elevation/","title":"Elevation (Digital surface model):","text":"<p>In this analysis, DEM data from the Japan Aerospace Exploration Agency (JAXA) were used to understand the topography of the region. The data is open access and free to use for any scientific studies.</p>"},{"location":"datasets/elevation/#dataset-overview","title":"Dataset Overview","text":"<ul> <li>Source: JAXA</li> <li>Product: AW3D30</li> <li>Spatial Resolution: 30m</li> <li>Output Format Used in EQIPA: GeoTIFF</li> </ul>"},{"location":"datasets/eta_ssebop/","title":"Evapotranspiration (SSEBop)","text":"<p>Actual ET (ETa) is produced using the operational Simplified Surface Energy Balance (SSEBop) model (Senay et al., 2012) for the period 2000 to present. The SSEBop setup is based on the Simplified Surface Energy Balance (SSEB) approach (Senay et al., 2011, 2013) with unique parameterization for operational applications. It combines ET fractions generated from remotely sensed MODIS thermal imagery, acquired every 8 days, with reference ET using a thermal index approach. The unique feature of the SSEBop parameterization is that it uses pre-defined, seasonally dynamic, boundary conditions that are unique to each pixel for the \u201chot/dry\u201d and \u201ccold/wet\u201d reference points. The original formulation of SSEB is based on the hot and cold pixel principles of SEBAL (Bastiaanssen et al., 1998) and METRIC (Allen et al., 2007) models.</p>"},{"location":"datasets/eta_ssebop/#dataset-overview","title":"Dataset Overview","text":"<ul> <li>Source: USGS</li> <li>Spatial Resolution: 1000m</li> <li>Temporal Resolution: Monthly and Annual</li> </ul>"},{"location":"datasets/eta_ssebop/#download-monthly-eta-ssebop","title":"Download Monthly ETa (SSEBop)","text":"<p>This script downloads monthly SSEBop ETa v6.1 GeoTIFFs.</p> <p>\ud83d\udcc1 India Boundary file: Link</p> <pre><code>import requests\nimport os\nimport zipfile\nfrom osgeo import gdal\n\n# Config\nfirstyear = 2023\nlastyear = 2024\noutput_folder = \"eta_ssebop_monthly\"\ngeojson_boundary = \"IndiaBoundary.geojson\"\n\n# Ensure folders exist\nos.makedirs(output_folder, exist_ok=True)\n\n\n# Loop through dates\nfor year in range(firstyear, lastyear + 1):\n    for month in range(1, 13):\n        filename = f\"m{year}{month:02d}.zip\"\n        output_filename = f\"ssebop_eta_m_{year}_{month:02d}.tif\"\n        url = f\"https://edcintl.cr.usgs.gov/downloads/sciweb1/shared/fews/web/global/monthly/etav61/downloads/monthly/{filename}\"\n        print(f\"Downloading {filename} ...\")\n\n        zip_path = os.path.join(output_folder, filename)\n\n        try:\n            # Download\n            response = requests.get(url, stream=True)\n            response.raise_for_status()\n            with open(zip_path, \"wb\") as f:\n                for chunk in response.iter_content(8192):\n                    f.write(chunk)\n            print(f\"Downloaded {filename}\")\n\n            # Unzip\n            with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n                zip_ref.extractall(output_folder)\n\n            # Find the GeoTIFF file (assume one tif per zip)\n            tif_files = [f for f in os.listdir(output_folder) if f.endswith(\".tif\") and f.startswith(f\"m{year}{month:02d}\")]\n            if not tif_files:\n                print(f\"No .tif found in {filename}\")\n                continue\n\n            tif_path = os.path.join(output_folder, tif_files[0])\n            clipped_path = os.path.join(output_folder, output_filename)\n\n            # Clip using gdal.Warp\n            gdal.Warp(\n                clipped_path,\n                tif_path,\n                cutlineDSName=geojson_boundary,\n                cropToCutline=True,\n                dstNodata=-9999\n            )\n            print(f\"Clipped and saved: {clipped_path}\")\n            os.remove(zip_path)\n            os.remove(tif_path)\n\n\n        except requests.exceptions.RequestException as e:\n            print(f\"Failed to download {filename}: {e}\")\n        except Exception as e:\n            print(f\"Error processing {filename}: {e}\")\n</code></pre>"},{"location":"datasets/eta_wapor%20copy/","title":"Actual Evapotranspiration","text":"<p>Evapotranspiration is the sum of the soil evaporation (E), canopy transpiration (T) and interception (I).  The sum of all three parameters i.e. the Actual Evapotranspiration and Interception (AETI) can be used to quantify the agricultural water consumption. For further information on the methodology read the WaPOR documentation available at: https://bitbucket.org/cioapps/wapor-et-look/wiki/Home</p>"},{"location":"datasets/eta_wapor%20copy/#dataset-overview","title":"Dataset Overview","text":"<ul> <li>Source: WaPOR L1 v3</li> <li>Period of Use: 2018\u20132023 crop years</li> <li>Spatial Resolution: 300m</li> <li>Temporal Resolution: Monthly</li> <li>Output Format Used in EQIPA: Monthly GeoTIFF</li> </ul>"},{"location":"datasets/eta_wapor%20copy/#data-processing-summary","title":"\ud83d\udccc Data Processing Summary","text":"<ol> <li>Monthly WaPOR L1 v3 AETI (300m) maps have been downloaded from WaPOR.</li> <li>Each monthly AETI raster have been multiplied by scale factor (0.1). See the scale factor for each WaPOR product here: https://data.apps.fao.org/wapor</li> <li>Annual AETI is computed for all crop years by aggregating monthly AETI values from June to May, covering crop years 2018-19 to 2022-23.</li> </ol>"},{"location":"datasets/eta_wapor%20copy/#python-script-download-monthly-global-aeti-wapor-v3","title":"\u2b07\ufe0f Python Script: Download Monthly Global AETI (WaPOR v3)","text":"<p>This script downloads Global monthly AETI GeoTIFFs from FAO's WaPOR v3 Google Cloud hosted URLs.</p> <pre><code># eta_wapor_v3.py\nimport requests\nimport os\nfrom tqdm import tqdm\n\nfirstyear = 2023\nlastyear = 2024\n\n# Create a folder to store downloads (optional)\ndownload_folder = \"eta_wapor_v3_monthly\"\nos.makedirs(download_folder, exist_ok=True)\n\n\nfor year in range(firstyear, lastyear+1):\n    for month in range(1, 13):\n        # Format filename as WAPOR-3.L1-AETI-M.YYYY-MM.tif\n        filename = f\"WAPOR-3.L1-AETI-M.{year}-{month:02d}.tif\"\n        output_path = os.path.join(download_folder, filename)\n\n        if os.path.exists(output_path):\n            print(f\"File already exists: {filename}, skipping...\")\n            continue\n\n        url = f\"https://gismgr.fao.org/DATA/WAPOR-3/MAPSET/L1-AETI-M/{filename}\"\n        print(f\"Downloading {filename} from {url} ...\")\n\n        try:\n            response = requests.get(url, stream=True)\n            response.raise_for_status()  # Raise an error for bad responses\n\n            # Get total file size from headers (if available)\n            total_size = int(response.headers.get('content-length', 0))\n\n            # Create a progress bar with tqdm\n            progress_bar = tqdm(total=total_size, unit='B', unit_scale=True, desc=filename)\n\n\n            with open(output_path, \"wb\") as f:\n                for chunk in response.iter_content(chunk_size=8192):\n                    if chunk:\n                        f.write(chunk)\n                        progress_bar.update(len(chunk))\n            progress_bar.close()\n\n            # Optional: Check if the download completed correctly\n            if total_size != 0 and progress_bar.n != total_size:\n                print(f\"WARNING: Download size mismatch for {filename}\")\n            else:\n                print(f\"Downloaded {filename} successfully.\")\n        except requests.exceptions.RequestException as e:\n            print(f\"Failed to download {filename}: {e}\")\n</code></pre>"},{"location":"datasets/eta_wapor%20copy/#clip-global-rasters-to-india-boundary","title":"Clip Global Rasters to India Boundary","text":"<p>This script clip global raster for India Boundary and apply scale factor</p> <p>\ud83d\udcc1 India Boundary file required: https://github.com/waterinag/eqipa-docs/blob/main/docs/assets/IndiaBoundary.geojson</p> <pre><code># eta_wapor_v3_clip.py\nimport os\nimport numpy as np\nimport rasterio\nfrom osgeo import gdal\n\n# Set your paths\ninput_folder = \"eta_wapor_v3_monthly\"      \noutput_folder = \"eta_wapor_v3_monthly_ind\"   \ngeojson_boundary = \"IndiaBoundary.geojson\" \n\nfirstyear = 2023\nlastyear = 2024\nscale_factor=0.1\n\n# Create the output folder if it doesn't exist\nif not os.path.exists(output_folder):\n    os.makedirs(output_folder)\n\n# Loop through all files in the input folder\nfor year in range(firstyear, lastyear+1):\n    for month in range(1, 13):\n        # Build input filename: WAPOR-3.L1-AETI-M.YYYY-MM.tif\n        filename = f\"WAPOR-3.L1-AETI-M.{year}-{month:02d}.tif\"\n        input_path = os.path.join(input_folder, filename)\n        output_filename = f\"wapor_eta_m_{year}_{month:02d}.tif\"\n\n        # Temporary file for the clipped raster\n        temp_clip = os.path.join(output_folder, f\"temp_{output_filename}\")\n\n        # Clip the raster using GDAL.Warp with the GeoJSON boundary\n        warp_options = gdal.WarpOptions(cutlineDSName=geojson_boundary, cropToCutline=True,dstNodata=-9999)\n        gdal.Warp(destNameOrDestDS=temp_clip, srcDSOrSrcDSTab=input_path, options=warp_options)\n\n        # Define the output path for the scaled raster\n        output_path = os.path.join(output_folder, output_filename)\n\n        # Open the clipped raster with Rasterio\n        with rasterio.open(temp_clip) as src:\n            profile = src.profile \n            data = src.read(1)\n            nodata = src.nodata\n\n            data = np.where(data == src.nodata, -9999, data)  \n            scaled_data = np.where(data != -9999, data * scale_factor, -9999)  \n\n\n\n            # Update the profile for the output file\n            profile.update(\n                dtype=rasterio.float32, \n                nodata=nodata, \n                compress=\"LZW\"  # Apply LZW compression\n            )\n            if nodata is not None:\n                profile.update(nodata=nodata)\n\n            # Write the scaled data to a new file\n            with rasterio.open(output_path, \"w\", **profile) as dst:\n                dst.write(scaled_data.astype(rasterio.float32), 1)\n\n        # Optionally, remove the temporary clipped file\n        os.remove(temp_clip)\n\n        print(f\"Processed {filename}: clipped and scaled saved to {output_path}\")\n</code></pre>"},{"location":"datasets/eta_wapor%20copy/#download-clipped-raster-and-apply-scale-factor","title":"Download Clipped Raster and Apply Scale Factor","text":"<p>This script downloads monthly WaPOR AETI raster files, clips them directly to the India boundary (using GDAL), and applies a scale factor.</p> <p>\ud83d\udcc1 India Boundary file required: https://github.com/waterinag/eqipa-docs/blob/main/docs/assets/IndiaBoundary.geojson</p> <pre><code>import os\nimport numpy as np\nimport rasterio\nfrom osgeo import gdal\n\nfirstyear = 2023\nlastyear = 2024\nscale_factor = 0.1\n\noutput_folder = \"eta_wapor_v3_monthly_ind\"\ngeojson_boundary = \"IndiaBoundary.geojson\"\nos.makedirs(output_folder, exist_ok=True)\n\nfor year in range(firstyear, lastyear + 1):\n    for month in range(1, 13):\n        filename = f\"WAPOR-3.L1-AETI-M.{year}-{month:02d}.tif\"\n        output_filename = f\"wapor_eta_m_{year}_{month:02d}.tif\"\n        output_path = os.path.join(output_folder, output_filename)\n\n        # Skip if already processed\n        if os.path.exists(output_path):\n            print(f\"\u2705 {output_filename} already exists, skipping...\")\n            continue\n\n        # Remote file URL via /vsicurl/\n        url = f\"https://gismgr.fao.org/DATA/WAPOR-3/MAPSET/L1-AETI-M/{filename}\"\n        vsicurl_url = f\"/vsicurl/{url}\"\n        temp_clip = os.path.join(output_folder, f\"temp_{output_filename}\")\n\n        print(f\"Downloading...{filename}\")\n\n        try:\n            warp_options = gdal.WarpOptions(\n                cutlineDSName=geojson_boundary,\n                cropToCutline=True,\n                dstNodata=-9999\n            )\n            gdal.Warp(destNameOrDestDS=temp_clip, srcDSOrSrcDSTab=vsicurl_url, options=warp_options)\n        except Exception as e:\n            print(f\"\u274c GDAL warp failed for {filename}: {e}\")\n            continue\n\n        # Scale and write output with compression\n        try:\n            with rasterio.open(temp_clip) as src:\n                profile = src.profile\n                data = src.read(1)\n                nodata = src.nodata\n\n                data = np.where(data == nodata, -9999, data)\n                scaled_data = np.where(data != -9999, data * scale_factor, -9999)\n\n                profile.update(\n                    dtype=rasterio.float32,\n                    nodata=-9999,\n                    compress=\"LZW\"\n                )\n\n                with rasterio.open(output_path, \"w\", **profile) as dst:\n                    dst.write(scaled_data.astype(rasterio.float32), 1)\n\n            os.remove(temp_clip)\n            print(f\"\u2705 Processed and saved: {output_filename}\")\n        except Exception as e:\n            print(f\"\u274c Failed to scale/write {filename}: {e}\")\n            if os.path.exists(temp_clip):\n                os.remove(temp_clip)\n</code></pre>"},{"location":"datasets/eta_wapor/","title":"Actual Evapotranspiration","text":"<p>Evapotranspiration is the sum of the soil evaporation (E), canopy transpiration (T) and interception (I).  The sum of all three parameters i.e. the Actual Evapotranspiration and Interception (AETI) can be used to quantify the agricultural water consumption. For further information on the methodology read the WaPOR documentation available at: https://bitbucket.org/cioapps/wapor-et-look/wiki/Home</p>"},{"location":"datasets/eta_wapor/#dataset-overview","title":"Dataset Overview","text":"<ul> <li>Source: WaPOR L1 v3</li> <li>Period of Use: 2018\u2013present</li> <li>Spatial Resolution: 300m</li> <li>Temporal Resolution: Monthly</li> <li>Output Format Used in EQIPA: Monthly GeoTIFF</li> </ul>"},{"location":"datasets/eta_wapor/#data-processing-summary","title":"\ud83d\udccc Data Processing Summary","text":"<ol> <li>Monthly WaPOR L1 v3 AETI (300m) maps have been downloaded from WaPOR.</li> <li>Each monthly AETI raster have been multiplied by scale factor (0.1). See the scale factor for each WaPOR product here: https://data.apps.fao.org/wapor</li> <li>Annual AETI is computed for all crop years by aggregating monthly AETI values from June to May, covering crop years 2018-19 to 2022-23.</li> </ol>"},{"location":"datasets/eta_wapor/#download-clipped-raster-and-apply-scale-factor","title":"Download Clipped Raster and Apply Scale Factor","text":"<p>This script downloads monthly WaPOR v3 AETI raster files from FAO's WaPOR Google Cloud Bucket URLs, clips them  to the India boundary (using GDAL), and applies a scale factor.</p> <p>\ud83d\udcc1 India Boundary file: Link</p> <pre><code>import os\nimport numpy as np\nimport rasterio\nfrom osgeo import gdal\n\nfirstyear = 2023\nlastyear = 2024\n\noutput_folder = \"eta_wapor_v3_monthly_ind\"\ngeojson_boundary = \"IndiaBoundary.geojson\"\nos.makedirs(output_folder, exist_ok=True)\n\nfor year in range(firstyear, lastyear + 1):\n    for month in range(1, 13):\n        filename = f\"WAPOR-3.L1-AETI-M.{year}-{month:02d}.tif\"\n        output_filename = f\"wapor_eta_m_{year}_{month:02d}.tif\"\n        output_path = os.path.join(output_folder, output_filename)\n\n        # Skip if already processed\n        if os.path.exists(output_path):\n            print(f\"\u2705 {output_filename} already exists, skipping...\")\n            continue\n\n        # Remote file URL via /vsicurl/\n        url = f\"https://gismgr.fao.org/DATA/WAPOR-3/MAPSET/L1-AETI-M/{filename}\"\n        vsicurl_url = f\"/vsicurl/{url}\"\n        temp_clip = os.path.join(output_folder, f\"temp_{output_filename}\")\n\n        print(f\"Downloading...{filename}\")\n\n        try:\n            warp_options = gdal.WarpOptions(\n                cutlineDSName=geojson_boundary,\n                cropToCutline=True,\n                dstNodata=-9999\n            )\n            gdal.Warp(destNameOrDestDS=temp_clip, srcDSOrSrcDSTab=vsicurl_url, options=warp_options)\n        except Exception as e:\n            print(f\"\u274c GDAL warp failed for {filename}: {e}\")\n            continue\n\n        # Scale and write output with compression\n        try:\n            with rasterio.open(temp_clip) as src:\n                profile = src.profile\n                data = src.read(1)\n                nodata = src.nodata\n\n                data = np.where(data == nodata, -9999, data)\n                scaled_data = np.where(data != -9999, data * 0.1, -9999)\n\n                profile.update(\n                    dtype=rasterio.float32,\n                    nodata=-9999,\n                    compress=\"LZW\"\n                )\n\n                with rasterio.open(output_path, \"w\", **profile) as dst:\n                    dst.write(scaled_data.astype(rasterio.float32), 1)\n\n            os.remove(temp_clip)\n            print(f\"\u2705 Processed and saved: {output_filename}\")\n        except Exception as e:\n            print(f\"\u274c Failed to scale/write {filename}: {e}\")\n            if os.path.exists(temp_clip):\n                os.remove(temp_clip)\n</code></pre>"},{"location":"datasets/lulc/","title":"Land Use and Land Cover (LULC)","text":"<p>The Land Use and Land Cover (LULC) data used in the EQIPA tool is sourced from the National Remote Sensing Centre (NRSC), India. These maps provide a detailed spatial representation of how different land types are utilized across agricultural regions, enabling spatial analysis of irrigation performance.</p>"},{"location":"datasets/lulc/#dataset-overview","title":"Dataset Overview","text":"<ul> <li>Source: NRSC LULC Portal</li> <li>Provider: National Remote Sensing Centre (NRSC), ISRO</li> <li>Product: LULC at 1:250,000 scale (250K)</li> <li>Spatial Resolution: ~56 meters</li> <li>Temporal Resolution: Annual</li> <li>Period of Use: 2018\u20132023</li> <li>Output Format Used in EQIPA: Annual GeoTIFF</li> </ul>"},{"location":"datasets/lulc/#notes","title":"\ud83d\udccc Notes","text":"<ul> <li>The dataset is not directly downloadable online.</li> <li>Access to LULC maps from NRSC requires formal data request through their official portal or by contacting NRSC.</li> <li>For official data acquisition, visit: https://www.nrsc.gov.in/EO_LULC_Portals</li> </ul>"},{"location":"datasets/overview/","title":"\ud83d\udef0\ufe0f Download Datasets \u2013 Overview","text":"<p>This section provides access instructions and sources for downloading remote sensing datasets used in the EQIPA platform. Each dataset has its own dedicated page with download links, tools, and script examples.</p>"},{"location":"datasets/overview/#datasets-used","title":"\ud83d\udce6 Datasets Used:","text":"<ul> <li>IMD Gridded Precipitation (PCP)</li> <li>WaPOR v3 \u2013 Actual Evapotranspiration (ETa)</li> <li>WaPOR v3 \u2013 Biomass Production (TBP)</li> <li>NRSC LULC 250K Land Cover (LULC)</li> <li>AW3D30 Elevation Model</li> </ul>"},{"location":"datasets/pcp_chirps/","title":"Precipitation (CHIRPS)","text":"<p>Since 1999, USGS and CHC scientists\u2014supported by funding from USAID, NASA, and NOAA\u2014have developed techniques for producing rainfall maps, especially in areas where surface data is sparse.</p>"},{"location":"datasets/pcp_chirps/#chirps-v30-overview","title":"CHIRPS v3.0 Overview","text":"<p>CHIRPS v3.0 is available for three domains: Global, Africa, and Latin America. Similar to CHIRPS v2.0, two products of CHIRPS v3.0 are available. A preliminary version and a final version. The preliminary version is produced at the end of every pentad with rapidly available Global Telecommunication System (GTS) data, while the final version \u2013 produced about two weeks after the end of the month \u2013 incorporates data from the Global Historical Climatology Network (GHCN), and the Global Summary of the Day (GSOD).</p> <p>CHIRPS v3.0 benefits from nearly four times more sources of gauge data compared to CHIRPS v2.0. This increased volume of observations significantly improves the spatial and temporal accuracy of rainfall estimates.</p> <ul> <li>Source: CHIRPS v3</li> </ul>"},{"location":"datasets/pcp_chirps/#download-monthly-chirps-pcp","title":"Download Monthly CHIRPS PCP","text":"<p>The following script downloads monthly CHIRPS v3.0 GeoTIFFs for a given year range:</p> <pre><code>import requests\nimport os\n\n\nfirstyear = 2022\nlastyear = 2023\n\n# Create a folder to store downloads\ndownload_folder = \"pcp_chirps_v3_monthly\"\nos.makedirs(download_folder, exist_ok=True)\n\n\nfor year in range(firstyear, lastyear + 1):\n    for month in range(1,13):\n        filename = f\"chirps-v3.0.{year}.{month:02d}.tif\"\n        url = f\"https://data.chc.ucsb.edu/products/CHIRPS/v3.0/monthly/global/tifs/{filename}\"\n        print(f\"Downloading {filename} from {url} ...\")\n\n        try:\n            response = requests.get(url, stream=True)\n            response.raise_for_status()  \n            output_path = os.path.join(download_folder, filename)\n            with open(output_path, \"wb\") as f:\n                for chunk in response.iter_content(chunk_size=8192):\n                    if chunk:\n                        f.write(chunk)\n            print(f\"Downloaded {filename} successfully.\")\n        except requests.exceptions.RequestException as e:\n            print(f\"Failed to download {filename}: {e}\")\n</code></pre>"},{"location":"datasets/pcp_chirps/#clip-chirps-global-rasters-to-india-boundary","title":"Clip CHIRPS Global Rasters to India Boundary","text":"<p>Once downloaded, use this script to clip the global raster to the India boundary using a GeoJSON file.</p> <p>\ud83d\udcc1 Boundary file required: <code>IndiaBoundary.geojson</code></p> <pre><code>import os\nfrom osgeo import gdal\n\n# Set your paths\ninput_folder = \"pcp_chirps_v3_monthly\"      \noutput_folder = \"pcp_chirps_ind_monthly\"   \ngeojson_boundary = \"IndiaBoundary.geojson\" \n\nfirstyear = 2022\nlastyear = 2023\n\n# Create the output folder if it doesn't exist\nif not os.path.exists(output_folder):\n    os.makedirs(output_folder)\n\n# Loop through all files in the input folder\nfor year in range(firstyear, lastyear+1):\n    for month in range(1, 13):\n        # Build input filename: WAPOR-3.L1-AETI-M.YYYY-MM.tif\n        filename = f\"chirps-v3.0.{year}.{month:02d}.tif\"\n        input_path = os.path.join(input_folder, filename)\n        output_filename = f\"chirps_pcp_m_{year}_{month:02d}.tif\"\n\n        output_path = os.path.join(output_folder, output_filename)\n\n        # Clip the raster using GDAL.Warp with the GeoJSON boundary\n        warp_options = gdal.WarpOptions(cutlineDSName=geojson_boundary, cropToCutline=True,dstNodata=-9999)\n        gdal.Warp(destNameOrDestDS=output_path, srcDSOrSrcDSTab=input_path, options=warp_options)\n\n        print(f\"Processed {filename}: clipped and scaled saved to {output_path}\")\n</code></pre>"},{"location":"datasets/pcp_imd/","title":"Precipitation (IMD)","text":"<p>For estimating precipitation, the EQIPA platform uses high-resolution daily gridded rainfall data provided by the India Meteorological Department (IMD). The dataset spans a long period (1901\u2013Present) and offers daily precipitation values across India at a 0.25\u00b0 x 0.25\u00b0 spatial resolution.</p>"},{"location":"datasets/pcp_imd/#dataset-overview","title":"Dataset Overview","text":"<ul> <li>Source: IMD Daily Gridded Rainfall Data</li> <li>Format: NetCDF (<code>.nc</code>)</li> <li>Period of Use: 2018\u20132023 crop years</li> <li>Spatial Resolution: 0.25\u00b0 x 0.25\u00b0</li> <li>Temporal Resolution: Daily</li> <li>Output Format Used in EQIPA: Monthly GeoTIFF</li> </ul>"},{"location":"datasets/pcp_imd/#data-processing-summary","title":"\ud83d\udccc Data Processing Summary","text":"<ol> <li>Daily NetCDF files are downloaded from IMD.</li> <li>Each file is converted to daily GeoTIFF rasters.</li> <li>These daily rasters are aggregated to produce monthly precipitation maps.</li> <li>Annual precipitation (per crop year) is computed by summing monthly rasters from June to May (e.g., June 2022 \u2013 May 2023).</li> </ol>"},{"location":"datasets/pcp_imd/#download-annual-netcdf-from-imd","title":"Download Annual NetCDF from IMD","text":"<pre><code># pcp_imd_download.py\nimport requests\nimport os\nimport re\nfrom tqdm import tqdm\n\n# Create a folder to store downloaded files\ndownload_folder = \"imd_netcdf_files\"\nos.makedirs(download_folder, exist_ok=True)\n\nfirstyear = 2023\nlastyear = 2024\n\n\n\n# Define the URL\nurl = \"https://www.imdpune.gov.in/cmpg/Griddata/RF25.php\"\n\n# Loop over the years for which you wish to download the netCDF files\nfor year in range(firstyear, lastyear + 1):  # Adjust the range as needed\n    payload = {\"RF25\": str(year)}\n    print(f\"Downloading netCDF file for year {year} ...\")\n\n    try:\n        # Post the request with the payload\n        response = requests.post(url, data=payload, stream=True)\n        response.raise_for_status()  # Raise an error for bad responses\n\n        # Determine filename (using a default if not provided in headers)\n        filename = f\"RF25_{year}.nc\"\n\n        # Get total file size from headers (if available) for the progress bar\n        total_size = int(response.headers.get('content-length', 0))\n        progress_bar = tqdm(total=total_size, unit='B', unit_scale=True, desc=filename)\n\n        output_path = os.path.join(download_folder, filename)\n        with open(output_path, \"wb\") as f:\n            for chunk in response.iter_content(chunk_size=8192):\n                if chunk:\n                    f.write(chunk)\n                    progress_bar.update(len(chunk))\n        progress_bar.close()\n\n        # Check if the download completed correctly\n        if total_size != 0 and progress_bar.n != total_size:\n            print(f\"WARNING: Download size mismatch for {filename}\")\n        else:\n            print(f\"Downloaded {filename} successfully.\")\n\n    except requests.RequestException as e:\n        print(f\"Failed to download netCDF file for year {year}: {e}\")\n</code></pre>"},{"location":"datasets/pcp_imd/#convert-netcdf-to-daily-geotiffs","title":"Convert NetCDF to Daily GeoTIFFs","text":"<p>The following Python script converts daily precipitation values from IMD NetCDF files to GeoTIFF format using <code>xarray</code> and <code>rioxarray</code>.</p> <pre><code># pcp_imd_daily.py\n# pcp_imd_daily.py\nimport xarray as xr\nimport rioxarray\nimport os\nfrom osgeo import gdal\n\nfirstyear = 2023\nlastyear = 2024\n\ninput_folder = \"imd_netcdf_files\"\n\noutput_folder = \"pcp_imd_daily\"\nos.makedirs(output_folder, exist_ok=True)\n\n\nfor year in range(firstyear, lastyear + 1):\n    # Construct the full path to the netCDF file using f-string and os.path.join\n    input_nc = os.path.join(input_folder, f\"RF25_{year}.nc\")\n\n    # Open the netCDF file\n    ds = xr.open_dataset(input_nc)\n    # print(ds.variables)\n    print(year)\n\n    if year&gt;2023:\n        variable_name = \"rf\"\n        time_var=\"time\"\n    else:\n        variable_name = \"RAINFALL\"\n        time_var=\"TIME\"\n\n    da = ds[variable_name]\n\n    # Loop over each day using the \"TIME\" coordinate\n    for day in da.coords[time_var]:\n        daily_data = da.sel({time_var: day})\n        daily_data.rio.write_crs(\"EPSG:4326\", inplace=True)\n\n        day_str = str(day.values).split(\"T\")[0]\n        raw_tif = os.path.join(output_folder, f\"imd_pcp_{day_str}_raw.tif\")\n        final_tif = os.path.join(output_folder, f\"imd_pcp_{day_str}.tif\")\n\n        # Export raw GeoTIFF\n        daily_data.rio.to_raster(raw_tif)\n\n\n        # Use GDAL Warp to ensure north-up and EPSG:4326\n        gdal.Warp(\n            destNameOrDestDS=final_tif,\n            srcDSOrSrcDSTab=raw_tif,\n            dstSRS='EPSG:4326',\n            resampleAlg='bilinear',\n            format='GTiff'\n        )\n\n        os.remove(raw_tif)  # Clean up intermediate\n        print(f\"Saved raw: {final_tif}\")\n</code></pre>"},{"location":"datasets/pcp_imd/#aggregate-daily-geotiffs-to-monthly","title":"Aggregate Daily GeoTIFFs to Monthly","text":"<p>This script uses <code>rasterio</code> and <code>numpy</code> to aggregate daily rasters into monthly precipitation maps by summing values.</p> <pre><code># pcp_imd_monthly.py\nimport os\nimport glob\nimport rasterio\nimport numpy as np\n\nfirstyear = 2023\nlastyear = 2024\n\noutput_folder = \"pcp_imd_monthly\"\nos.makedirs(output_folder, exist_ok=True)\n\ninput_folder = \"pcp_imd_daily\"\n\nfor year in range(firstyear, lastyear + 1):\n    for month in range(1, 13):\n        # Daily files are assumed to be named: imd_pcp_YYYY-MM-DD.tif\n        pattern = os.path.join(input_folder, f\"imd_pcp_{year}-{month:02d}-*.tif\")\n        daily_files = sorted(glob.glob(pattern))\n\n        if not daily_files:\n            print(f\"No daily files found for {year}-{month:02d}\")\n            continue\n\n        daily_arrays = []\n        meta = None\n        nodata_val = None\n\n        # Loop over daily files and read data as float32.\n        # Replace no-data values with np.nan for summing.\n        for daily_file in daily_files:\n            with rasterio.open(daily_file) as src:\n                data = src.read(1).astype(np.float32)\n                if meta is None:\n                    meta = src.meta.copy()\n                    nodata_val = src.nodata\n                    if nodata_val is None:\n                        # If nodata isn't defined, set a default value (e.g., -9999)\n                        nodata_val = -9999\n                        meta.update(nodata=nodata_val)\n                # Replace nodata with np.nan so it won't affect the sum\n                data[data == nodata_val] = np.nan\n                daily_arrays.append(data)\n\n        # Stack daily arrays along a new axis\n        stack = np.stack(daily_arrays, axis=0)\n        monthly_sum = np.nansum(stack, axis=0)\n        # Identify pixels that are no-data in all daily files\n        all_nan_mask = np.all(np.isnan(stack), axis=0)\n        monthly_sum[all_nan_mask] = nodata_val\n\n        # Update metadata: ensure data type and single band output\n        meta.update(dtype=rasterio.float32, count=1)\n        output_filename = os.path.join(output_folder, f\"imd_pcp_m_{year}_{month:02d}.tif\")\n\n        with rasterio.open(output_filename, 'w', **meta) as dst:\n            dst.write(monthly_sum, 1)\n\n        print(f\"Saved monthly raster: {output_filename}\")\n</code></pre>"},{"location":"datasets/pcp_imd/#aggregate-monthly-geotiffs-to-annual","title":"Aggregate Monthly GeoTIFFs to Annual","text":"<pre><code># pcp_imd_annual.py\nimport os\nimport numpy as np\nimport rasterio\n\nfirstyear = 2023\nlastyear=2024\n\noutput_folder = \"pcp_imd_annual\"\nos.makedirs(output_folder, exist_ok=True)\n\ninput_folder = \"pcp_imd_monthly\"\n\nfor year in range(firstyear, lastyear):\n    # Annual period: June of current year to May of next year.\n    monthly_files = []\n\n    # June to December for the current year\n    for month in range(6, 13):\n        file_path = os.path.join(input_folder, f\"imd_pcp_m_{year}_{month:02d}.tif\")\n        monthly_files.append(file_path)\n\n    # January to May for the next year\n    for month in range(1, 6):\n        file_path = os.path.join(input_folder, f\"imd_pcp_m_{year+1}_{month:02d}.tif\")\n        monthly_files.append(file_path)\n\n\n    monthly_arrays = []\n    meta = None\n    nodata_val = None\n\n    for monthly_file in monthly_files:\n        with rasterio.open(monthly_file) as src:\n            data = src.read(1).astype(np.float32)\n            if meta is None:\n                meta = src.meta.copy()\n                nodata_val = src.nodata\n                if nodata_val is None:\n                    # If nodata is not defined, set a default value (e.g., -9999)\n                    nodata_val = -9999\n                    meta.update(nodata=nodata_val)\n            # Replace nodata values with np.nan so they don't affect the sum\n            data[data == nodata_val] = np.nan\n            monthly_arrays.append(data)\n\n    # Stack monthly arrays and compute the sum, ignoring NaNs\n    stack = np.stack(monthly_arrays, axis=0)\n    annual_sum = np.nansum(stack, axis=0)\n\n    # For pixels that are nan in every month, set back to nodata\n    all_nan_mask = np.all(np.isnan(stack), axis=0)\n    annual_sum[all_nan_mask] = nodata_val\n\n    meta.update(dtype=rasterio.float32, count=1)\n    output_filename = os.path.join(output_folder, f\"imd_pcp_a_{year}_{year+1}.tif\")\n    with rasterio.open(output_filename, 'w', **meta) as dst:\n        dst.write(annual_sum, 1)\n\n    print(f\"Saved annual raster: {output_filename}\")\n</code></pre>"},{"location":"datasets/setup/","title":"\u2699\ufe0f Environment Setup for Dataset Download","text":"<p>To download and process datasets, you need to set up a Python environment with geospatial libraries such as GDAL, Rasterio, and Xarray.</p>"},{"location":"datasets/setup/#1-on-local-pc","title":"1: On Local PC","text":""},{"location":"datasets/setup/#1-install-conda-recommended","title":"1: Install Conda (Recommended)","text":"<p>Conda is a cross-platform environment manager that makes it easy to install geospatial libraries like GDAL.</p>"},{"location":"datasets/setup/#windows","title":"Windows","text":"<ol> <li>Download the Miniconda installer:    \ud83d\udc49 Miniconda Windows 64-bit</li> <li>Run the installer and choose \u201cAdd Miniconda to PATH\u201d during setup.</li> <li>After installation, open Anaconda Prompt or Command Prompt and test:</li> </ol> <pre><code>conda --version\n</code></pre>"},{"location":"datasets/setup/#macos-os","title":"MacOS OS","text":"<ol> <li> <p>Download the installer for macOS from:    \ud83d\udc49 Miniconda macOS</p> </li> <li> <p>Run the installer</p> </li> <li> <p>Restart terminal and verify:</p> </li> </ol> <pre><code>conda --version\n</code></pre>"},{"location":"datasets/setup/#2-create-a-conda-environment","title":"2: Create a Conda Environment","text":"<pre><code>conda create --name eqipa_env python=3.10\nconda activate eqipa_env\n</code></pre>"},{"location":"datasets/setup/#3-install-gdal-and-geospatial-libraries","title":"3: Install GDAL and Geospatial Libraries","text":"<p>Use the <code>conda-forge</code> channel:</p> <pre><code>conda install -c conda-forge gdal libgdal-jp2openjpeg \n</code></pre> <p>Verify GDAL installation:</p> <pre><code>gdalinfo --version\n</code></pre> <p>Then install required Python libraries:</p> <pre><code>conda install pandas tqdm geopandas numpy xarray rioxarray rasterio netCDF4 requests\n</code></pre>"},{"location":"datasets/setup/#4-enable-jupyter-notebook-support-optional","title":"4: Enable Jupyter Notebook Support (Optional)","text":"<pre><code>conda install -c conda-forge notebook ipykernel\npython -m ipykernel install --user --name=eqipa_env --display-name \"Python (eqipa_env)\"\n</code></pre> <p>To select the environment kernel in Jupyter: Kernel \u2192 Change Kernel \u2192 Python (eqipa_env)</p> <p>Optional Cleanup: If you ever want to remove the kernel, use: <pre><code>jupyter kernelspec uninstall eqipa_env\n</code></pre></p>"},{"location":"datasets/setup/#optional-save-environment-for-future-use","title":"Optional: Save Environment for Future Use","text":"<pre><code>conda env export &gt; eqipa_env.yml\n</code></pre> <p>Others can recreate the environment with:</p> <pre><code>conda env create -f eqipa_env.yml\n</code></pre>"},{"location":"datasets/setup/#on-ubuntu-without-conda","title":"On Ubuntu (Without Conda)","text":""},{"location":"datasets/setup/#1-install-gdal-system-packages","title":"1. Install GDAL system packages","text":"<pre><code>sudo apt-get install gdal-bin libgdal-dev libspatialindex-dev\n</code></pre>"},{"location":"datasets/setup/#2-create-and-activate-a-python-virtual-environment","title":"2. Create and Activate a Python Virtual Environment","text":"<pre><code>python3 -m venv venv\nsource venv/bin/activate\n</code></pre>"},{"location":"datasets/setup/#3-install-required-python-libraries","title":"3. Install Required Python Libraries","text":"<pre><code>pip install pandas tqdm geopandas numpy xarray rioxarray rasterio netCDF4\n</code></pre>"},{"location":"datasets/setup/#4-recommended-requirementstxt","title":"4. Recommended <code>requirements.txt</code>","text":"<p>You can create a <code>requirements.txt</code> for reuse:</p> <pre><code>pandas\ntqdm\ngeopandas\nnumpy\nxarray\nrioxarray\nrasterio\nnetCDF4\n</code></pre> <p>Install with:</p> <pre><code>pip install -r requirements.txt\n</code></pre>"},{"location":"datasets/setup/#next-step","title":"\u2705 Next Step","text":"<p>Once the environment is set up, proceed to the dataset you want to download.</p>"},{"location":"datasets/tbp_wapor%20copy/","title":"Actual Evapotranspiration","text":"<p>Total Biomass Production (TBP) is defined as the sum of the above-ground dry matter produced for a given year. TBP is calculated from Net Primary Production (NPP). TBP is expressed in kgDM/ha/day, and has thus different biomass units compared to NPP, with 1 gC/m2/day (NPP) = 22.222 kgDM/ha/day (DMP).</p> <p>For further information on the methodology read the WaPOR documentation available at: https://bitbucket.org/cioapps/wapor-et-look/wiki/Home</p>"},{"location":"datasets/tbp_wapor%20copy/#dataset-overview","title":"Dataset Overview","text":"<ul> <li>Source: WaPOR L1 v3</li> <li>Period of Use: 2018\u20132023 crop years</li> <li>Spatial Resolution: 300m</li> <li>Temporal Resolution: Monthly</li> <li>Output Format Used in EQIPA: Monthly GeoTIFF</li> </ul>"},{"location":"datasets/tbp_wapor%20copy/#data-processing-summary","title":"\ud83d\udccc Data Processing Summary","text":"<ol> <li>Monthly WaPOR L1 v3 NPP (300m) maps have been downloaded from WaPOR.</li> <li>Monthly TBP maps are calculated as = Monthly NPP \u00d7 Scale Factor (0.001) \u00d7 Unit Conversion Factor (22.222). See the scale factor for each WaPOR product here: https://data.apps.fao.org/wapor</li> <li>Annual TBP maps is computed for all crop years by aggregating monthly TBP maps from June to May, covering crop years 2018-19 to 2022-23.</li> </ol>"},{"location":"datasets/tbp_wapor%20copy/#python-script-download-monthly-npp-wapor-v3","title":"\u2b07\ufe0f Python Script: Download Monthly NPP (WaPOR v3)","text":"<p>This script downloads monthly NPP GeoTIFFs from FAO's WaPOR v3 Google-hosted URLs.</p> <pre><code># tbp_wapor_v3.py\nimport requests\nimport os\nfrom tqdm import tqdm\n\nfirstyear = 2023\nlastyear = 2024\n\n# Create a folder to store downloads (optional)\ndownload_folder = \"npp_wapor_v3_monthly\"\nos.makedirs(download_folder, exist_ok=True)\n\n\nfor year in range(firstyear, lastyear+1):\n    for month in range(1, 13):\n        filename = f\"WAPOR-3.L1-NPP-M.{year}-{month:02d}.tif\"\n        output_path = os.path.join(download_folder, filename)\n\n        if os.path.exists(output_path):\n            print(f\"File already exists: {filename}, skipping...\")\n            continue\n\n        url = f\"https://gismgr.fao.org/DATA/WAPOR-3/MAPSET/L1-NPP-M/{filename}\"\n        print(f\"Downloading {filename} from {url} ...\")\n\n        try:\n            response = requests.get(url, stream=True)\n            response.raise_for_status()  # Raise an error for bad responses\n\n            # Get total file size from headers (if available)\n            total_size = int(response.headers.get('content-length', 0))\n\n            # Create a progress bar with tqdm\n            progress_bar = tqdm(total=total_size, unit='B', unit_scale=True, desc=filename)\n\n\n            with open(output_path, \"wb\") as f:\n                for chunk in response.iter_content(chunk_size=8192):\n                    if chunk:\n                        f.write(chunk)\n                        progress_bar.update(len(chunk))\n            progress_bar.close()\n\n            # Optional: Check if the download completed correctly\n            if total_size != 0 and progress_bar.n != total_size:\n                print(f\"WARNING: Download size mismatch for {filename}\")\n            else:\n                print(f\"Downloaded {filename} successfully.\")\n        except requests.exceptions.RequestException as e:\n            print(f\"Failed to download {filename}: {e}\")\n</code></pre>"},{"location":"datasets/tbp_wapor%20copy/#clip-global-rasters-to-india-boundary","title":"Clip Global Rasters to India Boundary","text":"<p>Once downloaded, use this script to clip the global raster to the India boundary using a boundary file.</p> <p>\ud83d\udcc1 India Boundary file required: https://github.com/waterinag/eqipa-docs/blob/main/docs/assets/IndiaBoundary.geojson</p> <pre><code># tbp_wapor_v3_clip.py\nimport os\nimport numpy as np\nimport rasterio\nfrom osgeo import gdal\n\n# Set your paths\ninput_folder = \"npp_wapor_v3_monthly\"      \noutput_folder = \"tbp_wapor_v3_monthly_ind\"   \ngeojson_boundary = \"IndiaBoundary.geojson\" \nscale_factor=0.001*22.222\nfirstyear = 2023\nlastyear = 2024\n\n# Create the output folder if it doesn't exist\nif not os.path.exists(output_folder):\n    os.makedirs(output_folder)\n\n# Loop through all files in the input folder\nfor year in range(firstyear, lastyear+1):\n    for month in range(1, 13):\n        output_filename = f\"wapor_tbp_m_{year}_{month:02d}.tif\"\n        temp_clip = os.path.join(output_folder, f\"temp_{output_filename}\")\n\n        # Clip and Download raster from Cloud\n        # fileURL=f\"https://storage.googleapis.com/fao-gismgr-wapor-3-data/DATA/WAPOR-3/MAPSET/L2-NPP-M/WAPOR-3.L2-NPP-M.{year}-{month:02d}.tif\" \n        # vrt_file=f\"WAPOR-3.L2-NPP-M.{year}-{month:02d}.vrt\"\n        # gdal.BuildVRT(vrt_file, [f\"/vsicurl/{fileURL}\"])\n        # gdal.Warp(temp_clip, vrt_file, cutlineDSName=geojson_boundary, cropToCutline=True, dstNodata=-9999)\n\n\n        # Clip raster from local\n        filename = f\"WAPOR-3.L1-NPP-M.{year}-{month:02d}.tif\"\n        input_path = os.path.join(input_folder, filename)\n        warp_options = gdal.WarpOptions(cutlineDSName=geojson_boundary, cropToCutline=True,dstNodata=-9999)\n        gdal.Warp(destNameOrDestDS=temp_clip, srcDSOrSrcDSTab=input_path, options=warp_options)\n\n\n\n        # Define the output path for the scaled raster\n        output_path = os.path.join(output_folder, output_filename)\n\n        # Open the clipped raster with Rasterio\n        with rasterio.open(temp_clip) as src:\n            profile = src.profile \n            data = src.read(1)\n            nodata = src.nodata\n\n            data = np.where(data == src.nodata, -9999, data)  \n            scaled_data = np.where(data != -9999, data * scale_factor, -9999)\n\n\n            # Update the profile for the output file\n            profile.update(\n                dtype=rasterio.float32, \n                nodata=nodata, \n                compress=\"LZW\"  # Apply LZW compression\n            )\n            if nodata is not None:\n                profile.update(nodata=nodata)\n\n            # Write the scaled data to a new file\n            with rasterio.open(output_path, \"w\", **profile) as dst:\n                dst.write(scaled_data.astype(rasterio.float32), 1)\n\n        # Optionally, remove the temporary clipped file\n        os.remove(temp_clip)\n\n        print(f\"Processed: clipped and scaled saved to {output_path}\")\n</code></pre>"},{"location":"datasets/tbp_wapor%20copy/#download-clipped-npp-raster-apply-scale-factor-and-convert-inot-tbp","title":"Download Clipped NPP Raster, Apply Scale Factor and convert inot TBP","text":"<p>This script downloads monthly WaPOR NPP raster files, clips them directly to the India boundary (using GDAL), and applies a scale factor and unit conversion and produce Monthly TBP Rasters.</p> <p>\ud83d\udcc1 India Boundary file required: https://github.com/waterinag/eqipa-docs/blob/main/docs/assets/IndiaBoundary.geojson</p> <pre><code>import os\nimport numpy as np\nimport rasterio\nfrom osgeo import gdal\n\nfirstyear = 2023\nlastyear = 2024\nscale_factor = 0.001 * 22.222\n\noutput_folder = \"tbp_wapor_v3_monthly_ind\"\ngeojson_boundary = \"IndiaBoundary.geojson\"\nos.makedirs(output_folder, exist_ok=True)\n\nfor year in range(firstyear, lastyear + 1):\n    for month in range(1, 13):\n        filename = f\"WAPOR-3.L1-NPP-M.{year}-{month:02d}.tif\"\n        output_filename = f\"wapor_tbp_m_{year}_{month:02d}.tif\"\n        output_path = os.path.join(output_folder, output_filename)\n\n        if os.path.exists(output_path):\n            print(f\"\u2705 {output_filename} already exists, skipping...\")\n            continue\n\n        url = f\"https://gismgr.fao.org/DATA/WAPOR-3/MAPSET/L1-NPP-M/{filename}\"\n        vsicurl_url = f\"/vsicurl/{url}\"\n        temp_clip = os.path.join(output_folder, f\"temp_{output_filename}\")\n\n        try:\n            warp_options = gdal.WarpOptions(\n                cutlineDSName=geojson_boundary,\n                cropToCutline=True,\n                dstNodata=-9999\n            )\n            gdal.Warp(destNameOrDestDS=temp_clip, srcDSOrSrcDSTab=vsicurl_url, options=warp_options)\n\n        except Exception as e:\n            print(f\"\u274c GDAL warp failed for {filename}: {e}\")\n            continue\n\n        try:\n            with rasterio.open(temp_clip) as src:\n                profile = src.profile\n                data = src.read(1)\n                nodata = src.nodata\n\n                data = np.where(data == nodata, -9999, data)\n                scaled_data = np.where(data != -9999, data * scale_factor, -9999)\n\n                profile.update(\n                    dtype=rasterio.float32,\n                    nodata=-9999,\n                    compress=\"LZW\"\n                )\n\n                with rasterio.open(output_path, \"w\", **profile) as dst:\n                    dst.write(scaled_data.astype(rasterio.float32), 1)\n\n            os.remove(temp_clip)\n            print(f\"\u2705 Processed and saved: {output_filename}\")\n        except Exception as e:\n            print(f\"\u274c Failed to scale/write {filename}: {e}\")\n            if os.path.exists(temp_clip):\n                os.remove(temp_clip)\n</code></pre>"},{"location":"datasets/tbp_wapor/","title":"Total Biomass Production (TBP)","text":"<p>Total Biomass Production (TBP) is defined as the sum of the above-ground dry matter produced for a given year. TBP is calculated from Net Primary Production (NPP). TBP is expressed in kgDM/ha/day, and has thus different biomass units compared to NPP, with 1 gC/m2/day (NPP) = 22.222 kgDM/ha/day (DMP).</p> <p>For further information on the methodology read the WaPOR documentation available at: https://bitbucket.org/cioapps/wapor-et-look/wiki/Home</p>"},{"location":"datasets/tbp_wapor/#dataset-overview","title":"Dataset Overview","text":"<ul> <li>Source: WaPOR L1 v3</li> <li>Period of Use: 2018\u2013present</li> <li>Spatial Resolution: 300m</li> <li>Temporal Resolution: Monthly</li> <li>Output Format Used in EQIPA: Monthly GeoTIFF</li> </ul>"},{"location":"datasets/tbp_wapor/#data-processing-summary","title":"\ud83d\udccc Data Processing Summary","text":"<ol> <li>Monthly WaPOR L1 v3 NPP (300m) maps have been downloaded from WaPOR.</li> <li>Monthly TBP maps are calculated as = Monthly NPP \u00d7 Scale Factor (0.001) \u00d7 Unit Conversion Factor (22.222). See the scale factor for each WaPOR product here: https://data.apps.fao.org/wapor</li> <li>Annual TBP maps is computed for all crop years by aggregating monthly TBP maps from June to May, covering crop years 2018-19 to 2022-23.</li> </ol>"},{"location":"datasets/tbp_wapor/#download-clipped-monthly-npp-raster-apply-scale-factor-and-convert-to-monthly-tbp","title":"Download Clipped Monthly NPP Raster, Apply Scale Factor and convert to Monthly TBP","text":"<p>This script downloads monthly WaPOR v3 NPP raster files from FAO's WaPOR Google Cloud Bucket URLs, clips them to the India boundary (using GDAL), and applies a scale factor and unit conversion and produce Monthly TBP Rasters.</p> <p>\ud83d\udcc1 India Boundary file: Link</p> <pre><code>import os\nimport numpy as np\nimport rasterio\nfrom osgeo import gdal\n\nfirstyear = 2023\nlastyear = 2024\n\noutput_folder = \"tbp_wapor_v3_monthly_ind\"\ngeojson_boundary = \"IndiaBoundary.geojson\"\nos.makedirs(output_folder, exist_ok=True)\n\nfor year in range(firstyear, lastyear + 1):\n    for month in range(1, 13):\n        filename = f\"WAPOR-3.L1-NPP-M.{year}-{month:02d}.tif\"\n        output_filename = f\"wapor_tbp_m_{year}_{month:02d}.tif\"\n        output_path = os.path.join(output_folder, output_filename)\n\n        if os.path.exists(output_path):\n            print(f\"\u2705 {output_filename} already exists, skipping...\")\n            continue\n\n        url = f\"https://gismgr.fao.org/DATA/WAPOR-3/MAPSET/L1-NPP-M/{filename}\"\n        vsicurl_url = f\"/vsicurl/{url}\"\n        temp_clip = os.path.join(output_folder, f\"temp_{output_filename}\")\n        print(f\"Downloading...{filename}\")\n\n        try:\n            warp_options = gdal.WarpOptions(\n                cutlineDSName=geojson_boundary,\n                cropToCutline=True,\n                dstNodata=-9999\n            )\n            gdal.Warp(destNameOrDestDS=temp_clip, srcDSOrSrcDSTab=vsicurl_url, options=warp_options)\n\n        except Exception as e:\n            print(f\"\u274c GDAL warp failed for {filename}: {e}\")\n            continue\n\n        try:\n            with rasterio.open(temp_clip) as src:\n                profile = src.profile\n                data = src.read(1)\n                nodata = src.nodata\n\n                data = np.where(data == nodata, -9999, data)\n                scaled_data = np.where(data != -9999, data * 0.001 * 22.222, -9999)\n\n                profile.update(\n                    dtype=rasterio.float32,\n                    nodata=-9999,\n                    compress=\"LZW\"\n                )\n\n                with rasterio.open(output_path, \"w\", **profile) as dst:\n                    dst.write(scaled_data.astype(rasterio.float32), 1)\n\n            os.remove(temp_clip)\n            print(f\"\u2705 Processed and saved: {output_filename}\")\n        except Exception as e:\n            print(f\"\u274c Failed to scale/write {filename}: {e}\")\n            if os.path.exists(temp_clip):\n                os.remove(temp_clip)\n</code></pre>"},{"location":"geo-tools/gdal/","title":"\ud83c\udf0d GDAL (Geospatial Data Abstraction Library)","text":"<p>GDAL is an open-source library used in GIS (Geographic Information Systems) for reading, writing, and processing raster and vector geospatial data. It acts as a translator between different geospatial data formats and is widely used in software like QGIS, GRASS GIS, and many Python-based GIS workflows.</p>"},{"location":"geo-tools/gdal/#key-features","title":"Key Features","text":"<ul> <li>Supports 100+ raster formats (GeoTIFF, NetCDF, HDF, etc.) and vector formats (Shapefile, GeoJSON, KML, etc.)</li> <li>Powerful command-line tools (like gdalwarp, gdal_translate, ogr2ogr) for data conversion, reprojection, clipping, mosaicking, and more.</li> <li>Allows raster and vector data transformation, such as projection changes, resampling, and format conversion.</li> <li>Well-supported Python bindings for automation and integration with geospatial workflows.</li> <li>Extensively used in remote sensing, cartography, and spatial analysis.</li> </ul>"},{"location":"geo-tools/gdal/#essential-gdal-commands","title":"Essential GDAL Commands","text":"<pre><code># View Raster Metadata\ngdalinfo input.tif\n\n# Reproject Raster to EPSG:4326\ngdalwarp -t_srs EPSG:4326 input.tif output.tif\n\n# Extract Band from Multi-band Raster\ngdal_translate -b 1 input.tif output_band1.tif\n\n# Convert Raster Format (e.g. TIFF to PNG)\ngdal_translate input.tif output.png\n\n# Clip Raster using Bounding Box (ULX, ULY, LRX, LRY)\ngdal_translate -projwin ulx uly lrx lry input.tif output.tif\n\n# Merge Multiple Rasters\ngdal_merge.py -o output.tif input1.tif input2.tif\n\n# Resample Raster to New Resolution\ngdalwarp -tr 1000 1000 input.tif output.tif\n\n# Compute Raster Statistics\ngdalinfo -stats input.tif\n\n# Convert to GeoTIFF Format\ngdal_translate -of GTiff input.tif output.tif\n\n# Polygonize Raster to Vector\ngdal_polygonize.py input.tif -f \"ESRI Shapefile\" output.shp\n\n# Build Raster Pyramids (Overviews)\ngdaladdo -r average input.tif 2 4 8 16\n\n# Warp Raster to Cutline Boundary\ngdalwarp -cutline boundary.shp -crop_to_cutline input.tif output.tif\n\n# Convert Raster to ASCII Grid\ngdal_translate -of AAIGrid input.tif output.asc\n\n# Get NoData Value\ngdalinfo -mm input.tif\n\n# Set NoData Value\ngdalwarp -dstnodata -9999 input.tif output.tif\n\n# Rasterize Vector Data\ngdal_rasterize -a attribute -tr 1000 1000 -l layer vector.shp output.tif\n\n# Compress the raster\ngdal_translate -co COMPRESS=DEFLATE input.tif output.tif\n</code></pre>"},{"location":"geo-tools/gdal/#learn-more","title":"\ud83d\udcda Learn More","text":"<ul> <li>GDAL Official Site</li> <li>Mastering GDAL Tools (Full Course)</li> </ul>"},{"location":"geo-tools/geoserver/","title":"GeoServer","text":"<p>GeoServer is a powerful open-source server for sharing geospatial data using open standards such as WMS, WFS, and WCS. It allows you to publish raster and vector data formats from databases, files, and remote services with ease.</p> <p>This tutorial walks through the installation, configuration, and usage of GeoServer for web-based geospatial data publishing.</p>"},{"location":"geo-tools/geoserver/#1-installation","title":"1. Installation","text":"<ul> <li> <p>Download from the official site: https://geoserver.org/download</p> </li> <li> <p>Extract the ZIP file:</p> </li> </ul> <pre><code>unzip geoserver-&lt;version&gt;.zip\ncd geoserver-&lt;version&gt;/bin\n</code></pre> <ul> <li>Run GeoServer:</li> </ul> <pre><code># Linux/Mac\n./startup.sh\n\n# Windows\nstartup.bat\n</code></pre> <p>GeoServer will be accessible at: http://localhost:8080/geoserver</p>"},{"location":"geo-tools/geoserver/#2-basic-interface-overview","title":"2. Basic Interface Overview","text":"<p>Once logged in:</p> <ul> <li>Data \u2192 Stores: Register new raster/vector sources (Shapefile, PostGIS, GeoTIFF, etc.)</li> <li>Data \u2192 Layers: Publish individual layers from a Store</li> <li>Layer Preview: Test your services (WMS/WFS/WCS)</li> <li>Services: Configure WMS, WFS, and WCS capabilities</li> </ul>"},{"location":"geo-tools/geoserver/#3-add-and-publish-data","title":"3. Add and Publish Data","text":"<p>Add a Data Store To publish data:</p> <ul> <li>Navigate to Data \u2192 Stores</li> <li>Choose store type (e.g., Shapefile, GeoTIFF, PostGIS)</li> <li>Fill in connection details</li> <li>Save</li> </ul> <p>Publish a Layer</p> <ul> <li>After creating a store, click Publish</li> <li>Configure the following:<ul> <li>Name</li> <li>Coordinate Reference System (CRS)</li> <li>Bounding box</li> </ul> </li> <li>Save</li> </ul> <p>Layer will now appear in Layer Preview.</p>"},{"location":"geo-tools/geoserver/#4-styling-layers-sld","title":"4. Styling Layers (SLD)","text":"<p>You can style layers using SLD (Styled Layer Descriptor):</p> <ul> <li>Go to Styles \u2192 Add New Style</li> <li>Name your style and paste the SLD XML</li> <li>Save and apply to your layer</li> <li>Use GeoServer SLD Cookbook for examples.</li> </ul>"},{"location":"geo-tools/overview/","title":"\ud83e\uddf0 Geospatial Tools Used in EQIPA","text":"<p>EQIPA leverages several powerful open-source geospatial tools and libraries to enable efficient geospatial analysis, raster processing, and report generation.</p> <p>This section documents the core tools integrated into the backend of the platform:</p> <ul> <li>GRASS GIS</li> <li>GDAL (Geospatial Data Abstraction Library)</li> <li>Rasterio</li> <li>GeoPandas</li> <li>rioxarray</li> </ul>"},{"location":"grass/common-commands/","title":"Common GRASS GIS Commands","text":"<p>Here are some frequently used GRASS GIS commands useful for working with rasters, vectors, regions, and exporting data.</p>"},{"location":"grass/common-commands/#1-starting-and-managing-sessions","title":"1. Starting and Managing Sessions","text":"<pre><code># Create a new location from scratch\ngrass -c /mnt/mapdata/grassdata/new_location\n\n\n# Start GRASS in an existing location/mapset\ngrass /path/to/mapset/location\n\n# Create a new mapset inside an existing location\ng.mapset -c mapset=test location=eqipa\n\n# Switch to a different mapset\ng.mapset mapset=pcp_mean_monthly\n\n# Add multiple mapsets to current search path\ng.mapsets mapset=nrsc_lulc,ind_annual_data operation=add\n</code></pre>"},{"location":"grass/common-commands/#2-map-and-region-management","title":"2. Map and Region Management","text":"<pre><code># Check raster resolution and extent\nr.info -g pcpm_imd_2023_10\n\n# List all rasters and vectors\ng.list type=raster,vector\n\n# List all rasters and export to file\ng.list rast map=etg_etb_ind_monthly &gt;&gt; names.txt\n\n# Set region to match a raster or vector map\ng.region raster=your_raster_map\ng.region vector=your_vector_map\n\n# View current region settings\ng.region -p\n</code></pre>"},{"location":"grass/common-commands/#3-import-data","title":"3. Import Data","text":"<pre><code># Import a raster file (GeoTIFF, NetCDF, etc.)\nr.import input=chirps_pcp.tif output=chirps_pcp\n\n# Import a vector file (GeoJSON, Shapefile, etc.)\nv.import input=IndiaBoundary.geojson output=india_boundary\n</code></pre>"},{"location":"grass/common-commands/#4-raster-vector-info","title":"4. Raster &amp; Vector Info","text":"<pre><code># View metadata of a raster or vector\nr.info map=chirps_pcp\nv.info map=india_boundary\n</code></pre>"},{"location":"grass/common-commands/#5-raster-operations","title":"5. Raster Operations","text":"<pre><code># Map algebra\nr.mapcalc expression=\"output_map = raster1 + raster2\"\n\n# Zonal statistics\nr.univar map=raster_map zones=vector_zones_map\n\n# Raster statistics summary\nr.stats -a input=raster_map_name\n\n# Merge rasters\nr.patch input=map1,map2 output=merged_map\n\n# Clip raster with current region\nr.clip input=your_raster output=clipped_raster\n\n# Resample raster\nr.resample input=your_raster output=resampled_raster\n\n# Apply raster mask\nr.mask raster=mask_map\n\n# Export raster to GeoTIFF\nr.out.gdal input=raster_map output=/path/output.tif format=GTiff\n</code></pre>"},{"location":"grass/common-commands/#6-vector-operations","title":"6. Vector Operations","text":"<pre><code># Buffer vector geometry\nv.buffer input=your_vector output=buffered_vector distance=500\n\n# Convert vector to raster\nv.to.rast input=your_vector output=rasterized_vector use=cat\n\n# Convert raster to vector\nr.to.vect input=your_raster output=vector_map feature=area\n\n# Merge vectors\nv.patch input=vector1,vector2 output=merged_vector\n\n# Export vector to Shapefile\nv.out.ogr input=vector_map output=/path/output.shp format=ESRI_Shapefile\n</code></pre> <p>Tip: Always verify the region and CRS settings (<code>g.region -p</code>) before running any spatial operation.</p>"},{"location":"grass/concepts/","title":"Core Concepts","text":"<p>Understanding the core structure and philosophy of GRASS GIS is essential before diving into spatial analysis. GRASS GIS organizes data and operations in a unique hierarchical structure and uses powerful tools for geospatial processing.</p> <p>The main component of the Data tab is the Data Catalog which shows the GRASS GIS hierarchical structure consisting of database, project and mapset .</p> <ol> <li> <p>GRASS database (root project directory):</p> <ul> <li>GISDBASE is the directory where all GRASS GIS data is stored.</li> <li>It acts as a container that holds LOCATIONS.</li> <li>You can think of GISDBASE as the \"root folder\" where all GRASS-related data for a project is organized.</li> </ul> </li> <li> <p>Location (defines projection and extent):</p> <ul> <li>A LOCATION is a folder within GISDBASE that defines a specific coordinate system, projection, and geographic extent.</li> <li>Each LOCATION is tied to a specific Coordinate Reference System (CRS), so all maps and data within a location must use the same CRS.</li> </ul> </li> <li> <p>Mapset (stores individual data and settings):</p> <ul> <li>A MAPSET is a subdirectory inside a LOCATION where data is stored. It helps manage different workflows or user data independently, even within the same LOCATION.</li> <li>The PERMANENT mapset inside each LOCATION contains base information such as region settings (the extent and resolution) and the coordinate system. Other mapsets can be created for individual users or tasks within the same location.</li> </ul> </li> </ol> <p>\ud83d\udcd8 Read the GRASS Quickstart Guide to understand this setup better.</p>"},{"location":"grass/concepts/#grass-gis-startup-screen","title":"GRASS GIS Startup Screen","text":"<p>When you open GRASS for the first time, a new directory is created in your home folder. This directory is called grassdata by default and stores all your GRASS projects. GRASS projects are simply folders storing your geospatial data with common coordinate reference system (CRS), ensuring consistency of your data. At the project level, data is further organized into subprojects called mapsets, which you can use to manage different subregions or analyses within a project. Each project contains a special mapset called PERMANENT, which is used to store source datasets for your analysis that can be easily accessed from other mapsets.</p> <p></p>"},{"location":"grass/concepts/#grass-gis-database-structure","title":"GRASS GIS Database Structure","text":"Component Description <code>GISDBASE</code> Root folder where all GRASS GIS data is stored. <code>LOCATION</code> Folder inside <code>GISDBASE</code> that defines a projection/CRS. All data in a LOCATION shares the same CRS. <code>MAPSET</code> Subdirectory of a LOCATION for storing actual data and managing workflows. <code>PERMANENT</code> Special mapset holding region settings and the default CRS. <code>WIND</code> File in each MAPSET that holds region resolution/extent."},{"location":"grass/concepts/#grass-region-computational-window","title":"GRASS Region: Computational Window","text":"<p>Each analysis in GRASS operates within a defined computational region: - It specifies the geographic extent, resolution, and alignment. - You can view or set the region using the <code>g.region</code> command.</p> <p>\ud83d\udccc All raster calculations are restricted to the computational region.</p>"},{"location":"grass/concepts/#raster-and-vector-data-models","title":"Raster and Vector Data Models","text":"<p>GRASS supports both raster and vector formats:</p> <ul> <li>Raster data represent continuous surfaces like elevation or precipitation using a grid of cells.</li> <li>Vector data store discrete features such as roads, boundaries, or points of interest using geometries (point, line, polygon).</li> </ul> <p>Common import commands:</p> <ul> <li><code>r.in.gdal</code> \u2013 Import raster data</li> <li><code>v.in.ogr</code> \u2013 Import vector data</li> </ul>"},{"location":"grass/concepts/#command-structure-and-modules","title":"Command Structure and Modules","text":"<p>GRASS is modular: each task is handled by a command-line module.</p>"},{"location":"grass/concepts/#standard-syntax","title":"Standard Syntax:","text":"<pre><code>module_name input=... output=... [other parameters]\n</code></pre>"},{"location":"grass/concepts/#module-prefixes","title":"Module Prefixes:","text":"<ul> <li><code>r.</code> \u2013 Raster modules (e.g., <code>r.mapcalc</code>, <code>r.slope.aspect</code>)</li> <li><code>v.</code> \u2013 Vector modules (e.g., <code>v.buffer</code>, <code>v.overlay</code>)</li> <li><code>g.</code> \u2013 General tools (e.g., <code>g.region</code>, <code>g.list</code>)</li> <li><code>i.</code> \u2013 Imagery and remote sensing</li> <li><code>db.</code> \u2013 Database operations</li> <li><code>t.</code> \u2013 Temporal framework</li> </ul> <p>Example: <pre><code>r.slope.aspect elevation=dem slope=slope_map aspect=aspect_map\n</code></pre></p>"},{"location":"grass/concepts/#gui-and-cli","title":"GUI and CLI","text":"<ul> <li>GUI (Graphical User Interface): Beginner-friendly interface to access tools visually.</li> <li>CLI (Command Line Interface): Powerful, scriptable, and preferred for advanced workflows.</li> </ul> <p>Both interfaces work seamlessly and reflect the same underlying operations.</p>"},{"location":"grass/concepts/#attribute-tables-and-databases","title":"Attribute Tables and Databases","text":"<p>Each vector map can be linked to an attribute table (usually SQLite by default). GRASS provides SQL-like functionality with <code>db.select</code>, <code>db.connect</code>, etc., to manage these databases.</p>"},{"location":"grass/concepts/#scripting-and-automation","title":"Scripting and Automation","text":"<ul> <li>GRASS supports Python scripting using the <code>grass.script</code> and <code>grass.pygrass</code> modules.</li> <li>Batch processing is possible with Bash, Makefiles, or Python Notebooks.</li> <li>This enables building automated, reproducible workflows.</li> </ul>"},{"location":"grass/concepts/#logging-and-metadata","title":"Logging and Metadata","text":"<p>Every GRASS module logs processing history in the metadata: - View history using <code>r.info</code> or <code>v.info</code> - Helps maintain data provenance and reproducibility</p> <p>By understanding these concepts, you are now ready to begin working with raster and vector data in GRASS GIS.</p>"},{"location":"grass/installation/","title":"Installation and Setup","text":"<p>GRASS GIS can be installed on all major operating systems, including Windows, macOS, and Linux. Follow the instructions below for your platform.</p>"},{"location":"grass/installation/#install-grass-gis","title":"Install GRASS GIS","text":"<p>Download the latest stable release from the official site: https://grass.osgeo.org/download/ Installation Guide: https://grasswiki.osgeo.org/wiki/Installation_Guide</p> <p>Choose the installer based on your operating system:</p> <ul> <li>Standalone installer for Windows</li> <li><code>.dmg</code> package for MacOS</li> <li>Ubuntu: <pre><code>sudo add-apt-repository ppa:ubuntugis/ubuntugis-unstable\nsudo apt-get update\nsudo apt-get install grass grass-gui grass-dev\n</code></pre></li> </ul>"},{"location":"grass/installation/#verifying-installation","title":"Verifying Installation","text":"<p>After installation, launch GRASS GIS from your system menu or use the CLI: <pre><code>grass\n</code></pre> You should see the GRASS startup window asking you to select or create a Location and Mapset.</p>"},{"location":"grass/installation/#sample-data","title":"Sample Data","text":"<ul> <li> <p>India Boundary   \u27a1\ufe0f Download IndiaBoundary.geojson</p> </li> <li> <p>India States   \u27a1\ufe0f Download IndiaStates.geojson</p> </li> <li> <p>Bihar Commands   \u27a1\ufe0f Download Bihar_CA.geojson</p> </li> <li> <p>Western Kosi Command   \u27a1\ufe0f Download Western_Kosi.geojson</p> </li> </ul>"},{"location":"grass/intro/","title":"GRASS GIS","text":"<p>The Geographic Resource Analysis Support System (GRASS) is a free and open source geographic information system (GIS). It is a powerful tool for managing, analyzing, and visualizing geospatial data, supporting raster, vector, and 3D modeling functionalities.</p>"},{"location":"grass/intro/#why-use-grass-gis","title":"Why Use GRASS GIS?","text":"<ul> <li>Open Source and Free: No licensing fees, fully community-supported.</li> <li>Powerful Analysis Tools: Ideal for advanced geospatial modeling and automation.</li> <li>Cross-platform Compatibility: Available on Windows, macOS, and Linux.</li> <li>Integration Ready: Works well with QGIS, Python, PostgreSQL/PostGIS, and other open-source tools.</li> <li>Custom Scripting: Automate workflows using Bash or Python (PyGRASS).</li> </ul>"},{"location":"grass/intro/#key-features","title":"Key Features","text":"<ul> <li>Raster and vector data support with a rich set of analytical tools</li> <li>Region and mask management for precise control over analysis extents</li> <li>Time-series data management and analysis</li> <li>Advanced hydrological and terrain analysis modules</li> <li>3D visualization and volume modeling</li> <li>Flexible data import/export options</li> </ul>"},{"location":"grass/intro/#learn-more","title":"\ud83d\udcda Learn More","text":"<ul> <li>GRASS GIS Official Site</li> <li>GRASS GIS Documentation</li> <li>Python API for GRASS</li> <li>GRASS GIS Manuals</li> <li>GRASS GIS Tutorials</li> <li>Intro to GRASS GIS Workshop</li> </ul>"},{"location":"grass/quickstart/","title":"GRASS GIS Quickstart","text":"<p>When launching GRASS GIS for the first time, you will open a default project \"world_latlog_wgs84\" where you can find a map layer called \"country_boundaries\" showing a world map in the WGS84 coordinate system.</p> <p>The main component of the Data tab is the Data Catalog which shows the GRASS GIS hierarchical structure consisting of database, project and mapset .</p>"},{"location":"grass/quickstart/#interface-overview","title":"Interface Overview","text":"<p>The GRASS GUI has several panels and tools:</p> <ul> <li>Layer Manager: Controls loaded map layers.</li> <li>Map Display: Shows raster/vector data.</li> <li>Data Catalog: Displays the GRASS data hierarchy.</li> <li>Console: Run GRASS commands directly.</li> <li>Modules Search Bar: Search for specific tools and commands.</li> </ul>"},{"location":"grass/quickstart/#getting-started-with-grass-gis","title":"Getting Started with GRASS GIS","text":"<p>This section explains how to set up your working environment in GRASS GIS and import your geospatial data.</p>"},{"location":"grass/quickstart/#1-create-a-grass-database-directory","title":"1. Create a GRASS Database Directory","text":"<p>Open a terminal and create a directory that will act as the GRASS GIS database:</p> <pre><code>mkdir -p /Volumes/ExternalSSD/eqipa_data/grassdata\n</code></pre> <p>This directory will store all Locations and Mapsets.</p> <p>This is the root directory that will contain all your GRASS locations and mapsets.</p>"},{"location":"grass/quickstart/#2-launch-grass-gis","title":"2. Launch GRASS GIS","text":"<pre><code>grass\n</code></pre> <p>In the startup screen:</p> <ul> <li>Set GIS Database to: /Volumes/ExternalSSD/eqipa_data/grassdata</li> <li>Click on New next to Location</li> </ul>"},{"location":"grass/quickstart/#3-create-a-new-location-using-epsg-code","title":"3. Create a New Location Using EPSG Code","text":"<p>Use grass with the -c flag to create a new Location based on a coordinate reference system (CRS). <pre><code>grass -c EPSG:4326 /Volumes/ExternalSSD/eqipa_data/grassdata/eqipa\n</code></pre> This command:</p> <ul> <li>Creates a new Location named \"eqipa\"</li> <li>Uses EPSG:4326 (WGS 84 coordinate system)</li> <li>Initializes the default PERMANENT mapset</li> </ul>"},{"location":"grass/quickstart/#4-create-and-start-a-new-mapset","title":"4. Create and Start a New Mapset","text":"<p>Create a New Mapset <pre><code># create a new mapset \ng.mapset -c mapset=ind_monthly_data location=eqipa\n</code></pre></p> <pre><code># Launch GRASS into the new mapset\ngrass /Volumes/ExternalSSD/eqipa_data/grassdata/eqipa/ind_monthly_data\n</code></pre> <p>Notes: - The new mapset must be inside an existing location.</p> <p>List all available mapsets <pre><code>g.mapsets -l\n</code></pre></p> <p>Switch to a different mapset within the same location <pre><code>g.mapset mapset=ind_annual_data  \n</code></pre></p>"},{"location":"grass/quickstart/#5-set-the-computational-region-optional","title":"5. Set the Computational Region (Optional)","text":"<pre><code>g.region raster=&lt;existing_raster&gt;\n# or\ng.region vector=&lt;existing_vector&gt;\n\n# Set Resolution\ng.region res=0.003\n\n# To manually set region boundaries and resolution:\ng.region n=25 s=10 e=90 w=70 res=0.01 -p\n</code></pre>"},{"location":"grass/quickstart/#6-import-raster-data","title":"6. Import Raster Data","text":"<p>Single Raster Import <pre><code>r.import input=/path/to/raster.tif output=my_raster\n</code></pre></p> <p>Bulk Import Raster Files <pre><code>for file in /path/to/pcp_imd_monthly/*.tif; do\n    name=$(basename \"$file\" .tif)\n    r.import input=\"$file\" output=\"$name\"\ndone\n</code></pre></p>"},{"location":"grass/quickstart/#7-import-vector-data","title":"7. Import Vector Data","text":"<p>Single Vector Import <pre><code>v.import input=/path/to/vector.shp output=my_vector\n</code></pre></p> <p>Bulk Import Vector Files <pre><code>for file in /path/to/folder/*.shp; do\n    name=$(basename \"$file\" .shp)\n    v.import input=\"$file\" output=\"$name\"\ndone\n</code></pre></p>"},{"location":"grass/quickstart/#8-list-imported-layers","title":"8. List Imported Layers","text":"<pre><code>g.list type=raster\ng.list type=vector\n</code></pre>"},{"location":"grass/quickstart/#9-view-layer-metadata","title":"9. View Layer Metadata","text":"<pre><code>r.info my_raster\nr.info -g my_raster\n\nv.info my_vector\n</code></pre>"},{"location":"grass/quickstart/#10-exit-grass-gis","title":"10. Exit GRASS GIS","text":"<pre><code>exit\n</code></pre>"},{"location":"grass/raster_basics/","title":"Raster Analysis","text":"<p>This section introduces fundamental raster operations in GRASS GIS. You'll learn how to perform map algebra, clipping rasters to a boundary, statistical summaries, LULC masking, raster algebra, and temporal aggregation.</p>"},{"location":"grass/raster_basics/#clip-raster-to-a-boundary","title":"Clip Raster to a Boundary","text":"<pre><code># Set region to match vector boundary\ng.region vector=command_boundary align=wapor_eta_m_2023_01 -p\n\n# Create a mask using the boundary\nr.mask vector=command_boundary\n\n# Clip the raster\nr.mapcalc \"eta_clipped = wapor_eta_m_2023_01\"\n\n# Remove the mask after clipping\nr.mask -r\n</code></pre>"},{"location":"grass/raster_basics/#get-raster-statistics-min-max-mean-median","title":"Get Raster Statistics (min, max, mean, median)","text":"<pre><code># Basic stats:\nr.univar map=eta_clipped -g\n\n# For median and advanced stats:\nr.stats -aCn input=eta_clipped\n\n# For raster category counts, area and values:\nr.report map=eta_clipped units=h,c,p\n</code></pre>"},{"location":"grass/raster_basics/#lulc-masking-eg-mask-only-cropland-areas","title":"LULC Masking (e.g., Mask only Cropland Areas)","text":"<pre><code># Assuming you have an LULC raster (esa_lulc_2021) where value 40 = cropland:\nr.mapcalc \"cropland_mask = if(esa_lulc_2021 == 40, 1, null())\"\nr.mask raster=cropland_mask\n\n# Apply it to another raster:\nr.mapcalc \"eta_cropland = wapor_eta_m_2023_01\"\n\n# Then remove the mask:\nr.mask -r\n</code></pre>"},{"location":"grass/raster_basics/#raster-calculation","title":"Raster Calculation","text":"<pre><code># Water Productivity (WP)\nr.mapcalc \"wp_2023_01 = tbp_2023_01 / (wapor_eta_m_2023_01 * 10)\"\n</code></pre>"},{"location":"grass/raster_basics/#temporal-raster-analysis","title":"Temporal Raster Analysis","text":"<pre><code># Mean over years\nr.series input=wapor_eta_a_2018,wapor_eta_a_2019,wapor_eta_a_2020,wapor_eta_a_2021 output=eta_mean_2018_2021 method=average\n\n# Max or Min over years\nr.series input=wapor_eta_a_2018,wapor_eta_a_2019,wapor_eta_a_2020,wapor_eta_a_2021 output=eta_max_2018_2021 method=maximum\n\n# Aggregate Monthly to Annual Raster: Annual Sum\nr.series input=$(g.list type=raster pattern=\"wapor_eta_m_2023_*\" separator=comma) output=wapor_eta_a_2023_sum method=sum\n\n# Aggregate Monthly to Annual Raster: Annual Mean\nr.series input=$(g.list type=raster pattern=\"wapor_eta_m_2023_*\" separator=comma) output=wapor_eta_a_2023_mean method=average\n</code></pre>"},{"location":"grass/scripting/","title":"GRASS GIS Scripting with Python","text":"<p>GRASS GIS can be automated and extended using Python. This page demonstrates how to write a complete geospatial analysis workflow using GRASS GIS commands in Python using <code>grass.script</code> and <code>pygrass</code>.</p> <ul> <li>Python Scripts   \u27a1\ufe0f Download All Scripts</li> </ul>"},{"location":"grass/scripting/#python-script-import-raster-data","title":"Python Script: Import Raster Data","text":"<p>Import Raster files</p> <pre><code>import os\nimport sys\nimport subprocess\nimport grass.script as gs\nfrom grass.pygrass.modules.shortcuts import general as g\nfrom grass.pygrass.modules.shortcuts import raster as r\nfrom grass.pygrass.modules.shortcuts import display as d\nfrom grass.pygrass.modules.shortcuts import vector as v\nfrom grass.pygrass.gis import *\nimport grass.script as grass\nimport grass.script.setup as gsetup\nimport re\n\n\n\n\n# Main function\ndef main(gisdb, location, mapset): \n\n    os.environ['GISDBASE'] = gisdb\n    os.environ['LOCATION_NAME'] = location\n\n    # Check if mapset exists; if not, create it\n    mapset_path = os.path.join(gisdb, location, mapset)\n    if not os.path.exists(mapset_path):\n        print(f\"Mapset '{mapset}' does not exist. Creating new mapset...\")\n        # Create the new mapset\n        gs.run_command('g.mapset', flags='c', mapset=mapset, location=location, dbase=GISDBASE)\n    else:\n        print(f\"Mapset '{mapset}' already exists.\")\n\n    # Initialize GRASS session\n    gsetup.init(gisdb, location, mapset)\n    print(f\"GRASS GIS session initialized in {gisdb}/{location}/{mapset}\")\n\n\n    input_folder = \"/Volumes/ExternalSSD/eqipa_data/pcp_imd_monthly\"\n    for file in os.listdir(input_folder):\n        if file.endswith(\".tif\"):\n            full_path = os.path.join(input_folder, file)\n            name = os.path.splitext(file)[0]  \n            print(f\"Importing {file} as {name}\")\n            gs.run_command('r.import', input=full_path, output=name)\n\n\n\n\nif __name__ == '__main__':\n    GISDBASE = \"/Volumes/ExternalSSD/eqipa_data/grassdata\"\n    LOCATION_NAME = \"eqipa\"\n    MAPSET = \"data_monthly\"                 \n\n    # Call the main function\n    main(GISDBASE, LOCATION_NAME, MAPSET)\n</code></pre>"},{"location":"grass/scripting/#python-script-resampling-of-raster-maps","title":"Python Script: Resampling of Raster Maps","text":"<p>Resampling</p> <pre><code>import os\nimport sys\nimport subprocess\nimport grass.script as gs\nfrom grass.pygrass.modules.shortcuts import general as g\nfrom grass.pygrass.modules.shortcuts import raster as r\nfrom grass.pygrass.modules.shortcuts import display as d\nfrom grass.pygrass.modules.shortcuts import vector as v\nfrom grass.pygrass.gis import *\nimport grass.script as grass\nimport grass.script.setup as gsetup\nimport re\n\n\n\n\n# Main function\ndef main(gisdb, location, mapset): \n\n    shapefile = 'IndiaBoundary.geojson' \n\n    os.environ['GISDBASE'] = gisdb\n    os.environ['LOCATION_NAME'] = location\n\n    # Check if mapset exists; if not, create it\n    mapset_path = os.path.join(gisdb, location, mapset)\n    if not os.path.exists(mapset_path):\n        print(f\"Mapset '{mapset}' does not exist. Creating new mapset...\")\n        # Create the new mapset\n        gs.run_command('g.mapset', flags='c', mapset=mapset, location=location, dbase=GISDBASE)\n    else:\n        print(f\"Mapset '{mapset}' already exists.\")\n\n    # Initialize GRASS session\n    gsetup.init(gisdb, location, mapset)\n    print(f\"GRASS GIS session initialized in {gisdb}/{location}/{mapset}\")\n\n\n\n    vector_name = os.path.splitext(os.path.basename(shapefile))[0]\n\n\n    # Import shapefile\n    gs.run_command('v.import', input=shapefile, output=vector_name, overwrite=True)\n\n    # Set region\n    gs.run_command('g.region', vector=vector_name, res=0.00292)\n\n    start_yr = '2023'\n    end_yr = '2024'\n\n\n\n    for year in range(int(start_yr), int(end_yr) + 1):\n        for month in range(1,13):\n            input_raster = f\"imd_pcp_m_{year}_{month:02d}\"\n            resampled_raster = f\"imd_pcp_resamp_m_{year}_{month:02d}\"\n\n            # This resampling only change the pixel size, will not apply any interpolation or will not change pixel value\n            gs.run_command(\n                'r.resample',\n                input=input_raster,\n                output=resampled_raster,\n                overwrite=True\n            )\n\n\n\n\n\nif __name__ == '__main__':\n    GISDBASE = \"/Volumes/ExternalSSD/eqipa_data/grassdata\"\n    LOCATION_NAME = \"eqipa\"\n    MAPSET = \"data_monthly\"                 \n\n    # Call the main function\n    main(GISDBASE, LOCATION_NAME, MAPSET)\n</code></pre>"},{"location":"grass/scripting/#python-script-aggregate-monthly-maps-to-annual","title":"Python Script: Aggregate Monthly Maps to Annual","text":"<p>Monthly to Annual Maps</p> <pre><code>import os\nimport sys\nimport subprocess\nimport grass.script as gs\nfrom grass.pygrass.modules.shortcuts import general as g\nfrom grass.pygrass.modules.shortcuts import raster as r\nfrom grass.pygrass.modules.shortcuts import display as d\nfrom grass.pygrass.modules.shortcuts import vector as v\nfrom grass.pygrass.gis import *\nimport grass.script as grass\nimport grass.script.setup as gsetup\nimport re\n\n\n\n\n# Main function\ndef main(gisdb, location, mapset): \n\n    shapefile = 'IndiaBoundary.geojson' \n\n    os.environ['GISDBASE'] = gisdb\n    os.environ['LOCATION_NAME'] = location\n\n    # Check if mapset exists; if not, create it\n    mapset_path = os.path.join(gisdb, location, mapset)\n    if not os.path.exists(mapset_path):\n        print(f\"Mapset '{mapset}' does not exist. Creating new mapset...\")\n        # Create the new mapset\n        gs.run_command('g.mapset', flags='c', mapset=mapset, location=location, dbase=GISDBASE)\n    else:\n        print(f\"Mapset '{mapset}' already exists.\")\n\n    # Initialize GRASS session\n    gsetup.init(gisdb, location, mapset)\n    print(f\"GRASS GIS session initialized in {gisdb}/{location}/{mapset}\")\n\n\n\n    # Argi year: June - May\n    start_month='6'\n    end_month='5'\n\n    start_yr = '2023'\n    end_yr = '2023'\n\n    agri_yr_timerange = []\n\n    for year in range(int(start_yr), int(end_yr) + 1):\n        months_range = []\n\n        if int(start_month) &gt; int(end_month):\n            for month in range(int(start_month), 13):\n                months_range.append(f\"{year}_{month:02d}\")\n            for month in range(1, int(end_month) + 1):\n                months_range.append(f\"{year + 1}_{month:02d}\")\n        else:\n            for month in range(int(start_month), int(end_month) + 1):\n                months_range.append(f\"{year}_{month:02d}\")\n        agri_yr_timerange.append(months_range)\n\n        print('agri_yr_timerange',agri_yr_timerange)\n\n        timerange = range(int(start_yr), int(end_yr) + 1)\n        years = list(timerange)\n\n        # Create strings like \"2022_2023\"\n        years_str = [f\"{y}_{y + 1}\" for y in years]\n\n        print(\"years_str\")\n        print(years_str)\n\n    # Add other mapsets to the current session\n    gs.run_command('g.mapsets', mapset=\"data_monthly\", operation=\"add\")\n    vector_name = os.path.splitext(os.path.basename(shapefile))[0]\n\n\n    # Import shapefile\n    gs.run_command('v.import', input=shapefile, output=vector_name, overwrite=True)\n\n    # Set region\n    gs.run_command('g.region', vector=vector_name, res=0.00292)\n\n\n    for y in agri_yr_timerange:\n        yr = int(y[0].split(\"_\")[0]) \n        yr_string = f'{yr}_{yr + 1}' \n        print(yr_string)\n\n        eta_maps_list = [f\"wapor_eta_m_{i}\" for i in y]\n        eta_out_map_name = f'wapor_eta_a_{yr_string}'\n\n        tbp_maps_list = [f\"wapor_tbp_m_{i}\" for i in y]\n        tbp_out_map_name = f'wapor_tbp_a_{yr_string}'\n\n        pcp_maps_list = [f\"imd_pcp_resam_m_{i}\" for i in y]\n        pcp_out_map_name = f'imd_pcp_resamp_a_{yr_string}'\n\n        gs.run_command('r.series', input=eta_maps_list, output=eta_out_map_name, method='sum', overwrite=True)\n        gs.run_command('r.series', input=tbp_maps_list, output=tbp_out_map_name, method='sum', overwrite=True)\n        gs.run_command('r.series', input=pcp_maps_list, output=pcp_out_map_name, method='sum', overwrite=True)\n\n\n\n\nif __name__ == '__main__':\n    GISDBASE = \"/Volumes/ExternalSSD/eqipa_data/grassdata\"\n    LOCATION_NAME = \"eqipa\"\n    MAPSET = \"data_annual\"                 \n\n    # Call the main function\n    main(GISDBASE, LOCATION_NAME, MAPSET)\n</code></pre>"},{"location":"grass/scripting/#python-script-raster-calculation-and-masking","title":"Python Script: Raster Calculation and Masking","text":"<p>Raster Calculation</p> <pre><code>import os\nimport sys\nimport subprocess\nimport grass.script as gs\nfrom grass.pygrass.modules.shortcuts import general as g\nfrom grass.pygrass.modules.shortcuts import raster as r\nfrom grass.pygrass.modules.shortcuts import display as d\nfrom grass.pygrass.modules.shortcuts import vector as v\nfrom grass.pygrass.gis import *\nimport grass.script as grass\nimport grass.script.setup as gsetup\nimport re\n\n\n\n\n# Main function\ndef main(gisdb, location, mapset): \n\n    shapefile = 'IndiaBoundary.geojson' \n\n    os.environ['GISDBASE'] = gisdb\n    os.environ['LOCATION_NAME'] = location\n\n    # Check if mapset exists; if not, create it\n    mapset_path = os.path.join(gisdb, location, mapset)\n    if not os.path.exists(mapset_path):\n        print(f\"Mapset '{mapset}' does not exist. Creating new mapset...\")\n        # Create the new mapset\n        gs.run_command('g.mapset', flags='c', mapset=mapset, location=location, dbase=GISDBASE)\n    else:\n        print(f\"Mapset '{mapset}' already exists.\")\n\n    # Initialize GRASS session\n    gsetup.init(gisdb, location, mapset)\n    print(f\"GRASS GIS session initialized in {gisdb}/{location}/{mapset}\")\n\n\n\n    vector_name = os.path.splitext(os.path.basename(shapefile))[0]\n\n\n    # Import shapefile\n    gs.run_command('v.import', input=shapefile, output=vector_name, overwrite=True)\n\n    g.mapsets(mapset=\"nrsc_lulc\", operation=\"add\")\n\n\n    # Set region\n    gs.run_command('g.region', vector=vector_name, res=0.00292)\n\n    start_yr = '2023'\n    end_yr = '2023'\n\n\n    timerange = range(int(start_yr), int(end_yr) + 1)\n    years = list(timerange)\n\n    years_str = [f\"{y}_{y + 1}\" for y in years]\n\n    print(\"years_str\")\n    print(years_str)\n\n\n    for y in years_str:\n        # Apply raster mask\n        # gs.run_command('r.mask', raster=f'LULC_250k_{y}', maskcats='2 3 4 5 7', overwrite=True)\n        gs.run_command('r.mask', raster=f'LULC_250k_2022_2023', maskcats='2 3 4 5 7', overwrite=True)\n\n        # Perform map calculations\n        gs.mapcalc(f\"wapor_eta_a_cropland_{y} = wapor_eta_a_{y}\", overwrite=True)\n        gs.mapcalc(f\"wapor_tbp_a_cropland_{y} = wapor_tbp_a_{y}\", overwrite=True)\n        gs.mapcalc(f\"wapor_bwp_a_{y} = wapor_tbp_a_{y} / (wapor_eta_a_{y} * 10)\",overwrite=True)\n        gs.run_command('r.mask', flags='r')\n\n\nif __name__ == '__main__':\n    GISDBASE = \"/Volumes/ExternalSSD/eqipa_data/grassdata\"\n    LOCATION_NAME = \"eqipa\"\n    MAPSET = \"data_annual\"                 \n\n    # Call the main function\n    main(GISDBASE, LOCATION_NAME, MAPSET)\n</code></pre>"},{"location":"grass/vector_basics/","title":"Vector Operations","text":"<p>This section explains key vector operations in GRASS GIS using command-line modules. These include buffering, overlays, filtering, attribute queries, and conversions \u2014 all handled in terminal mode.</p>"},{"location":"grass/vector_basics/#list-vector-maps","title":"List Vector Maps","text":"<pre><code># List all available vector maps in the current mapset:\ng.list type=vector\n\n# Get basic information about a vector map:\nv.info map=roads\n\n# Check the attribute table:\nv.db.select map=roads\n</code></pre>"},{"location":"grass/vector_basics/#create-buffers-around-features","title":"Create Buffers Around Features","text":"<pre><code># Use v.buffer to create buffer zones (e.g., 1000-meter buffer around roads):\nv.buffer input=roads output=roads_buffer distance=1000\n</code></pre>"},{"location":"grass/vector_basics/#select-and-extract-features","title":"Select and Extract Features","text":"<pre><code># Select and Extract Features by Attribute\n# Use v.extract to filter features using SQL-like queries.\nv.extract input=roads output=highways where=\"type = 'highway'\"\n\n# Check the attribute table:\nv.db.select map=roads\n</code></pre>"},{"location":"grass/vector_basics/#overlay-vector-layers","title":"Overlay Vector Layers","text":"<pre><code># Intersect\nv.overlay ainput=landuse binput=admin_boundaries operator=and output=landuse_admin\n# Union:\nv.overlay ainput=layer1 binput=layer2 operator=or output=combined_layer\n\n# Dissolve: Merge adjacent polygons with the same attribute\nv.dissolve input=landuse output=landuse_dissolved column=category\n</code></pre>"},{"location":"grass/vector_basics/#convert-between-raster-and-vector","title":"Convert Between Raster and Vector","text":"<pre><code># Raster to Vector:\nr.to.vect input=classified_map output=land_units type=area\n\n\n# Vector to Raster:\nv.to.rast input=land_units output=land_raster use=cat\n</code></pre>"},{"location":"grass/vector_basics/#reproject-a-vector-map","title":"Reproject a Vector Map","text":"<pre><code># To reproject from one location to another, use v.proj inside the target location\nv.proj location=source_location mapset=PERMANENT input=roads output=roads_projected\n</code></pre>"},{"location":"grass/vector_basics/#export-vector-maps","title":"Export Vector Maps","text":"<pre><code># Export to Shapefile or GeoPackage:\nv.out.ogr input=roads_buffer output=roads_buffer.shp format=ESRI_Shapefile\n\n# Export to GeoJSON:\nv.out.ogr input=roads output=roads.geojson format=GeoJSON\n</code></pre>"},{"location":"grass/zonalstats/","title":"Zonal Statistics (Terminal)","text":"<p>Zonal statistics summarize raster values (e.g., mean, sum, count) within vector zones such as administrative boundaries, watersheds, or land parcels. This guide explains how to perform zonal statistics in GRASS GIS using a GeoJSON boundary file and a raster map.</p>"},{"location":"grass/zonalstats/#import-vector-boundary-geojson","title":"Import Vector Boundary (GeoJSON)","text":"<p>Use <code>v.in.ogr</code> to import a GeoJSON file:</p> <pre><code>v.in.ogr input=/path/to/boundaries.geojson output=zones\n</code></pre> <p>\ud83d\udd0d Check if the projection of your GeoJSON matches the current GRASS location. If not, reproject the vector (see section below).</p>"},{"location":"grass/zonalstats/#import-raster-map","title":"Import Raster Map","text":"<p>Use r.import to bring in a GeoTIFF or similar raster file:</p> <pre><code>r.import input=/path/to/raster.tif output=my_raster\n</code></pre>"},{"location":"grass/zonalstats/#set-computational-region","title":"Set Computational Region","text":"<p>Match the region to your raster map:</p> <pre><code>g.region raster=my_raster -p\n\n# (Optional) Expand region to fully cover vector zones:\ng.region vector=zones align=my_raster\n</code></pre>"},{"location":"grass/zonalstats/#perform-zonal-statistics-with-vraststats","title":"Perform Zonal Statistics with v.rast.stats","text":"<p>Use the vector map (zones) to compute stats from the raster (my_raster) for each polygon:</p> <pre><code>v.rast.stats map=zones raster=my_raster column_prefix=stats method=average,sum,count\n</code></pre> <ul> <li>column_prefix: Adds columns like stats_mean, stats_sum, etc.</li> <li>method: Can be one or more of: average, sum, count, min, max, stddev</li> </ul> <p>This updates the attribute table of the vector map with the calculated values.</p>"},{"location":"grass/zonalstats/#view-results","title":"View Results","text":"<p>Display the updated attribute table:</p> <pre><code>v.db.select map=zones\n</code></pre>"},{"location":"grass/zonalstats/#optional-export-the-results-to-geojson-or-shapefile","title":"Optional: Export the Results to GeoJSON or Shapefile","text":"<pre><code># Export GeoJSON\nv.out.ogr input=zones output=zones_stats.geojson format=GeoJSON\n\n# or Export Shapefile\nv.out.ogr input=zones output=zones_stats.shp format=ESRI_Shapefile\n\n# or Export Attribute Table to CSV\nv.db.select map=zones separator=comma file=zones_stats.csv\n</code></pre>"},{"location":"grass/zonalstats/#optional-reproject-geojson-if-needed","title":"(Optional) Reproject GeoJSON if Needed","text":"<p>If your GeoJSON CRS doesn't match the current GRASS location, you can either:</p> <ul> <li>Reproject using GDAL before importing, or</li> <li>Import it into a matching GRASS location, and use v.proj</li> </ul> <pre><code># Run this inside your target location\nv.proj location=source_location mapset=PERMANENT input=zones output=zones_reprojected\n</code></pre>"},{"location":"grass/zonalstats/#grass-python-scripts","title":"GRASS Python Scripts","text":"<pre><code># Create a Python 3 virtual environment \npython3 -m venv venv\n\n# Activate the virtual environment\nsource venv/bin/activate\n\n# Install dependencies with `pip`\npip install pandas numpy geopandas openpyxl\n\n# or from requirements.txt\npip install -r requirements.txt\npip3 freeze &gt; requirements.txt\n</code></pre>"},{"location":"grass/zonalstats/#python-script-monthly-zonal-stats","title":"Python Script: Monthly Zonal Stats","text":"<p>Monthly Zonal Stats</p> <pre><code>import os\nimport sys\nimport subprocess\nimport shutil\nimport calendar\nimport math\nimport grass.script as gs\nfrom grass.pygrass.modules.shortcuts import general as g\nfrom grass.pygrass.modules.shortcuts import raster as r\nfrom grass.pygrass.modules.shortcuts import display as d\nfrom grass.pygrass.modules.shortcuts import vector as v\nfrom grass.pygrass.gis import *\nimport grass.script as grass\nimport grass.script.setup as gsetup\nimport re\nimport numpy as np\nimport geopandas as gdf\nimport pandas as pd\nimport io\n\n\n# Main function\ndef main(gisdb, location, mapset): \n\n    geojson_file = 'StatesBoundary.geojson'\n    output_csv_path=f\"IndiaStates_monthly_zonalstats.csv\"\n    start_yr = '2023'\n    end_yr = '2024'\n\n    os.environ['GISDBASE'] = gisdb\n    os.environ['LOCATION_NAME'] = location\n\n    # Check if mapset exists; if not, create it\n    mapset_path = os.path.join(gisdb, location, mapset)\n    if not os.path.exists(mapset_path):\n        print(f\"Mapset '{mapset}' does not exist. Creating new mapset...\")\n        # Create the new mapset\n        gs.run_command('g.mapset', flags='c', mapset=mapset, location=location, dbase=GISDBASE)\n    else:\n        print(f\"Mapset '{mapset}' already exists.\")\n\n    # Initialize GRASS session\n    gsetup.init(gisdb, location, mapset)\n    print(f\"GRASS GIS session initialized in {gisdb}/{location}/{mapset}\")\n\n\n    vector_name = os.path.splitext(os.path.basename(geojson_file))[0]\n\n    v.import_(input=geojson_file, output=vector_name, overwrite=True)\n\n    g.mapsets(mapset=\"nrsc_lulc,data_annual,data_monthly\", operation=\"add\")\n\n    gs.run_command('g.region', vector=vector_name, res=0.00292)\n\n\n    for year in range(int(start_yr), int(end_yr) + 1):\n        for month in range(1,13):\n\n            raster_name=f\"imd_pcp_resam_m_{year}_{month:02d}\"\n            gs.run_command('v.rast.stats', map=vector_name, raster=raster_name, \n                column_prefix=raster_name, \n                #    method='percentile',\n                    # percentile=98,\n                method='average', \n                #    method='coeff_var', \n                # method='stddev',\n                overwrite=True)\n\n    stats_output = gs.read_command(\n        'v.db.select', map=vector_name, format=\"csv\", overwrite=True\n    )\n\n    # Use StringIO to read the data into a Pandas DataFrame\n    data = io.StringIO(stats_output)\n    df = pd.read_csv(data)\n\n    # Export the DataFrame to a CSV file\n    df.to_csv(output_csv_path, index=False)\n\n\n    print(f\"zonalstats exported successfully: {vector_name}\")\n\n\n\n\nif __name__ == '__main__':\n    GISDBASE = \"/Volumes/ExternalSSD/eqipa_data/grassdata\"\n    LOCATION_NAME = \"eqipa\"\n    MAPSET = \"eqipa_stats\"                 \n\n    # Call the main function\n    main(GISDBASE, LOCATION_NAME, MAPSET)\n</code></pre>"},{"location":"grass/zonalstats/#python-script-eqipa-overview-stats","title":"Python script: EQIPA Overview Stats","text":"<p>We will build a Python script that:</p> <ul> <li>Initializes a GRASS session</li> <li>Imports a vector (GeoJSON) file</li> <li>Calculates zonal statistics for multiple rasters</li> <li>Derives Irrigation Performance Indicators (IPA) like Equity, Adequacy, and Cropping Intensity</li> <li>Exports results to Excel</li> </ul>"},{"location":"grass/zonalstats/#analysis-workflow","title":"Analysis Workflow","text":"<p>The script includes the following:</p> <ul> <li>Imports the GeoJSON vector layer</li> <li>Computes zonal statistics (v.rast.stats) on multiple rasters</li> <li>Computes IPA metrics like Equity and Adequacy</li> <li>Calculates Cropland and Gross Cropped Area from pixel counts</li> <li>Exports to Excel with two sheets (Info and Stats)</li> <li>See the Full Python Script below for the complete implementation.</li> </ul> <p>Full Python Script</p> <pre><code>import os\nimport sys\nimport subprocess\nimport shutil\nimport calendar\nimport math\nimport grass.script as gs\nfrom grass.pygrass.modules.shortcuts import general as g\nfrom grass.pygrass.modules.shortcuts import raster as r\nfrom grass.pygrass.modules.shortcuts import display as d\nfrom grass.pygrass.modules.shortcuts import vector as v\nfrom grass.pygrass.gis import *\nimport grass.script as grass\nimport grass.script.setup as gsetup\nimport re\nimport numpy as np\nimport geopandas as gdf\nimport pandas as pd\n\n\n\n# Main function\ndef main(gisdb, location, mapset): \n\n    geojson_file = 'StatesBoundary.geojson'\n    selectedYear=\"2023_2024\"\n\n    os.environ['GISDBASE'] = gisdb\n    os.environ['LOCATION_NAME'] = location\n\n    # Check if mapset exists; if not, create it\n    mapset_path = os.path.join(gisdb, location, mapset)\n    if not os.path.exists(mapset_path):\n        print(f\"Mapset '{mapset}' does not exist. Creating new mapset...\")\n        # Create the new mapset\n        gs.run_command('g.mapset', flags='c', mapset=mapset, location=location, dbase=GISDBASE)\n    else:\n        print(f\"Mapset '{mapset}' already exists.\")\n\n    # Initialize GRASS session\n    gsetup.init(gisdb, location, mapset)\n    print(f\"GRASS GIS session initialized in {gisdb}/{location}/{mapset}\")\n\n\n    print(\"selected_year\",selectedYear)\n\n    file_name = os.path.splitext(geojson_file)[0]\n\n    vector_name = re.sub(r'[^a-zA-Z0-9_]', '_', file_name)\n\n    # Ensure the name starts with a letter\n    if not vector_name[0].isalpha():\n        vector_name = \"v_\" + vector_name  # Prefix with \"v_\"\n\n    # Truncate if too long (max 256 chars)\n    vector_name = vector_name[:256]\n\n\n    output_excel_path=f\"{vector_name}_{selectedYear}_zonalstats.xlsx\"\n\n    v.import_(input=geojson_file, output=vector_name, overwrite=True)\n    g.mapsets(mapset=\"nrsc_lulc,data_annual\", operation=\"add\")\n\n\n    grass.run_command(\n        \"v.to.db\",\n        map=vector_name,\n        option=\"area\",\n        columns=\"geographical_area_ha\",\n        units=\"hectares\",\n        overwrite=True\n    )\n\n\n    # Set the region to match the raster\n    # g.region(vector=vector_name, res=0.001)\n    g.region(vector=vector_name, res=0.001)\n    # 0.003 degrees \u2248 111 km * 0.003 \u2248 333 meters.\n    # 0.001 degrees \u2248 111 km * 0.001 \u2248 111 meters.\n\n    # LULC: 56m\n    # WaPOR ETa: 300m\n    # WaPOR TBP: 300m\n    # IMD PCP: 0.25 degree\n\n\n    # lcc_map=f\"LULC_250k_{selectedYear}\"\n    lcc_map=f\"LULC_250k_2022_2023\"\n    eta_map=f\"wapor_eta_a_{selectedYear}\"\n    tbp_map=f\"wapor_tbp_a_{selectedYear}\"\n    pcp_map=f\"imd_pcp_resamp_a_{selectedYear}\"\n    bwp_map =f\"wapor_bwp_a_{selectedYear}\"\n\n\n    grass.parse_command(\n            'v.rast.stats',\n            map=vector_name,\n            raster=eta_map,\n            method=['average'],\n            column_prefix=f'ETa_{selectedYear}',\n            overwrite=True\n        )\n\n    grass.parse_command(\n            'v.rast.stats',\n            map=vector_name,\n            raster=pcp_map,\n            method=['average'],\n            column_prefix=f'PCP_{selectedYear}',\n            overwrite=True\n        )\n\n\n    r.mask(raster=lcc_map, maskcats='2 3 4 5 7')\n\n    grass.mapcalc(f\"{bwp_map} = {tbp_map} / ({eta_map} * 10)\",overwrite=True)\n\n\n    grass.parse_command(\n        'v.rast.stats',\n        map=vector_name,\n        raster=eta_map,\n        method=[\"average\",\"coeff_var\" ],\n        column_prefix=f'ETa_cropland_{selectedYear}',\n        overwrite=True\n    )\n    grass.parse_command(\n            \"v.rast.stats\",\n            map=vector_name,\n            raster=eta_map,\n            column_prefix=f'ETa_cropland_{selectedYear}',\n            method=\"percentile\",\n            percentile=98,\n            overwrite=True,\n        )\n\n\n    grass.parse_command(\n            \"v.rast.stats\",\n            map=vector_name,\n            raster=tbp_map,\n            column_prefix=f'BLP_{selectedYear}',\n            method=[ \"average\"],\n            overwrite=True,\n        )\n\n    grass.parse_command(\n        \"v.rast.stats\",\n        map=vector_name,\n        raster=bwp_map,\n        column_prefix=f'BWP_{selectedYear}',\n        method=[ \"average\"],\n        overwrite=True,\n    )\n\n    r.mask(flags=\"r\")\n\n    cropland_classes = {\n            'exclusive_kharif': '2',\n            'exclusive_rabi': '3',\n            'exclusive_zaid': '4',\n            'double_crop': '5',\n            'plantation': '7'\n    }\n\n    # Iterate over each class and perform zonal statistics\n    for class_name, maskcats in cropland_classes.items():\n        # Apply mask\n        r.mask(raster=lcc_map, maskcats=maskcats)\n\n        grass.parse_command(\n            \"v.rast.stats\",\n            map=vector_name,\n            raster=lcc_map,\n            column_prefix=f\"{class_name}_pixelcount\",\n            method=[\"number\"],\n            overwrite=True,\n        )\n\n\n        # Remove mask\n        r.mask(flags=\"r\")\n\n    output_csv_path = output_excel_path.replace(\".xlsx\", \".csv\")\n\n    v.out_ogr(\n        input=vector_name,\n        output=output_csv_path,\n        format=\"CSV\",\n        overwrite=True\n    )\n\n    g.region(flags=\"d\")  \n\n\n    df = pd.read_csv(output_csv_path)\n    df = df.drop_duplicates()  \n    df.drop(columns=['cat'], inplace=True, errors='ignore')\n\n\n    coeff_var_col = f\"ETa_cropland_{selectedYear}_coeff_var\"\n    avg_col = f\"ETa_cropland_{selectedYear}_average\"\n    perc_98_col = f\"ETa_cropland_{selectedYear}_percentile_98\"\n    equity_col = f\"Equity\"\n    adequacy_col = f\"Adequacy\"\n\n\n\n    # Calculate Equity and Adequacy\n    if (\n        coeff_var_col in df.columns and \n        avg_col in df.columns and \n        perc_98_col in df.columns and \n        (df[coeff_var_col] != 0).any() and \n        (df[avg_col] != 0).any() and \n        (df[perc_98_col] != 0).any()\n    ):\n        df[equity_col] = 100 - df[coeff_var_col]\n        df[adequacy_col] = (df[avg_col] * 100) / df[perc_98_col]\n    else:\n        print(f\"Columns missing for class {class_name}. Skipping Equity and Adequacy calculations.\")\n\n    df.drop(columns=[ perc_98_col], errors='ignore', inplace=True)\n\n\n\n    for class_name in cropland_classes.keys():\n        pixel_count_col = f\"{class_name}_pixelcount_number\"\n        area_col = f\"{class_name}_area_ha\"  \n        # Calculate area in hectares for the class\n        if pixel_count_col in df.columns:\n            # df[area_col] = df[pixel_count_col] * 3020 / 10000  \n            df[area_col] = df[pixel_count_col] * 2978 / 10000  \n            df.drop(columns=[pixel_count_col], errors='ignore', inplace=True)\n\n\n    cropland_area_cols = [f\"{class_name}_area_ha\" for class_name in cropland_classes.keys()]\n    df[\"Cropland_Area_ha\"] = df[cropland_area_cols].sum(axis=1)  # Sum all class areas\n\n    for col in [f\"{class_name}_area_ha\" for class_name in cropland_classes.keys()]:\n        if col not in df.columns:\n            df[col] = 0\n        df[col] = df[col].fillna(0)\n\n\n    df[\"Gross_Cropped_Area_ha\"] = (\n        df[\"exclusive_kharif_area_ha\"]\n        + df[\"exclusive_rabi_area_ha\"]\n        + df[\"exclusive_zaid_area_ha\"]\n        + (df[\"double_crop_area_ha\"] * 2)\n        + df[\"plantation_area_ha\"]\n    )\n    df[\"Cropping_Intensity\"] = df[\"Gross_Cropped_Area_ha\"] *100/ df[\"Cropland_Area_ha\"]\n    df[\"Cropping_Intensity\"] = df[\"Cropping_Intensity\"].replace([np.inf, -np.inf, np.nan], 0)\n\n\n    df = df.round(2)\n    df.to_csv(output_csv_path, index=False)\n\n\n\n    print(f\"zonalstats exported successfully: {vector_name}\")\n\n\n\n\nif __name__ == '__main__':\n    GISDBASE = \"/Volumes/ExternalSSD/eqipa_data/grassdata\"\n    LOCATION_NAME = \"eqipa\"\n    MAPSET = \"eqipa_stats\"                 \n\n    # Call the main function\n    main(GISDBASE, LOCATION_NAME, MAPSET)\n</code></pre>"},{"location":"tool-setup/apache/","title":"\ud83c\udf10 Apache Configuration","text":"<p>This section explains how to configure Apache to serve the EQIPA Django project using uWSGI and enable SSL using Let's Encrypt via Certbot.</p>"},{"location":"tool-setup/apache/#1-copy-apache-virtual-host-configuration","title":"1: Copy Apache Virtual Host Configuration","text":"<p>Copy the example configuration to the Apache sites-available directory:</p> <pre><code>sudo cp /home/aman/ipa_india/webapp/ipa_india/ipa_india.conf /etc/apache2/sites-available/ipa_india.conf\n</code></pre> ipa_india.conf <pre><code>&lt;VirtualHost *:80&gt;\n    ServerName eqipa.waterinag.org\n\nAlias /static/ /home/aman/ipa_india/webapp/ipa_india/static/\n\n    &lt;Directory /home/aman/ipa_india/webapp/ipa_india/ipa_india&gt;\n        &lt;Files wsgi.py&gt;\n            Require all granted\n        &lt;/Files&gt;\n    &lt;/Directory&gt;\n\n&lt;Location /static&gt;\n                SetHandler none\n                Options -Indexes\n        &lt;/Location&gt;\n\n        &lt;Location /media&gt;\n                SetHandler none\n                Options -Indexes\n        &lt;/Location&gt;\n\n        Alias /media/ /home/aman/ipa_india/webapp/ipa_india/media/\n\n        Alias /static/ /home/aman/ipa_india/webapp/ipa_india/static/\n\n        &lt;Directory /home/aman/ipa_india/webapp/ipa_india/&gt;\n                Require all granted\n        &lt;/Directory&gt;\n\n        &lt;Directory /home/aman/ipa_india/webapp/ipa_india/static&gt;\n                Options FollowSymLinks\n                Order allow,deny\n                Allow from all\n        &lt;/Directory&gt;\n\n        &lt;Directory /home/aman/ipa_india/webapp/ipa_india/media&gt;\n                Options FollowSymLinks\n                Order allow,deny\n                Allow from all\n        &lt;/Directory&gt;\n\n    ProxyPass / unix:/home/aman/ipa_india/webapp/ipa_india/ipa_india.sock|uwsgi://localhost/\n    # Proxying the connection to uWSGI\n\n    # ProxyPass / unix:/home/aman/ipa_india/webapp/ipa_india/ipa_india.sock|uwsgi://localhost/\n    ErrorLog ${APACHE_LOG_DIR}/ipa_india_error.log\n    CustomLog ${APACHE_LOG_DIR}/ipa_india_access.log combined\n\n\n&lt;/VirtualHost&gt;\n</code></pre> <p>Make sure to update paths in the config to match your project directory.</p>"},{"location":"tool-setup/apache/#2-enable-required-apache-modules","title":"2: Enable Required Apache Modules","text":"<pre><code>sudo a2enmod uwsgi\nsudo a2enmod ssl\n</code></pre>"},{"location":"tool-setup/apache/#3-enable-the-site","title":"3: Enable the Site","text":"<pre><code>sudo a2ensite ipa_india.conf\n</code></pre> <p>Verify Apache Configuration</p> <p><pre><code>sudo apachectl configtest\n</code></pre> You should see: <code>Syntax OK</code></p> <p>Restart Apache to apply changes:</p> <pre><code>sudo systemctl reload apache2\nsudo systemctl restart apache2\n</code></pre>"},{"location":"tool-setup/apache/#4-enable-ssl-with-certbot","title":"4: Enable SSL with Certbot","text":"<p>Install Certbot:</p> <pre><code>sudo apt install certbot python3-certbot-apache\n</code></pre> <p>Enable HTTPS with your domain:</p> <pre><code>sudo certbot --apache -d eqipa.waterinag.org\n</code></pre> <p>Restart Apache to apply changes:</p> <pre><code>sudo systemctl restart apache2\n</code></pre>"},{"location":"tool-setup/apache/#apache-site-commands-summary","title":"\ud83d\udcc2 Apache Site Commands Summary","text":""},{"location":"tool-setup/apache/#enable-site","title":"Enable site","text":"<pre><code>sudo a2ensite eqipa.waterinag.org.conf\n</code></pre>"},{"location":"tool-setup/apache/#disable-site","title":"Disable site","text":"<pre><code>sudo a2dissite eqipa.waterinag.org.conf\n</code></pre>"},{"location":"tool-setup/apache/#list-enabled-sites","title":"List enabled sites","text":"<pre><code>ls -l /etc/apache2/sites-enabled\n</code></pre>"},{"location":"tool-setup/apache/#logs-and-troubleshooting","title":"\ud83d\udd0e Logs and Troubleshooting","text":""},{"location":"tool-setup/apache/#view-apache-error-log","title":"View Apache error log","text":"<pre><code>sudo tail -f /var/log/apache2/ipa_india_error.log\n</code></pre>"},{"location":"tool-setup/apache/#check-uwsgi-log","title":"Check uWSGI log","text":"<pre><code>tail -f /home/aman/ipa_india/webapp/ipa_india/log/ipa_india.log\n</code></pre> <p>Ensure Apache's config is pointing to the correct uWSGI socket and the socket file has proper read/write permissions.</p> <p>\u2705 Apache is now configured and serving your EQIPA application securely over HTTPS!</p>"},{"location":"tool-setup/deployment/","title":"\ud83d\ude80 Deployment in Production","text":"<p>This guide covers how to deploy the EQIPA Django app to a production server using Celery, uWSGI, and Apache2.</p>"},{"location":"tool-setup/deployment/#celery-worker-as-a-systemd-service","title":"Celery Worker as a Systemd Service","text":"<p>Celery is used to handle background tasks such as report generation.</p>"},{"location":"tool-setup/deployment/#1-create-pid-directory","title":"1: Create PID Directory","text":"<pre><code>sudo mkdir /var/run/celery/\nsudo chown -R $USER:$USER /var/run/celery/\nsudo chown -R aman:aman /var/run/celery/\n</code></pre>"},{"location":"tool-setup/deployment/#2-add-celery-service-to-systemd","title":"2: Add Celery Service to Systemd","text":"<pre><code>sudo ln -s /home/aman/ipa_india/webapp/ipa_india/celery_ipa_india.service /etc/systemd/system\n</code></pre> <p>Make sure to update the necessary fields in celery_ipa_india.service .. EnvironmentFile=-/home/aman/ipa_india/webapp/ipa_india/celery.conf .. WorkingDirectory=/home/aman/ipa_india/webapp/ipa_india/</p>"},{"location":"tool-setup/deployment/#3-reload-and-enable-service","title":"3: Reload and Enable Service","text":"<pre><code>sudo systemctl daemon-reload\nsudo systemctl enable celery_ipa_india.service\nsudo systemctl start celery_ipa_india.service\n\n# enable the service to be automatically start on boot\nsudo systemctl status celery_ipa_india.service\n</code></pre> celery_ipa_india.service <pre><code>[Unit]\nDescription=Celery Service for ipa_india app\nAfter=network.target\n\n[Service]\nType=forking\nUser=aman\nGroup=aman\nEnvironmentFile=/home/aman/ipa_india/webapp/ipa_india/celery.conf\nWorkingDirectory=/home/aman/ipa_india/webapp/ipa_india/\nExecStart=/bin/sh -c '${CELERY_BIN} -A ${CELERY_APP} multi start ${CELERYD_NODES} \\\n    --pidfile=${CELERYD_PID_FILE} --logfile=${CELERYD_LOG_FILE} \\\n    --loglevel=${CELERYD_LOG_LEVEL} ${CELERYD_OPTS}'\nExecStop=/bin/sh -c '${CELERY_BIN} multi stopwait ${CELERYD_NODES} \\\n    --pidfile=${CELERYD_PID_FILE} --loglevel=${CELERYD_LOG_LEVEL}'\nExecReload=/bin/sh -c '${CELERY_BIN} -A ${CELERY_APP} multi restart ${CELERYD_NODES} \\\n    --pidfile=${CELERYD_PID_FILE} --logfile=${CELERYD_LOG_FILE} \\\n    --loglevel=${CELERYD_LOG_LEVEL} ${CELERYD_OPTS}'\nRestart=always\n\n[Install]\nWantedBy=multi-user.target\n</code></pre>"},{"location":"tool-setup/deployment/#check-celery-logs","title":"Check Celery Logs","text":"<pre><code>tail -f /home/aman/ipa_india/webapp/ipa_india/log/celery/worker1.log\n</code></pre>"},{"location":"tool-setup/deployment/#uwsgi-setup","title":"uWSGI Setup","text":""},{"location":"tool-setup/deployment/#run-django-app-via-uwsgi","title":"Run Django App via uWSGI","text":"<p>Ensure your virtual environment is activated, then run:</p> <pre><code>uwsgi --ini ipa_india.ini\n</code></pre> <p>Make sure to update the necessary fields in ipa_india.ini</p> ipa_india.ini <pre><code>[uwsgi]\nchdir           = /home/aman/ipa_india/webapp/ipa_india\nmodule          = ipa_india.wsgi\nhome            = /home/aman/ipa_india/webapp/venv\nenv = DJANGO_SETTINGS_MODULE=ipa_india.settings\nmaster          = true\nprocesses       = 5\nthreads = 2\nsocket          = /home/aman/ipa_india/webapp/ipa_india/ipa_india.sock\nchmod-socket    = 666\nvacuum          = true\ndaemonize = /home/aman/ipa_india/webapp/ipa_india/log/ipa_india.log\npost-buffering = True\nroute-run = harakiri:180\n</code></pre> <p>This will launch the Django application using your <code>.ini</code> configuration.</p>"},{"location":"tool-setup/deployment/#restarting-celery-and-uwsgi-after-code-changes","title":"Restarting Celery and uWSGI After Code Changes","text":"<pre><code># reload the systemd files (this has been done everytime celery_ipa_india.service is changed)\nsudo systemctl daemon-reload\n\n#Stop Celery Service\nsudo systemctl stop celery_ipa_india.service\n\n#Start Celery Service\nsudo systemctl start celery_ipa_india.service\n\n#Verify Celery is Running Correctly\nsudo systemctl status celery_ipa_india.service\n\n#Kill Remaining Celery Processes\nsudo pkill -9 -f 'celery worker'\n\n#Ensure All Processes Are Stoppedps aux | grep celery\nps aux | grep celery`\n\n#Monitoring Logs\ntail -f /home/aman/ipa_india/log/celery/worker1-7.log\ntail -f /home/aman/ipa_india/log/celery/worker1-6.log\ntail -f /home/aman/ipa_india/log/celery/worker1.log\n\n# or all at once:\nfor file in /home/aman/ipa_india/log/celery/*.log; do\n    echo \"Checking $file\"\n    tail -n 20 $file\ndone\n\n\n# check all the running uWSGI workers\nps aux | grep uwsgi\n\n# To stop uWSGI\nsudo killall -9 uwsgi\n\n#Restart uWSGI (first activate the venv)\nuwsgi --ini ipa_india.ini\n</code></pre>"},{"location":"tool-setup/deployment/#summary-of-configuration-files","title":"Summary of Configuration Files","text":"<ul> <li><code>celery_ipa_india.service</code>: systemd unit file for Celery</li> <li><code>ipa_india.ini</code>: uWSGI configuration file</li> <li><code>template_apache.conf</code>: Apache virtual host config</li> </ul> <p>\u2705 Once both Celery and uWSGI are running, you're ready to link them to Apache2 (covered next in Apache Configuration).</p>"},{"location":"tool-setup/development-mode/","title":"\ud83d\udcbb Running Tool in Development Mode","text":"<p>This guide explains how to set up and run the EQIPA Django app in a development environment.</p>"},{"location":"tool-setup/development-mode/#1-copy-the-code-to-the-system","title":"1: Copy the code to the system","text":""},{"location":"tool-setup/development-mode/#2-create-and-activate-a-virtual-environment","title":"2: Create and Activate a Virtual Environment","text":"<p>Create a Python 3 virtual environment inside the <code>webapp</code> folder:</p> <pre><code>python3 -m venv venv\nsource venv/bin/activate\n</code></pre>"},{"location":"tool-setup/development-mode/#3-install-python-dependencies","title":"3: Install Python Dependencies","text":"<p>Install all required packages using the <code>requirements.txt</code> file:</p> <pre><code>pip install -r requirements.txt\n</code></pre>"},{"location":"tool-setup/development-mode/#4-configure-django-settings","title":"4: Configure Django Settings","text":"<p>Open <code>ipa_india/settings.py</code> and update the following:</p> <ul> <li><code>ALLOWED_HOSTS</code></li> <li><code>CSRF_TRUSTED_ORIGINS</code></li> <li><code>BASE_URL</code></li> <li><code>DATABASES</code> section \u2192 add username, password, and DB name</li> <li><code>GRASS_DB</code> path \u2192 e.g., <code>/mnt/mapdata/grassdata/ipa_india</code></li> <li><code>GRASS_LOCATION</code></li> </ul>"},{"location":"tool-setup/development-mode/#5-apply-migrations-collect-static-files","title":"5: Apply Migrations &amp; Collect Static Files","text":"<p>Run the following commands to prepare your database and static files:</p> <pre><code>python manage.py makemigrations webapp\npython manage.py migrate\npython manage.py collectstatic\n</code></pre>"},{"location":"tool-setup/development-mode/#6-create-a-superuser","title":"6: Create a Superuser","text":"<pre><code>python manage.py createsuperuser --username admin\n</code></pre> <p>Sample credentials:</p> <ul> <li>Username: <code>admin</code></li> <li>Email: <code>your-email@gmail.com</code></li> <li>Password: <code>your-pass</code></li> </ul>"},{"location":"tool-setup/development-mode/#7-test-local-server","title":"7: Test Local Server","text":"<p>Run the Django development server:</p> <pre><code>python manage.py runserver\n</code></pre> <p>To access from another device on the same network:</p> <pre><code>python manage.py runserver 0.0.0.0:8001\n</code></pre> <p>Now open your browser at:</p> <ul> <li>http://127.0.0.1:8000</li> <li>or your local IP, e.g.: <code>http://ServerIP:8001/</code></li> </ul> <p>Start Celery worker using:</p> <pre><code>celery -A ipa_india worker -l INFO\n</code></pre> <p>To run Celery inside a <code>screen</code> session:</p> <pre><code>screen -S ipa_celery\ncelery -A ipa_india worker -l INFO\n</code></pre> <p>To detach from the screen session:</p> <pre><code>Ctrl + A, then D\n</code></pre> <p>To reattach:</p> <pre><code>screen -r ipa_celery\n</code></pre> <p>\ud83d\udce6 Screen</p> <p>Learn more: How to Use Linux Screen</p> <p>Use <code>screen</code> to manage background processes like Celery or the Django dev server:</p> <p>Install Linux Screen on Ubuntu and Debian: <pre><code>sudo apt update\nsudo apt install screen\n</code></pre> \ud83d\udd04 Attach to a screen: <pre><code>screen -r &lt;screen_name&gt;\n</code></pre></p> <p>\ud83d\udd0d Check running screens: <pre><code>screen -r\n</code></pre></p> <p>\ud83d\udd19 Detach a screen: <pre><code>screen -d &lt;screen_name&gt;\n</code></pre></p> <p>\u274c Delete (terminate) a screen: <pre><code>screen -S &lt;screen_name&gt; -X quit\n</code></pre></p> <p>\ud83c\udd95 Start a new screen session: <pre><code>screen -S &lt;screen_name&gt;\n</code></pre></p> <p>Detach from a screen <pre><code>Ctrl + A, then D\n</code></pre></p>"},{"location":"tool-setup/development-mode/#admin-site-setup","title":"Admin Site Setup","text":"<p>When running the server for the first time, visit:</p> <pre><code>http://ServerIP:8000/admin\n</code></pre> <p>Go to the \"Sites\" tab and update the domain to match your current host:</p> <ul> <li>For local testing: <code>127.0.0.1:8000</code></li> <li>For production: your domain name</li> </ul> <p>This ensures correct rendering of templates during report generation.</p> <p>\u2705 Your development server is now ready!</p>"},{"location":"tool-setup/errors/","title":"\u2757 Common Errors &amp; Fixes","text":"<p>This page lists common issues encountered while setting up or deploying the EQIPA application, along with tested solutions.</p>"},{"location":"tool-setup/errors/#file-permission-errors","title":"File Permission Errors","text":""},{"location":"tool-setup/errors/#error","title":"Error","text":"<p>Logs show permission denied when accessing socket or log files.</p>"},{"location":"tool-setup/errors/#solution","title":"Solution","text":"<pre><code>sudo chown -R www-data:www-data /home/aman/ipa_india/webapp/ipa_india\nsudo chown -R aman:aman /home/aman/ipa_india/webapp/ipa_india/log/\nsudo chmod -R 755 /home/aman/ipa_india/webapp/ipa_india/log/\n</code></pre>"},{"location":"tool-setup/errors/#uwsgi-modifier-error","title":"uWSGI Modifier Error","text":""},{"location":"tool-setup/errors/#error-in-uwsgi-logs","title":"Error (in uWSGI logs)","text":"<pre><code>-- unavailable modifier requested: 0 --\n-- unavailable modifier requested: 0 --\n-- unavailable modifier requested: 0 --\n-- unavailable modifier requested: 0 --\n</code></pre>"},{"location":"tool-setup/errors/#solution_1","title":"Solution","text":"<pre><code>sudo killall -9 uwsgi\n\nsudo chown -R aman:aman /home/aman/ipa_india/webapp/ipa_india/\nsudo chmod 755 /home/aman/ipa_india/webapp/ipa_india/\n\nuwsgi --ini ipa_india.ini\n</code></pre>"},{"location":"tool-setup/errors/#monitoring-celery-logs","title":"Monitoring Celery Logs","text":"<pre><code>tail -f /home/aman/ipa_india/webapp/ipa_india/log/celery/worker1.log\n\n# or all at once:\nfor file in /home/aman/ipa_india/webapp/ipa_india/log/celery/*.log; do\n    echo \"Checking $file\"\n    tail -n 20 $file\ndone\n</code></pre>"},{"location":"tool-setup/errors/#monitoring-uwsgi-log","title":"Monitoring uWSGI log","text":"<pre><code>tail -f /home/aman/ipa_india/webapp/ipa_india/log/ipa_india.log\n</code></pre>"},{"location":"tool-setup/errors/#monitoring-apache-logs","title":"Monitoring apache logs","text":"<pre><code>sudo tail -f /var/log/apache2/ipa_india_error.log\nsudo tail -f /var/log/apache2/ipa_india_access.log\n</code></pre>"},{"location":"tool-setup/run-docker/","title":"\ud83d\udc33 Run EQIPA Using Docker","text":"<p>This guide explains how to build and run the EQIPA platform using Docker and <code>docker-compose</code> in localhost.</p>"},{"location":"tool-setup/run-docker/#1-install-docker","title":"1: Install Docker","text":"<p>Install Docker Desktop for your OS:</p> <ul> <li> <p>Windows / macOS:   \ud83d\udc49 https://www.docker.com/products/docker-desktop</p> </li> <li> <p>Ubuntu/Linux:   \ud83d\udc49 Install Docker Engine</p> </li> </ul> <p>Make sure Docker and Docker Compose are installed:</p> <pre><code>docker --version\ndocker-compose --version\n</code></pre>"},{"location":"tool-setup/run-docker/#2-build-and-run-containers","title":"2: Build and Run Containers","text":""},{"location":"tool-setup/run-docker/#build-docker-image","title":"\ud83d\udd28 Build Docker Image","text":"<pre><code>docker-compose build\n</code></pre> Dockerfile <p>Below is a sample <code>Dockerfile</code> that builds the full Django + GRASS + GDAL + Python environment inside Ubuntu 22.04:</p> <pre><code># Use Ubuntu as the base image\nFROM ubuntu:22.04\n\n# Set environment variables to avoid prompts during installation\nENV DEBIAN_FRONTEND=noninteractive\n\n# Install required system dependencies\nRUN apt-get update &amp;&amp; apt-get install -y \\\n    python3 \\\n    python3-pip \\\n    python3-venv \\\n    git \\\n    gdal-bin \\\n    postgis \\\n    redis-server \\\n    virtualenv \\\n    build-essential \\\n    python3-dev \\\n    libpq-dev \\\n    pango1.0-tools \\\n    postgresql \\\n    postgresql-postgis \\\n    grass \\\n    grass-dev \\\n    &amp;&amp; apt-get clean\n\n\nRUN mkdir /app\n\n# Set GRASS GIS environment variables (PERSISTENT)\nENV GRASS_BIN=/usr/bin/grass\nENV GRASS_DB=/app/grassdata\nENV GRASS_LOCATION=wagen\nENV GISBASE=/usr/lib/grass78\nENV LD_LIBRARY_PATH=/usr/lib/grass78/lib:$LD_LIBRARY_PATH\nENV PYTHONPATH=/usr/lib/grass78/etc/python:$PYTHONPATH\n\n\n# Set working directory\nWORKDIR /app\n\n\nCOPY . /app\n\nCOPY requirements.txt .\nRUN pip install --upgrade pip &amp;&amp; pip install -r requirements.txt\n\n# Expose the port and define the default command\nEXPOSE 8000\n</code></pre>"},{"location":"tool-setup/run-docker/#start-all-services","title":"\ud83d\ude80 Start All Services","text":"<pre><code>docker-compose up -d\n</code></pre> docker-compose.yml <p>Here\u2019s a sample docker-compose.yml to bring up the full stack:</p> <pre><code>services:\n    db:\n        image: postgis/postgis:15-3.3\n        container_name: postgres_db\n        restart: always\n        environment:\n        POSTGRES_DB: ipa_test\n        POSTGRES_USER: ipa_test\n        POSTGRES_PASSWORD: ipa_test123\n        # volumes:\n        #   - postgres_data:/var/lib/postgresql/data\n        volumes:\n        - /Volumes/ExternalSSD/Docker/ipa_docker/postgres_data:/var/lib/postgresql/data\n        ports:\n        - \"5433:5432\"  # Host port 5433 mapped to container's port 5432\n\n    redis:\n        image: redis:alpine\n        container_name: redis\n        restart: always\n        ports:\n        - \"6379:6379\"\n\n    web:\n        build: .\n        container_name: ipa_docker\n        restart: always\n        depends_on:\n        - db\n        ports:\n        - \"8000:8000\"\n        environment:\n        DATABASE_URL: postgresql://ipa_test:ipa_test123@db:5432/ipa_test\n        REDIS_URL: redis://redis:6379  # Define or remove if not using Redis\n        volumes:\n        - .:/app  # For development only; remove in production to use the baked image\n        - /Volumes/ExternalSSD/grassdata:/mnt/grassdata\n        command: sh -c \"python3 manage.py makemigrations webapp &amp;&amp; python3 manage.py migrate &amp;&amp; python3 manage.py collectstatic --noinput &amp;&amp; python3 manage.py runserver 0.0.0.0:8000\"\n\n\n\n    celery:\n        build: .\n        container_name: celery_worker\n        restart: always\n        depends_on:\n        - redis\n        - web\n        - db\n        environment:\n        DATABASE_URL: postgresql://ipa_test:ipa_test123@db:5432/ipa_test\n        REDIS_URL: redis://redis:6379\n        volumes:\n        - .:/app\n        - /Volumes/ExternalSSD/grassdata:/mnt/grassdata\n        command: celery -A ipa_india worker --loglevel=info\n\nvolumes:\n    postgres_data:\n</code></pre> <p>This will start: - Django app (<code>ipa_docker</code>) - PostgreSQL (<code>postgres_db</code>) - Redis (<code>redis_cache</code>) - Celery worker (<code>celery_worker</code>)</p>"},{"location":"tool-setup/run-docker/#stop-all-services","title":"Stop All Services","text":"<pre><code>docker-compose down\n</code></pre>"},{"location":"tool-setup/run-docker/#rebuild-without-cache-force-clean-build","title":"Rebuild Without Cache (Force Clean Build)","text":"<pre><code>docker-compose down\ndocker-compose build --no-cache\ndocker-compose up -d\n</code></pre>"},{"location":"tool-setup/run-docker/#check-logs","title":"Check Logs","text":"<p>To verify that containers are running correctly, view logs for each service:</p> <pre><code>docker logs celery_worker\ndocker logs redis_cache\ndocker logs postgres_db\ndocker logs ipa_docker\n</code></pre>"},{"location":"tool-setup/run-docker/#enter-the-django-container","title":"Enter the Django Container","text":"<p>You can access the app container directly and run Django management commands:</p> <pre><code>docker exec -it ipa_docker bash\n</code></pre> <p>Inside the container, you can:</p> <pre><code># Create superuser (only first time)\npython3 manage.py createsuperuser\n</code></pre> <p>\ud83d\udca1 Tip: You can also run migrations or collectstatic here if needed.</p> <p>\u2705 Your EQIPA platform should now be running at: <pre><code>http://localhost:8000/\n</code></pre></p> <p>Update your <code>.env</code> and <code>docker-compose.yml</code> files as needed.</p>"},{"location":"tool-setup/system-setup/","title":"\ud83d\udee0\ufe0f System Setup","text":"<p>This section covers the complete setup of system dependencies and software required to run the EQIPA (Evapotranspiration-based Quick Irrigation Performance Assessment) application on a fresh Ubuntu server.</p>"},{"location":"tool-setup/system-setup/#server-configuration","title":"Server Configuration","text":"<ul> <li>The EQIPA Tool requires a Linux-based Ubuntu server with AMD or intel processor minimum 8 cores, 5TB storage (considering future expansion of the database) and minimum 126 GB RAM for efficient performance.</li> <li>Full admin access to the server</li> </ul>"},{"location":"tool-setup/system-setup/#prerequisite-software","title":"Prerequisite Software","text":"<p>Ensure the following software is installed:</p> <ul> <li>Python 3.10</li> <li>PostgreSQL</li> <li>PostGIS</li> <li>GRASS GIS</li> <li>GDAL</li> <li>Redis</li> <li>Apache2</li> <li>Virtualenv</li> <li>Git</li> <li>Build tools &amp; Python development headers</li> </ul>"},{"location":"tool-setup/system-setup/#install-required-system-packages","title":"Install Required System Packages","text":"<pre><code>sudo apt-get update\n</code></pre> <pre><code>sudo apt-get install -y \\\n    git \\\n    gdal-bin \\\n    apache2 \\\n    postgis \\\n    redis-server \\\n    virtualenv \\\n    build-essential \\\n    python3-dev \\\n    libpq-dev \\\n    pango1.0-tools\n</code></pre>"},{"location":"tool-setup/system-setup/#verify-installation","title":"Verify Installation","text":"<pre><code>python3 --version\nsudo apt install -y python3.10 python3.10-venv python3.10-dev\n</code></pre>"},{"location":"tool-setup/system-setup/#choose-the-default-version","title":"Choose the default version","text":"<pre><code>sudo update-alternatives --config python3\n\n  Selection    Path                Priority   Status\n------------------------------------------------------------\n* 0            /usr/bin/python3.8   2         auto mode\n  1            /usr/bin/python3.8   2         manual mode\n  2            /usr/bin/python3.10  1         manual mode\n</code></pre>"},{"location":"tool-setup/system-setup/#install-postgresql-postgis","title":"Install PostgreSQL &amp; PostGIS","text":"<pre><code>sudo apt-get install -y postgresql postgresql-postgis\n</code></pre>"},{"location":"tool-setup/system-setup/#install-grass-gis","title":"Install GRASS GIS","text":"<pre><code>sudo add-apt-repository ppa:ubuntugis/ubuntugis-unstable\nsudo apt-get install -y grass grass-dev\n</code></pre>"},{"location":"tool-setup/system-setup/#create-a-grass-gis-location","title":"Create a GRASS GIS Location","text":"<pre><code>grass -c EPSG:4326 -e /mnt/mapdata/grassdata/ipa_india\n</code></pre> <p>Verify the mapset:</p> <pre><code>ls /mnt/mapdata/grassdata/ipa_india\n</code></pre> <p>Note: In <code>settings.py</code>, the value of <code>GRASS_DB</code> should be set as <code>/mnt/mapdata/grassdata</code></p>"},{"location":"tool-setup/system-setup/#configure-postgresql-user-and-database","title":"Configure PostgreSQL User and Database","text":"<p>Create a new PostgreSQL user:</p> <pre><code>sudo -u postgres createuser ipa_india\n</code></pre> <p>Login to PostgreSQL:</p> <pre><code>sudo -u postgres psql\n</code></pre> <p>Inside psql:</p> <pre><code>ALTER USER postgres PASSWORD 'ipa_india';\nALTER USER ipa_india PASSWORD 'ipa_india123';\nALTER USER ipa_india WITH SUPERUSER;\n\\q\n</code></pre> <p>Create the database and enable PostGIS:</p> <pre><code>createdb -U ipa_india -h localhost ipa_india\npsql -U ipa_india -h localhost ipa_india -c \"CREATE EXTENSION postgis\"\n</code></pre>"},{"location":"tool-setup/system-setup/#summary","title":"\u2705 Summary","text":"Component Version / Details OS Ubuntu 20.04 or later Python 3.10 PostgreSQL With PostGIS extension GRASS GIS Installed via ubuntugis-unstable PPA Redis Required for Celery queue Apache2 + uWSGI For production deployment <p>You're now ready to proceed with setting up the Django app. \u2192 Continue to Running tool in Development Mode</p>"}]}